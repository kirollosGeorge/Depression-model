{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import re\n",
    "import string\n",
    "import gensim\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import punkt\n",
    "from nltk import wordnet\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding, LSTM, Dropout, GRU, Bidirectional, Conv1D, GlobalMaxPooling1D\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.callbacks import ReduceLROnPlateau, EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    the real reason why you're sad? you're attache...\n",
      "1        my biggest problem is overthinking everything\n",
      "2    the worst sadness is the sadness you've taught...\n",
      "3    i cannot make you understand. i cannot make an...\n",
      "4    i don't think anyone really understands how ti...\n",
      "Name: tweet, dtype: object\n",
      "0    4695\n",
      "1    3440\n",
      "Name: target, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "data_columns = [\"target\", \"tweet\", \"username\"]\n",
    "data_encoding = \"ISO-8859-1\"\n",
    "data=pd.read_csv('./TwitterDataset.csv',encoding = data_encoding, usecols=data_columns)\n",
    "\n",
    "X = data.iloc[:, 1]\n",
    "Y = data.iloc[:, 0]\n",
    "\n",
    "print(X.head())\n",
    "print(data['target'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(tweet):\n",
    "    username = \"@\\S+\"\n",
    "    new_tweet = re.sub(username, ' ',tweet) # Remove @tags\n",
    "    \n",
    "    new_tweet = new_tweet.lower() # Smart lowercase\n",
    "    \n",
    "    new_tweet = re.sub(r'\\d+', ' ', new_tweet) # Remove numbers\n",
    "    \n",
    "    text_noise = \"https?:\\S+|http?:\\S|[^A-Za-z0-9]+\" \n",
    "    new_tweet = re.sub(text_noise, ' ', new_tweet) # Remove links\n",
    "    \n",
    "    new_tweet = new_tweet.translate(new_tweet.maketrans('','',string.punctuation)) # Remove Punctuation\n",
    "    \n",
    "    new_tweet = new_tweet.strip() # Remove white spaces\n",
    "    \n",
    "    new_tweet = word_tokenize(new_tweet) # Tokenize into words\n",
    "    \n",
    "    new_tweet = ' '.join([word for word in new_tweet if word.isalpha()]) # Remove non alphabetic tokens\n",
    "    \n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    new_tweet = ' '.join([word for word in new_tweet.split() if not word in stop_words]) # Filter out stop words\n",
    "    \n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    new_tweet = ' '.join([lemmatizer.lemmatize(word,\"v\") for word in new_tweet.split()]) # Word Lemmatization\n",
    "    \n",
    "    return new_tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       real reason sad attach people distant pay atte...\n",
      "1                 biggest problem overthinking everything\n",
      "2                        worst sadness sadness teach hide\n",
      "3       make understand make anyone understand happen ...\n",
      "4       think anyone really understand tire act okay a...\n",
      "                              ...                        \n",
      "8130    cardi b want trademark catchphrase okurr think...\n",
      "8131    bet kellyanne george conway pretty disturb mak...\n",
      "8132    fan always ask watch old stuff finally answer ...\n",
      "8133    ray romano hilarious comedian kind soul rare n...\n",
      "8134    mueller report may finish mine next week johnn...\n",
      "Name: tweet, Length: 8135, dtype: object\n"
     ]
    }
   ],
   "source": [
    "X = X.apply(preprocess)\n",
    "\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN size: 6508\n",
      "TEST size: 1627\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "print(\"TRAIN size:\", len(X_train))\n",
    "print(\"TEST size:\", len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_size = 300\n",
    "w2v_win = 7\n",
    "w2v_epoch = 32\n",
    "w2v_mincount = 10\n",
    "\n",
    "document = [tweet.split() for tweet in X_train]\n",
    "word2vec_model = gensim.models.word2vec.Word2Vec(vector_size=w2v_size,\n",
    "                                                window=w2v_win,\n",
    "                                                min_count=w2v_mincount,\n",
    "                                                workers=8)\n",
    "\n",
    "word2vec_model.build_vocab(document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary_size :::  964\n"
     ]
    }
   ],
   "source": [
    "words = word2vec_model.wv.index_to_key\n",
    "vocabulary_size = len(words)\n",
    "print('Vocabulary_size ::: ',vocabulary_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1185622, 1851840)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2vec_model.train(document,total_examples=len(document),epochs=w2v_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No.of unique tokens === 8635\n"
     ]
    }
   ],
   "source": [
    "max_sequence_length = 300\n",
    "vector_size = 300\n",
    "\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "unique_tokens = tokenizer.word_index\n",
    "tokens_size = len(unique_tokens)\n",
    "print('No.of unique tokens === %s'%tokens_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_padded = tokenizer.texts_to_sequences(X_train)\n",
    "X_train_padded = pad_sequences(X_train_padded,maxlen=max_sequence_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vector matrix shape ===  (8636, 300)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [-0.07327162,  0.35163948, -0.04450747, ...,  0.01208324,\n",
       "         0.06084003, -0.092077  ],\n",
       "       [-0.41569623,  0.21939704, -0.33398464, ..., -0.43874168,\n",
       "         0.56521469, -0.63016099],\n",
       "       ...,\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_matrix = np.zeros((tokens_size+1,w2v_size))\n",
    "\n",
    "for word,i in tokenizer.word_index.items():\n",
    "    if word in word2vec_model.wv:\n",
    "        vector_matrix[i]=word2vec_model.wv[word]\n",
    "\n",
    "print('vector matrix shape === ',vector_matrix.shape)\n",
    "\n",
    "vector_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_padded = tokenizer.texts_to_sequences(X_test)\n",
    "X_test_padded = pad_sequences(X_test_padded,maxlen=max_sequence_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers.convolutional import MaxPooling1D\n",
    "def build_lstm_model(optimizer, dropout_rate, n_neurons, cnn_activation, dense_activation):\n",
    "    LSTM_model = Sequential(name='LSTM_model')\n",
    "    LSTM_model.add(Embedding(tokens_size+1,w2v_size, weights=[vector_matrix],input_length=max_sequence_length,trainable=False))\n",
    "    LSTM_model.add(Dropout(0.5))\n",
    "    LSTM_model.add(Conv1D(filters=300, kernel_size=3, padding='same', activation='relu'))\n",
    "    LSTM_model.add(MaxPooling1D(pool_size=2))\n",
    "    LSTM_model.add(LSTM(100, dropout=0.2, recurrent_dropout=0.2))\n",
    "    LSTM_model.add(Dense(1, activation='sigmoid'))\n",
    "    LSTM_model.compile(loss='binary_crossentropy',optimizer=optimizer,metrics=['accuracy'])\n",
    "    return LSTM_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "WARNING:tensorflow:Layer lstm_279 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kerillos\\AppData\\Local\\Temp\\ipykernel_12752\\1161767166.py:6: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  classifier = KerasClassifier(build_lstm_model)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "122/122 [==============================] - 43s 320ms/step - loss: 0.3735 - accuracy: 0.8281 - val_loss: 0.3362 - val_accuracy: 0.8571\n",
      "Epoch 2/100\n",
      "122/122 [==============================] - 39s 316ms/step - loss: 0.3238 - accuracy: 0.8599 - val_loss: 0.2759 - val_accuracy: 0.8848\n",
      "Epoch 3/100\n",
      "122/122 [==============================] - 38s 316ms/step - loss: 0.3051 - accuracy: 0.8691 - val_loss: 0.3240 - val_accuracy: 0.8525\n",
      "Epoch 4/100\n",
      "122/122 [==============================] - 39s 317ms/step - loss: 0.2930 - accuracy: 0.8724 - val_loss: 0.2710 - val_accuracy: 0.8825\n",
      "Epoch 5/100\n",
      "122/122 [==============================] - 39s 317ms/step - loss: 0.2798 - accuracy: 0.8819 - val_loss: 0.2778 - val_accuracy: 0.8710\n",
      "Epoch 6/100\n",
      "122/122 [==============================] - 38s 314ms/step - loss: 0.2608 - accuracy: 0.8850 - val_loss: 0.2795 - val_accuracy: 0.8779\n",
      "Epoch 7/100\n",
      "122/122 [==============================] - 38s 314ms/step - loss: 0.2448 - accuracy: 0.8986 - val_loss: 0.2980 - val_accuracy: 0.8641\n",
      "Epoch 8/100\n",
      "122/122 [==============================] - 40s 325ms/step - loss: 0.2272 - accuracy: 0.9047 - val_loss: 0.2806 - val_accuracy: 0.8756\n",
      "Epoch 9/100\n",
      "122/122 [==============================] - 40s 325ms/step - loss: 0.2091 - accuracy: 0.9098 - val_loss: 0.3130 - val_accuracy: 0.8710\n",
      "Epoch 10/100\n",
      "122/122 [==============================] - 39s 324ms/step - loss: 0.1918 - accuracy: 0.9173 - val_loss: 0.3412 - val_accuracy: 0.8410\n",
      "Epoch 11/100\n",
      "122/122 [==============================] - 41s 333ms/step - loss: 0.1878 - accuracy: 0.9211 - val_loss: 0.2781 - val_accuracy: 0.8917\n",
      "Epoch 12/100\n",
      "122/122 [==============================] - 39s 323ms/step - loss: 0.1552 - accuracy: 0.9331 - val_loss: 0.3036 - val_accuracy: 0.8894\n",
      "Epoch 13/100\n",
      "122/122 [==============================] - 39s 323ms/step - loss: 0.1452 - accuracy: 0.9370 - val_loss: 0.3138 - val_accuracy: 0.8733\n",
      "Epoch 14/100\n",
      "122/122 [==============================] - 39s 320ms/step - loss: 0.1382 - accuracy: 0.9454 - val_loss: 0.3467 - val_accuracy: 0.8433\n",
      "Epoch 15/100\n",
      "122/122 [==============================] - 38s 316ms/step - loss: 0.1206 - accuracy: 0.9462 - val_loss: 0.3742 - val_accuracy: 0.8571\n",
      "Epoch 16/100\n",
      "122/122 [==============================] - 39s 321ms/step - loss: 0.1039 - accuracy: 0.9582 - val_loss: 0.3754 - val_accuracy: 0.8618\n",
      "Epoch 17/100\n",
      "122/122 [==============================] - 39s 319ms/step - loss: 0.0993 - accuracy: 0.9598 - val_loss: 0.3575 - val_accuracy: 0.8802\n",
      "Epoch 18/100\n",
      "122/122 [==============================] - 39s 320ms/step - loss: 0.0854 - accuracy: 0.9639 - val_loss: 0.4205 - val_accuracy: 0.8479\n",
      "Epoch 19/100\n",
      "122/122 [==============================] - 39s 318ms/step - loss: 0.0954 - accuracy: 0.9590 - val_loss: 0.3775 - val_accuracy: 0.8641\n",
      "Epoch 20/100\n",
      "122/122 [==============================] - 38s 315ms/step - loss: 0.0728 - accuracy: 0.9700 - val_loss: 0.4403 - val_accuracy: 0.8502\n",
      "Epoch 21/100\n",
      "122/122 [==============================] - 40s 326ms/step - loss: 0.0792 - accuracy: 0.9675 - val_loss: 0.3886 - val_accuracy: 0.8664\n",
      "Epoch 22/100\n",
      "122/122 [==============================] - 39s 324ms/step - loss: 0.0609 - accuracy: 0.9731 - val_loss: 0.4289 - val_accuracy: 0.8502\n",
      "Epoch 23/100\n",
      "122/122 [==============================] - 39s 324ms/step - loss: 0.0650 - accuracy: 0.9734 - val_loss: 0.4471 - val_accuracy: 0.8571\n",
      "Epoch 24/100\n",
      "122/122 [==============================] - 40s 325ms/step - loss: 0.0654 - accuracy: 0.9741 - val_loss: 0.4922 - val_accuracy: 0.8456\n",
      "WARNING:tensorflow:Layer lstm_280 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Epoch 1/100\n",
      "123/123 [==============================] - 77s 612ms/step - loss: 0.3757 - accuracy: 0.8325 - val_loss: 0.3290 - val_accuracy: 0.8387\n",
      "Epoch 2/100\n",
      "123/123 [==============================] - 75s 610ms/step - loss: 0.3309 - accuracy: 0.8504 - val_loss: 0.2885 - val_accuracy: 0.8733\n",
      "Epoch 3/100\n",
      "123/123 [==============================] - 75s 607ms/step - loss: 0.3172 - accuracy: 0.8622 - val_loss: 0.2852 - val_accuracy: 0.8779\n",
      "Epoch 4/100\n",
      "123/123 [==============================] - 75s 613ms/step - loss: 0.2946 - accuracy: 0.8743 - val_loss: 0.3005 - val_accuracy: 0.8502\n",
      "Epoch 5/100\n",
      "123/123 [==============================] - 77s 623ms/step - loss: 0.2779 - accuracy: 0.8758 - val_loss: 0.2635 - val_accuracy: 0.8779\n",
      "Epoch 6/100\n",
      "123/123 [==============================] - 75s 608ms/step - loss: 0.2671 - accuracy: 0.8817 - val_loss: 0.2942 - val_accuracy: 0.8618\n",
      "Epoch 7/100\n",
      "123/123 [==============================] - 77s 624ms/step - loss: 0.2720 - accuracy: 0.8812 - val_loss: 0.2950 - val_accuracy: 0.8687\n",
      "Epoch 8/100\n",
      "123/123 [==============================] - 76s 616ms/step - loss: 0.2397 - accuracy: 0.8976 - val_loss: 0.3220 - val_accuracy: 0.8594\n",
      "Epoch 9/100\n",
      "123/123 [==============================] - 76s 619ms/step - loss: 0.2187 - accuracy: 0.9014 - val_loss: 0.3512 - val_accuracy: 0.8502\n",
      "Epoch 10/100\n",
      "123/123 [==============================] - 75s 611ms/step - loss: 0.2242 - accuracy: 0.9012 - val_loss: 0.2816 - val_accuracy: 0.8871\n",
      "Epoch 11/100\n",
      "123/123 [==============================] - 76s 621ms/step - loss: 0.1914 - accuracy: 0.9178 - val_loss: 0.3086 - val_accuracy: 0.8733\n",
      "Epoch 12/100\n",
      "123/123 [==============================] - 73s 594ms/step - loss: 0.1710 - accuracy: 0.9255 - val_loss: 0.3251 - val_accuracy: 0.8917\n",
      "Epoch 13/100\n",
      "123/123 [==============================] - 76s 619ms/step - loss: 0.1559 - accuracy: 0.9324 - val_loss: 0.3726 - val_accuracy: 0.8664\n",
      "Epoch 14/100\n",
      "123/123 [==============================] - 75s 611ms/step - loss: 0.1489 - accuracy: 0.9360 - val_loss: 0.4303 - val_accuracy: 0.8410\n",
      "Epoch 15/100\n",
      "123/123 [==============================] - 74s 600ms/step - loss: 0.1328 - accuracy: 0.9419 - val_loss: 0.3660 - val_accuracy: 0.8687\n",
      "Epoch 16/100\n",
      "123/123 [==============================] - 75s 611ms/step - loss: 0.1233 - accuracy: 0.9462 - val_loss: 0.3548 - val_accuracy: 0.8664\n",
      "Epoch 17/100\n",
      "123/123 [==============================] - 77s 627ms/step - loss: 0.1337 - accuracy: 0.9429 - val_loss: 0.4004 - val_accuracy: 0.8618\n",
      "Epoch 18/100\n",
      "123/123 [==============================] - 75s 609ms/step - loss: 0.1104 - accuracy: 0.9549 - val_loss: 0.3800 - val_accuracy: 0.8687\n",
      "Epoch 19/100\n",
      "123/123 [==============================] - 75s 610ms/step - loss: 0.0981 - accuracy: 0.9593 - val_loss: 0.3951 - val_accuracy: 0.8641\n",
      "Epoch 20/100\n",
      "123/123 [==============================] - 76s 615ms/step - loss: 0.1008 - accuracy: 0.9521 - val_loss: 0.4019 - val_accuracy: 0.8710\n",
      "Epoch 21/100\n",
      "123/123 [==============================] - 75s 611ms/step - loss: 0.0848 - accuracy: 0.9647 - val_loss: 0.4244 - val_accuracy: 0.8664\n",
      "Epoch 22/100\n",
      "123/123 [==============================] - 74s 601ms/step - loss: 0.0764 - accuracy: 0.9680 - val_loss: 0.4949 - val_accuracy: 0.8525\n",
      "Epoch 23/100\n",
      "123/123 [==============================] - 77s 625ms/step - loss: 0.0789 - accuracy: 0.9644 - val_loss: 0.4204 - val_accuracy: 0.8894\n",
      "Epoch 24/100\n",
      "123/123 [==============================] - 74s 606ms/step - loss: 0.0774 - accuracy: 0.9703 - val_loss: 0.4008 - val_accuracy: 0.8733\n",
      "Epoch 25/100\n",
      "123/123 [==============================] - 75s 612ms/step - loss: 0.0705 - accuracy: 0.9688 - val_loss: 0.4479 - val_accuracy: 0.8779\n",
      "WARNING:tensorflow:Layer lstm_281 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Epoch 1/100\n",
      "123/123 [==============================] - 78s 619ms/step - loss: 0.3570 - accuracy: 0.8410 - val_loss: 0.3716 - val_accuracy: 0.8479\n",
      "Epoch 2/100\n",
      "123/123 [==============================] - 77s 628ms/step - loss: 0.3104 - accuracy: 0.8635 - val_loss: 0.3606 - val_accuracy: 0.8502\n",
      "Epoch 3/100\n",
      "123/123 [==============================] - 77s 630ms/step - loss: 0.2950 - accuracy: 0.8738 - val_loss: 0.4107 - val_accuracy: 0.8410\n",
      "Epoch 4/100\n",
      "123/123 [==============================] - 77s 629ms/step - loss: 0.2796 - accuracy: 0.8853 - val_loss: 0.3730 - val_accuracy: 0.8548\n",
      "Epoch 5/100\n",
      "123/123 [==============================] - 76s 619ms/step - loss: 0.2730 - accuracy: 0.8873 - val_loss: 0.3677 - val_accuracy: 0.8502\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/100\n",
      "123/123 [==============================] - 76s 614ms/step - loss: 0.2460 - accuracy: 0.8988 - val_loss: 0.3635 - val_accuracy: 0.8571\n",
      "Epoch 7/100\n",
      "123/123 [==============================] - 77s 624ms/step - loss: 0.2402 - accuracy: 0.8999 - val_loss: 0.3988 - val_accuracy: 0.8456\n",
      "Epoch 8/100\n",
      "123/123 [==============================] - 78s 637ms/step - loss: 0.2207 - accuracy: 0.9109 - val_loss: 0.3947 - val_accuracy: 0.8341\n",
      "Epoch 9/100\n",
      "123/123 [==============================] - 76s 616ms/step - loss: 0.2090 - accuracy: 0.9114 - val_loss: 0.4044 - val_accuracy: 0.8618\n",
      "Epoch 10/100\n",
      "123/123 [==============================] - 77s 629ms/step - loss: 0.1854 - accuracy: 0.9186 - val_loss: 0.4082 - val_accuracy: 0.8594\n",
      "Epoch 11/100\n",
      "123/123 [==============================] - 76s 615ms/step - loss: 0.1692 - accuracy: 0.9265 - val_loss: 0.4484 - val_accuracy: 0.8618\n",
      "Epoch 12/100\n",
      "123/123 [==============================] - 75s 613ms/step - loss: 0.1768 - accuracy: 0.9278 - val_loss: 0.4590 - val_accuracy: 0.8479\n",
      "Epoch 13/100\n",
      "123/123 [==============================] - 76s 615ms/step - loss: 0.1397 - accuracy: 0.9411 - val_loss: 0.4563 - val_accuracy: 0.8548\n",
      "Epoch 14/100\n",
      "123/123 [==============================] - 77s 624ms/step - loss: 0.1269 - accuracy: 0.9472 - val_loss: 0.5182 - val_accuracy: 0.8525\n",
      "Epoch 15/100\n",
      "123/123 [==============================] - 76s 615ms/step - loss: 0.1139 - accuracy: 0.9547 - val_loss: 0.5388 - val_accuracy: 0.8433\n",
      "Epoch 16/100\n",
      "123/123 [==============================] - 77s 631ms/step - loss: 0.1136 - accuracy: 0.9534 - val_loss: 0.5502 - val_accuracy: 0.8525\n",
      "Epoch 17/100\n",
      "123/123 [==============================] - 76s 614ms/step - loss: 0.1034 - accuracy: 0.9588 - val_loss: 0.5786 - val_accuracy: 0.8410\n",
      "Epoch 18/100\n",
      "123/123 [==============================] - 76s 614ms/step - loss: 0.1000 - accuracy: 0.9529 - val_loss: 0.5892 - val_accuracy: 0.8387\n",
      "Epoch 19/100\n",
      "123/123 [==============================] - 77s 625ms/step - loss: 0.0788 - accuracy: 0.9695 - val_loss: 0.6172 - val_accuracy: 0.8410\n",
      "Epoch 20/100\n",
      "123/123 [==============================] - 78s 633ms/step - loss: 0.0786 - accuracy: 0.9706 - val_loss: 0.5934 - val_accuracy: 0.8525\n",
      "Epoch 21/100\n",
      "123/123 [==============================] - 75s 611ms/step - loss: 0.0798 - accuracy: 0.9685 - val_loss: 0.6060 - val_accuracy: 0.8341\n",
      "Epoch 22/100\n",
      "123/123 [==============================] - 77s 624ms/step - loss: 0.0676 - accuracy: 0.9736 - val_loss: 0.6566 - val_accuracy: 0.8594\n",
      "WARNING:tensorflow:Layer lstm_282 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Epoch 1/100\n",
      "122/122 [==============================] - 42s 338ms/step - loss: 0.6124 - accuracy: 0.6662 - val_loss: 0.5587 - val_accuracy: 0.7903\n",
      "Epoch 2/100\n",
      "122/122 [==============================] - 41s 339ms/step - loss: 0.5173 - accuracy: 0.8005 - val_loss: 0.4874 - val_accuracy: 0.8157\n",
      "Epoch 3/100\n",
      "122/122 [==============================] - 40s 332ms/step - loss: 0.4569 - accuracy: 0.8174 - val_loss: 0.4473 - val_accuracy: 0.8111\n",
      "Epoch 4/100\n",
      "122/122 [==============================] - 39s 323ms/step - loss: 0.4198 - accuracy: 0.8266 - val_loss: 0.4272 - val_accuracy: 0.8111\n",
      "Epoch 5/100\n",
      "122/122 [==============================] - 40s 327ms/step - loss: 0.4019 - accuracy: 0.8258 - val_loss: 0.4113 - val_accuracy: 0.8065\n",
      "Epoch 6/100\n",
      "122/122 [==============================] - 40s 326ms/step - loss: 0.3901 - accuracy: 0.8297 - val_loss: 0.4109 - val_accuracy: 0.7995\n",
      "Epoch 7/100\n",
      "122/122 [==============================] - 41s 333ms/step - loss: 0.3829 - accuracy: 0.8327 - val_loss: 0.4086 - val_accuracy: 0.8018\n",
      "Epoch 8/100\n",
      "122/122 [==============================] - 41s 335ms/step - loss: 0.3771 - accuracy: 0.8353 - val_loss: 0.4024 - val_accuracy: 0.8088\n",
      "Epoch 9/100\n",
      "122/122 [==============================] - 40s 329ms/step - loss: 0.3712 - accuracy: 0.8366 - val_loss: 0.3996 - val_accuracy: 0.8134\n",
      "Epoch 10/100\n",
      "122/122 [==============================] - 41s 332ms/step - loss: 0.3672 - accuracy: 0.8394 - val_loss: 0.3953 - val_accuracy: 0.8157\n",
      "Epoch 11/100\n",
      "122/122 [==============================] - 40s 332ms/step - loss: 0.3661 - accuracy: 0.8363 - val_loss: 0.3871 - val_accuracy: 0.8180\n",
      "Epoch 12/100\n",
      "122/122 [==============================] - 40s 328ms/step - loss: 0.3609 - accuracy: 0.8389 - val_loss: 0.3724 - val_accuracy: 0.8203\n",
      "Epoch 13/100\n",
      "122/122 [==============================] - 40s 325ms/step - loss: 0.3566 - accuracy: 0.8404 - val_loss: 0.3807 - val_accuracy: 0.8180\n",
      "Epoch 14/100\n",
      "122/122 [==============================] - 40s 332ms/step - loss: 0.3561 - accuracy: 0.8438 - val_loss: 0.3852 - val_accuracy: 0.8180\n",
      "Epoch 15/100\n",
      "122/122 [==============================] - 41s 340ms/step - loss: 0.3532 - accuracy: 0.8443 - val_loss: 0.3700 - val_accuracy: 0.8203\n",
      "Epoch 16/100\n",
      "122/122 [==============================] - 41s 337ms/step - loss: 0.3525 - accuracy: 0.8453 - val_loss: 0.3681 - val_accuracy: 0.8203\n",
      "Epoch 17/100\n",
      "122/122 [==============================] - 40s 329ms/step - loss: 0.3499 - accuracy: 0.8450 - val_loss: 0.3733 - val_accuracy: 0.8226\n",
      "Epoch 18/100\n",
      "122/122 [==============================] - 39s 322ms/step - loss: 0.3476 - accuracy: 0.8494 - val_loss: 0.3500 - val_accuracy: 0.8410\n",
      "Epoch 19/100\n",
      "122/122 [==============================] - 39s 319ms/step - loss: 0.3474 - accuracy: 0.8466 - val_loss: 0.3637 - val_accuracy: 0.8249\n",
      "Epoch 20/100\n",
      "122/122 [==============================] - 40s 324ms/step - loss: 0.3433 - accuracy: 0.8481 - val_loss: 0.3664 - val_accuracy: 0.8157\n",
      "Epoch 21/100\n",
      "122/122 [==============================] - 40s 329ms/step - loss: 0.3413 - accuracy: 0.8543 - val_loss: 0.3436 - val_accuracy: 0.8387\n",
      "Epoch 22/100\n",
      "122/122 [==============================] - 40s 329ms/step - loss: 0.3420 - accuracy: 0.8502 - val_loss: 0.3577 - val_accuracy: 0.8272\n",
      "Epoch 23/100\n",
      "122/122 [==============================] - 39s 322ms/step - loss: 0.3396 - accuracy: 0.8512 - val_loss: 0.3503 - val_accuracy: 0.8295\n",
      "Epoch 24/100\n",
      "122/122 [==============================] - 40s 326ms/step - loss: 0.3387 - accuracy: 0.8491 - val_loss: 0.3493 - val_accuracy: 0.8318\n",
      "Epoch 25/100\n",
      "122/122 [==============================] - 39s 319ms/step - loss: 0.3368 - accuracy: 0.8496 - val_loss: 0.3353 - val_accuracy: 0.8502\n",
      "Epoch 26/100\n",
      "122/122 [==============================] - 39s 318ms/step - loss: 0.3344 - accuracy: 0.8527 - val_loss: 0.3524 - val_accuracy: 0.8272\n",
      "Epoch 27/100\n",
      "122/122 [==============================] - 39s 321ms/step - loss: 0.3341 - accuracy: 0.8555 - val_loss: 0.3462 - val_accuracy: 0.8364\n",
      "Epoch 28/100\n",
      "122/122 [==============================] - 40s 331ms/step - loss: 0.3329 - accuracy: 0.8540 - val_loss: 0.3393 - val_accuracy: 0.8387\n",
      "Epoch 29/100\n",
      "122/122 [==============================] - 40s 331ms/step - loss: 0.3305 - accuracy: 0.8527 - val_loss: 0.3268 - val_accuracy: 0.8618\n",
      "Epoch 30/100\n",
      "122/122 [==============================] - 39s 319ms/step - loss: 0.3331 - accuracy: 0.8555 - val_loss: 0.3312 - val_accuracy: 0.8525\n",
      "Epoch 31/100\n",
      "122/122 [==============================] - 40s 332ms/step - loss: 0.3278 - accuracy: 0.8540 - val_loss: 0.3314 - val_accuracy: 0.8502\n",
      "Epoch 32/100\n",
      "122/122 [==============================] - 39s 318ms/step - loss: 0.3263 - accuracy: 0.8548 - val_loss: 0.3212 - val_accuracy: 0.8641\n",
      "Epoch 33/100\n",
      "122/122 [==============================] - 39s 321ms/step - loss: 0.3260 - accuracy: 0.8548 - val_loss: 0.3284 - val_accuracy: 0.8571\n",
      "Epoch 34/100\n",
      "122/122 [==============================] - 39s 322ms/step - loss: 0.3298 - accuracy: 0.8566 - val_loss: 0.3264 - val_accuracy: 0.8571\n",
      "Epoch 35/100\n",
      "122/122 [==============================] - 39s 320ms/step - loss: 0.3243 - accuracy: 0.8589 - val_loss: 0.3272 - val_accuracy: 0.8571\n",
      "Epoch 36/100\n",
      "122/122 [==============================] - 40s 325ms/step - loss: 0.3242 - accuracy: 0.8576 - val_loss: 0.3216 - val_accuracy: 0.8618\n",
      "Epoch 37/100\n",
      "122/122 [==============================] - 39s 323ms/step - loss: 0.3218 - accuracy: 0.8619 - val_loss: 0.3299 - val_accuracy: 0.8594\n",
      "Epoch 38/100\n",
      "122/122 [==============================] - 40s 326ms/step - loss: 0.3201 - accuracy: 0.8599 - val_loss: 0.3294 - val_accuracy: 0.8618\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39/100\n",
      "122/122 [==============================] - 39s 323ms/step - loss: 0.3198 - accuracy: 0.8612 - val_loss: 0.3368 - val_accuracy: 0.8548\n",
      "Epoch 40/100\n",
      "122/122 [==============================] - 40s 329ms/step - loss: 0.3191 - accuracy: 0.8596 - val_loss: 0.3322 - val_accuracy: 0.8548\n",
      "Epoch 41/100\n",
      "122/122 [==============================] - 40s 326ms/step - loss: 0.3166 - accuracy: 0.8624 - val_loss: 0.3286 - val_accuracy: 0.8548\n",
      "Epoch 42/100\n",
      "122/122 [==============================] - 40s 325ms/step - loss: 0.3193 - accuracy: 0.8642 - val_loss: 0.3187 - val_accuracy: 0.8618\n",
      "Epoch 43/100\n",
      "122/122 [==============================] - 39s 319ms/step - loss: 0.3190 - accuracy: 0.8645 - val_loss: 0.3217 - val_accuracy: 0.8548\n",
      "Epoch 44/100\n",
      "122/122 [==============================] - 39s 319ms/step - loss: 0.3136 - accuracy: 0.8648 - val_loss: 0.3161 - val_accuracy: 0.8594\n",
      "Epoch 45/100\n",
      "122/122 [==============================] - 39s 317ms/step - loss: 0.3158 - accuracy: 0.8650 - val_loss: 0.3152 - val_accuracy: 0.8618\n",
      "Epoch 46/100\n",
      "122/122 [==============================] - 39s 316ms/step - loss: 0.3133 - accuracy: 0.8668 - val_loss: 0.3076 - val_accuracy: 0.8618\n",
      "Epoch 47/100\n",
      "122/122 [==============================] - 39s 321ms/step - loss: 0.3137 - accuracy: 0.8671 - val_loss: 0.3175 - val_accuracy: 0.8571\n",
      "Epoch 48/100\n",
      "122/122 [==============================] - 40s 326ms/step - loss: 0.3169 - accuracy: 0.8635 - val_loss: 0.3169 - val_accuracy: 0.8571\n",
      "Epoch 49/100\n",
      "122/122 [==============================] - 39s 324ms/step - loss: 0.3121 - accuracy: 0.8678 - val_loss: 0.3095 - val_accuracy: 0.8641\n",
      "Epoch 50/100\n",
      "122/122 [==============================] - 40s 326ms/step - loss: 0.3140 - accuracy: 0.8650 - val_loss: 0.3077 - val_accuracy: 0.8594\n",
      "Epoch 51/100\n",
      "122/122 [==============================] - 40s 327ms/step - loss: 0.3119 - accuracy: 0.8686 - val_loss: 0.3118 - val_accuracy: 0.8594\n",
      "Epoch 52/100\n",
      "122/122 [==============================] - 39s 318ms/step - loss: 0.3056 - accuracy: 0.8691 - val_loss: 0.3154 - val_accuracy: 0.8548\n",
      "Epoch 53/100\n",
      "122/122 [==============================] - 39s 319ms/step - loss: 0.3075 - accuracy: 0.8648 - val_loss: 0.3147 - val_accuracy: 0.8548\n",
      "Epoch 54/100\n",
      "122/122 [==============================] - 40s 331ms/step - loss: 0.3142 - accuracy: 0.8665 - val_loss: 0.3131 - val_accuracy: 0.8571\n",
      "Epoch 55/100\n",
      "122/122 [==============================] - 40s 327ms/step - loss: 0.3078 - accuracy: 0.8704 - val_loss: 0.3063 - val_accuracy: 0.8618\n",
      "Epoch 56/100\n",
      "122/122 [==============================] - 40s 326ms/step - loss: 0.3109 - accuracy: 0.8691 - val_loss: 0.3051 - val_accuracy: 0.8618\n",
      "Epoch 57/100\n",
      "122/122 [==============================] - 40s 325ms/step - loss: 0.3067 - accuracy: 0.8660 - val_loss: 0.3109 - val_accuracy: 0.8594\n",
      "Epoch 58/100\n",
      "122/122 [==============================] - 39s 323ms/step - loss: 0.3076 - accuracy: 0.8722 - val_loss: 0.3210 - val_accuracy: 0.8525\n",
      "Epoch 59/100\n",
      "122/122 [==============================] - 39s 322ms/step - loss: 0.3098 - accuracy: 0.8663 - val_loss: 0.3189 - val_accuracy: 0.8548\n",
      "Epoch 60/100\n",
      "122/122 [==============================] - 40s 327ms/step - loss: 0.3057 - accuracy: 0.8660 - val_loss: 0.3042 - val_accuracy: 0.8618\n",
      "Epoch 61/100\n",
      "122/122 [==============================] - 45s 373ms/step - loss: 0.3021 - accuracy: 0.8704 - val_loss: 0.3044 - val_accuracy: 0.8641\n",
      "Epoch 62/100\n",
      "122/122 [==============================] - 61s 498ms/step - loss: 0.3031 - accuracy: 0.8658 - val_loss: 0.3063 - val_accuracy: 0.8618\n",
      "Epoch 63/100\n",
      "122/122 [==============================] - 61s 502ms/step - loss: 0.3035 - accuracy: 0.8660 - val_loss: 0.3049 - val_accuracy: 0.8664\n",
      "Epoch 64/100\n",
      "122/122 [==============================] - 59s 481ms/step - loss: 0.3038 - accuracy: 0.8676 - val_loss: 0.3069 - val_accuracy: 0.8594\n",
      "Epoch 65/100\n",
      "122/122 [==============================] - 60s 494ms/step - loss: 0.3046 - accuracy: 0.8719 - val_loss: 0.3209 - val_accuracy: 0.8594\n",
      "Epoch 66/100\n",
      "122/122 [==============================] - 60s 494ms/step - loss: 0.2980 - accuracy: 0.8760 - val_loss: 0.3091 - val_accuracy: 0.8594\n",
      "Epoch 67/100\n",
      "122/122 [==============================] - 61s 497ms/step - loss: 0.2984 - accuracy: 0.8706 - val_loss: 0.3052 - val_accuracy: 0.8664\n",
      "Epoch 68/100\n",
      "122/122 [==============================] - 59s 487ms/step - loss: 0.2988 - accuracy: 0.8758 - val_loss: 0.3038 - val_accuracy: 0.8687\n",
      "Epoch 69/100\n",
      "122/122 [==============================] - 59s 485ms/step - loss: 0.3008 - accuracy: 0.8694 - val_loss: 0.3117 - val_accuracy: 0.8548\n",
      "Epoch 70/100\n",
      "122/122 [==============================] - 60s 491ms/step - loss: 0.2997 - accuracy: 0.8727 - val_loss: 0.3249 - val_accuracy: 0.8456\n",
      "Epoch 71/100\n",
      "122/122 [==============================] - 61s 497ms/step - loss: 0.2985 - accuracy: 0.8714 - val_loss: 0.3014 - val_accuracy: 0.8687\n",
      "Epoch 72/100\n",
      "122/122 [==============================] - 61s 497ms/step - loss: 0.3002 - accuracy: 0.8683 - val_loss: 0.3182 - val_accuracy: 0.8548\n",
      "Epoch 73/100\n",
      "122/122 [==============================] - 60s 488ms/step - loss: 0.3001 - accuracy: 0.8730 - val_loss: 0.3012 - val_accuracy: 0.8664\n",
      "Epoch 74/100\n",
      "122/122 [==============================] - 61s 503ms/step - loss: 0.2963 - accuracy: 0.8742 - val_loss: 0.3148 - val_accuracy: 0.8594\n",
      "Epoch 75/100\n",
      "122/122 [==============================] - 60s 491ms/step - loss: 0.2916 - accuracy: 0.8755 - val_loss: 0.2971 - val_accuracy: 0.8664\n",
      "Epoch 76/100\n",
      "122/122 [==============================] - 60s 490ms/step - loss: 0.2946 - accuracy: 0.8773 - val_loss: 0.2954 - val_accuracy: 0.8710\n",
      "Epoch 77/100\n",
      "122/122 [==============================] - 59s 484ms/step - loss: 0.2921 - accuracy: 0.8717 - val_loss: 0.3063 - val_accuracy: 0.8571\n",
      "Epoch 78/100\n",
      "122/122 [==============================] - 59s 484ms/step - loss: 0.2941 - accuracy: 0.8730 - val_loss: 0.3056 - val_accuracy: 0.8594\n",
      "Epoch 79/100\n",
      "122/122 [==============================] - 59s 487ms/step - loss: 0.2900 - accuracy: 0.8763 - val_loss: 0.2958 - val_accuracy: 0.8710\n",
      "Epoch 80/100\n",
      "122/122 [==============================] - 60s 491ms/step - loss: 0.2911 - accuracy: 0.8745 - val_loss: 0.3034 - val_accuracy: 0.8618\n",
      "Epoch 81/100\n",
      "122/122 [==============================] - 60s 490ms/step - loss: 0.2907 - accuracy: 0.8719 - val_loss: 0.3150 - val_accuracy: 0.8571\n",
      "Epoch 82/100\n",
      "122/122 [==============================] - 60s 489ms/step - loss: 0.2856 - accuracy: 0.8776 - val_loss: 0.3029 - val_accuracy: 0.8641\n",
      "Epoch 83/100\n",
      "122/122 [==============================] - 59s 482ms/step - loss: 0.2911 - accuracy: 0.8776 - val_loss: 0.2989 - val_accuracy: 0.8687\n",
      "Epoch 84/100\n",
      "122/122 [==============================] - 59s 488ms/step - loss: 0.2914 - accuracy: 0.8727 - val_loss: 0.2997 - val_accuracy: 0.8710\n",
      "Epoch 85/100\n",
      "122/122 [==============================] - 60s 492ms/step - loss: 0.2853 - accuracy: 0.8783 - val_loss: 0.3081 - val_accuracy: 0.8594\n",
      "Epoch 86/100\n",
      "122/122 [==============================] - 59s 485ms/step - loss: 0.2898 - accuracy: 0.8763 - val_loss: 0.2978 - val_accuracy: 0.8687\n",
      "Epoch 87/100\n",
      "122/122 [==============================] - 60s 496ms/step - loss: 0.2869 - accuracy: 0.8786 - val_loss: 0.3064 - val_accuracy: 0.8571\n",
      "Epoch 88/100\n",
      "122/122 [==============================] - 59s 482ms/step - loss: 0.2879 - accuracy: 0.8781 - val_loss: 0.3032 - val_accuracy: 0.8641\n",
      "Epoch 89/100\n",
      "122/122 [==============================] - 60s 491ms/step - loss: 0.2884 - accuracy: 0.8763 - val_loss: 0.2936 - val_accuracy: 0.8687\n",
      "Epoch 90/100\n",
      "122/122 [==============================] - 59s 486ms/step - loss: 0.2878 - accuracy: 0.8760 - val_loss: 0.3052 - val_accuracy: 0.8594\n",
      "Epoch 91/100\n",
      "122/122 [==============================] - 59s 487ms/step - loss: 0.2866 - accuracy: 0.8742 - val_loss: 0.3026 - val_accuracy: 0.8548\n",
      "Epoch 92/100\n",
      "122/122 [==============================] - 60s 491ms/step - loss: 0.2870 - accuracy: 0.8763 - val_loss: 0.3032 - val_accuracy: 0.8548\n",
      "Epoch 93/100\n",
      "122/122 [==============================] - 57s 467ms/step - loss: 0.2864 - accuracy: 0.8788 - val_loss: 0.3116 - val_accuracy: 0.8525\n",
      "Epoch 94/100\n",
      "122/122 [==============================] - 57s 466ms/step - loss: 0.2844 - accuracy: 0.8758 - val_loss: 0.2995 - val_accuracy: 0.8641\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 95/100\n",
      "122/122 [==============================] - 57s 472ms/step - loss: 0.2831 - accuracy: 0.8778 - val_loss: 0.2942 - val_accuracy: 0.8710\n",
      "Epoch 96/100\n",
      "122/122 [==============================] - 54s 440ms/step - loss: 0.2827 - accuracy: 0.8791 - val_loss: 0.3034 - val_accuracy: 0.8571\n",
      "Epoch 97/100\n",
      "122/122 [==============================] - 41s 334ms/step - loss: 0.2840 - accuracy: 0.8765 - val_loss: 0.2974 - val_accuracy: 0.8594\n",
      "Epoch 98/100\n",
      "122/122 [==============================] - 41s 335ms/step - loss: 0.2833 - accuracy: 0.8760 - val_loss: 0.2975 - val_accuracy: 0.8618\n",
      "Epoch 99/100\n",
      "122/122 [==============================] - 41s 334ms/step - loss: 0.2783 - accuracy: 0.8832 - val_loss: 0.2998 - val_accuracy: 0.8571\n",
      "Epoch 100/100\n",
      "122/122 [==============================] - 40s 326ms/step - loss: 0.2816 - accuracy: 0.8791 - val_loss: 0.3046 - val_accuracy: 0.8548\n",
      "WARNING:tensorflow:Layer lstm_283 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Epoch 1/100\n",
      "123/123 [==============================] - 76s 609ms/step - loss: 0.6159 - accuracy: 0.6855 - val_loss: 0.5555 - val_accuracy: 0.7719\n",
      "Epoch 2/100\n",
      "123/123 [==============================] - 75s 611ms/step - loss: 0.5178 - accuracy: 0.7887 - val_loss: 0.4860 - val_accuracy: 0.7995\n",
      "Epoch 3/100\n",
      "123/123 [==============================] - 75s 606ms/step - loss: 0.4577 - accuracy: 0.8072 - val_loss: 0.4521 - val_accuracy: 0.8065\n",
      "Epoch 4/100\n",
      "123/123 [==============================] - 77s 629ms/step - loss: 0.4203 - accuracy: 0.8230 - val_loss: 0.4392 - val_accuracy: 0.8065\n",
      "Epoch 5/100\n",
      "123/123 [==============================] - 76s 616ms/step - loss: 0.4057 - accuracy: 0.8197 - val_loss: 0.4141 - val_accuracy: 0.8088\n",
      "Epoch 6/100\n",
      "123/123 [==============================] - 77s 626ms/step - loss: 0.3933 - accuracy: 0.8225 - val_loss: 0.4158 - val_accuracy: 0.8065\n",
      "Epoch 7/100\n",
      "123/123 [==============================] - 76s 616ms/step - loss: 0.3864 - accuracy: 0.8259 - val_loss: 0.4057 - val_accuracy: 0.8065\n",
      "Epoch 8/100\n",
      "123/123 [==============================] - 76s 615ms/step - loss: 0.3814 - accuracy: 0.8225 - val_loss: 0.3884 - val_accuracy: 0.8226\n",
      "Epoch 9/100\n",
      "123/123 [==============================] - 75s 608ms/step - loss: 0.3733 - accuracy: 0.8318 - val_loss: 0.3711 - val_accuracy: 0.8203\n",
      "Epoch 10/100\n",
      "123/123 [==============================] - 76s 616ms/step - loss: 0.3753 - accuracy: 0.8330 - val_loss: 0.3874 - val_accuracy: 0.8180\n",
      "Epoch 11/100\n",
      "123/123 [==============================] - 76s 622ms/step - loss: 0.3700 - accuracy: 0.8323 - val_loss: 0.4116 - val_accuracy: 0.8041\n",
      "Epoch 12/100\n",
      "123/123 [==============================] - 76s 614ms/step - loss: 0.3679 - accuracy: 0.8333 - val_loss: 0.3873 - val_accuracy: 0.8203\n",
      "Epoch 13/100\n",
      "123/123 [==============================] - 76s 620ms/step - loss: 0.3674 - accuracy: 0.8323 - val_loss: 0.3591 - val_accuracy: 0.8295\n",
      "Epoch 14/100\n",
      "123/123 [==============================] - 76s 617ms/step - loss: 0.3637 - accuracy: 0.8353 - val_loss: 0.3753 - val_accuracy: 0.8295\n",
      "Epoch 15/100\n",
      "123/123 [==============================] - 77s 623ms/step - loss: 0.3589 - accuracy: 0.8379 - val_loss: 0.3686 - val_accuracy: 0.8295\n",
      "Epoch 16/100\n",
      "123/123 [==============================] - 76s 615ms/step - loss: 0.3590 - accuracy: 0.8417 - val_loss: 0.3466 - val_accuracy: 0.8433\n",
      "Epoch 17/100\n",
      "123/123 [==============================] - 75s 614ms/step - loss: 0.3555 - accuracy: 0.8387 - val_loss: 0.3397 - val_accuracy: 0.8456\n",
      "Epoch 18/100\n",
      "123/123 [==============================] - 76s 615ms/step - loss: 0.3528 - accuracy: 0.8412 - val_loss: 0.3445 - val_accuracy: 0.8364\n",
      "Epoch 19/100\n",
      "123/123 [==============================] - 76s 621ms/step - loss: 0.3496 - accuracy: 0.8435 - val_loss: 0.3373 - val_accuracy: 0.8456\n",
      "Epoch 20/100\n",
      "123/123 [==============================] - 74s 604ms/step - loss: 0.3470 - accuracy: 0.8446 - val_loss: 0.3517 - val_accuracy: 0.8364\n",
      "Epoch 21/100\n",
      "123/123 [==============================] - 78s 635ms/step - loss: 0.3471 - accuracy: 0.8476 - val_loss: 0.3596 - val_accuracy: 0.8341\n",
      "Epoch 22/100\n",
      "123/123 [==============================] - 75s 607ms/step - loss: 0.3448 - accuracy: 0.8458 - val_loss: 0.3498 - val_accuracy: 0.8341\n",
      "Epoch 23/100\n",
      "123/123 [==============================] - 75s 610ms/step - loss: 0.3444 - accuracy: 0.8466 - val_loss: 0.3256 - val_accuracy: 0.8502\n",
      "Epoch 24/100\n",
      "123/123 [==============================] - 75s 611ms/step - loss: 0.3418 - accuracy: 0.8471 - val_loss: 0.3233 - val_accuracy: 0.8571\n",
      "Epoch 25/100\n",
      "123/123 [==============================] - 76s 619ms/step - loss: 0.3421 - accuracy: 0.8453 - val_loss: 0.3442 - val_accuracy: 0.8433\n",
      "Epoch 26/100\n",
      "123/123 [==============================] - 74s 604ms/step - loss: 0.3410 - accuracy: 0.8474 - val_loss: 0.3332 - val_accuracy: 0.8479\n",
      "Epoch 27/100\n",
      "123/123 [==============================] - 76s 622ms/step - loss: 0.3399 - accuracy: 0.8504 - val_loss: 0.3205 - val_accuracy: 0.8594\n",
      "Epoch 28/100\n",
      "123/123 [==============================] - 75s 606ms/step - loss: 0.3360 - accuracy: 0.8538 - val_loss: 0.3194 - val_accuracy: 0.8641\n",
      "Epoch 29/100\n",
      "123/123 [==============================] - 76s 618ms/step - loss: 0.3349 - accuracy: 0.8533 - val_loss: 0.3365 - val_accuracy: 0.8433\n",
      "Epoch 30/100\n",
      "123/123 [==============================] - 76s 614ms/step - loss: 0.3363 - accuracy: 0.8528 - val_loss: 0.3295 - val_accuracy: 0.8502\n",
      "Epoch 31/100\n",
      "123/123 [==============================] - 78s 634ms/step - loss: 0.3314 - accuracy: 0.8553 - val_loss: 0.3244 - val_accuracy: 0.8594\n",
      "Epoch 32/100\n",
      "123/123 [==============================] - 76s 616ms/step - loss: 0.3318 - accuracy: 0.8510 - val_loss: 0.3395 - val_accuracy: 0.8456\n",
      "Epoch 33/100\n",
      "123/123 [==============================] - 78s 630ms/step - loss: 0.3302 - accuracy: 0.8563 - val_loss: 0.3232 - val_accuracy: 0.8571\n",
      "Epoch 34/100\n",
      "123/123 [==============================] - 73s 596ms/step - loss: 0.3274 - accuracy: 0.8556 - val_loss: 0.3191 - val_accuracy: 0.8618\n",
      "Epoch 35/100\n",
      "123/123 [==============================] - 79s 638ms/step - loss: 0.3299 - accuracy: 0.8484 - val_loss: 0.3097 - val_accuracy: 0.8710\n",
      "Epoch 36/100\n",
      "123/123 [==============================] - 74s 599ms/step - loss: 0.3216 - accuracy: 0.8594 - val_loss: 0.3296 - val_accuracy: 0.8525\n",
      "Epoch 37/100\n",
      "123/123 [==============================] - 76s 617ms/step - loss: 0.3236 - accuracy: 0.8535 - val_loss: 0.3129 - val_accuracy: 0.8710\n",
      "Epoch 38/100\n",
      "123/123 [==============================] - 73s 592ms/step - loss: 0.3233 - accuracy: 0.8620 - val_loss: 0.3046 - val_accuracy: 0.8687\n",
      "Epoch 39/100\n",
      "123/123 [==============================] - 77s 630ms/step - loss: 0.3236 - accuracy: 0.8566 - val_loss: 0.3024 - val_accuracy: 0.8664\n",
      "Epoch 40/100\n",
      "123/123 [==============================] - 75s 608ms/step - loss: 0.3217 - accuracy: 0.8604 - val_loss: 0.3028 - val_accuracy: 0.8756\n",
      "Epoch 41/100\n",
      "123/123 [==============================] - 78s 636ms/step - loss: 0.3245 - accuracy: 0.8627 - val_loss: 0.3041 - val_accuracy: 0.8756\n",
      "Epoch 42/100\n",
      "123/123 [==============================] - 75s 607ms/step - loss: 0.3224 - accuracy: 0.8569 - val_loss: 0.3114 - val_accuracy: 0.8664\n",
      "Epoch 43/100\n",
      "123/123 [==============================] - 77s 624ms/step - loss: 0.3226 - accuracy: 0.8569 - val_loss: 0.3101 - val_accuracy: 0.8618\n",
      "Epoch 44/100\n",
      "123/123 [==============================] - 76s 617ms/step - loss: 0.3195 - accuracy: 0.8617 - val_loss: 0.3186 - val_accuracy: 0.8618\n",
      "Epoch 45/100\n",
      "123/123 [==============================] - 76s 621ms/step - loss: 0.3168 - accuracy: 0.8673 - val_loss: 0.3196 - val_accuracy: 0.8594\n",
      "Epoch 46/100\n",
      "123/123 [==============================] - 76s 614ms/step - loss: 0.3168 - accuracy: 0.8609 - val_loss: 0.3146 - val_accuracy: 0.8618\n",
      "Epoch 47/100\n",
      "123/123 [==============================] - 77s 624ms/step - loss: 0.3150 - accuracy: 0.8645 - val_loss: 0.3042 - val_accuracy: 0.8756\n",
      "Epoch 48/100\n",
      "123/123 [==============================] - 77s 625ms/step - loss: 0.3164 - accuracy: 0.8622 - val_loss: 0.3088 - val_accuracy: 0.8618\n",
      "Epoch 49/100\n",
      "123/123 [==============================] - 76s 620ms/step - loss: 0.3128 - accuracy: 0.8604 - val_loss: 0.3046 - val_accuracy: 0.8641\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/100\n",
      "123/123 [==============================] - 75s 611ms/step - loss: 0.3170 - accuracy: 0.8620 - val_loss: 0.3016 - val_accuracy: 0.8687\n",
      "Epoch 51/100\n",
      "123/123 [==============================] - 78s 631ms/step - loss: 0.3163 - accuracy: 0.8625 - val_loss: 0.3014 - val_accuracy: 0.8664\n",
      "Epoch 52/100\n",
      "123/123 [==============================] - 74s 604ms/step - loss: 0.3155 - accuracy: 0.8676 - val_loss: 0.2966 - val_accuracy: 0.8664\n",
      "Epoch 53/100\n",
      "123/123 [==============================] - 76s 616ms/step - loss: 0.3104 - accuracy: 0.8653 - val_loss: 0.3069 - val_accuracy: 0.8618\n",
      "Epoch 54/100\n",
      "123/123 [==============================] - 74s 605ms/step - loss: 0.3093 - accuracy: 0.8638 - val_loss: 0.3113 - val_accuracy: 0.8641\n",
      "Epoch 55/100\n",
      "123/123 [==============================] - 76s 614ms/step - loss: 0.3102 - accuracy: 0.8663 - val_loss: 0.2968 - val_accuracy: 0.8664\n",
      "Epoch 56/100\n",
      "123/123 [==============================] - 75s 613ms/step - loss: 0.3088 - accuracy: 0.8689 - val_loss: 0.2955 - val_accuracy: 0.8664\n",
      "Epoch 57/100\n",
      "123/123 [==============================] - 74s 600ms/step - loss: 0.3101 - accuracy: 0.8650 - val_loss: 0.2990 - val_accuracy: 0.8664\n",
      "Epoch 58/100\n",
      "123/123 [==============================] - 75s 614ms/step - loss: 0.3055 - accuracy: 0.8679 - val_loss: 0.2980 - val_accuracy: 0.8687\n",
      "Epoch 59/100\n",
      "123/123 [==============================] - 75s 611ms/step - loss: 0.3101 - accuracy: 0.8648 - val_loss: 0.2891 - val_accuracy: 0.8779\n",
      "Epoch 60/100\n",
      "123/123 [==============================] - 77s 630ms/step - loss: 0.3087 - accuracy: 0.8645 - val_loss: 0.3048 - val_accuracy: 0.8594\n",
      "Epoch 61/100\n",
      "123/123 [==============================] - 73s 596ms/step - loss: 0.3078 - accuracy: 0.8699 - val_loss: 0.3022 - val_accuracy: 0.8756\n",
      "Epoch 62/100\n",
      "123/123 [==============================] - 76s 617ms/step - loss: 0.3015 - accuracy: 0.8650 - val_loss: 0.2886 - val_accuracy: 0.8779\n",
      "Epoch 63/100\n",
      "123/123 [==============================] - 77s 627ms/step - loss: 0.3091 - accuracy: 0.8668 - val_loss: 0.4666 - val_accuracy: 0.7765\n",
      "Epoch 64/100\n",
      "123/123 [==============================] - 75s 613ms/step - loss: 0.3067 - accuracy: 0.8648 - val_loss: 0.2884 - val_accuracy: 0.8710\n",
      "Epoch 65/100\n",
      "123/123 [==============================] - 73s 594ms/step - loss: 0.3051 - accuracy: 0.8622 - val_loss: 0.2997 - val_accuracy: 0.8687\n",
      "Epoch 66/100\n",
      "123/123 [==============================] - 75s 612ms/step - loss: 0.3011 - accuracy: 0.8707 - val_loss: 0.3137 - val_accuracy: 0.8687\n",
      "Epoch 67/100\n",
      "123/123 [==============================] - 75s 606ms/step - loss: 0.3036 - accuracy: 0.8691 - val_loss: 0.2897 - val_accuracy: 0.8710\n",
      "Epoch 68/100\n",
      "123/123 [==============================] - 75s 609ms/step - loss: 0.2991 - accuracy: 0.8745 - val_loss: 0.3001 - val_accuracy: 0.8641\n",
      "Epoch 69/100\n",
      "123/123 [==============================] - 75s 609ms/step - loss: 0.2997 - accuracy: 0.8691 - val_loss: 0.3003 - val_accuracy: 0.8618\n",
      "Epoch 70/100\n",
      "123/123 [==============================] - 75s 610ms/step - loss: 0.2965 - accuracy: 0.8745 - val_loss: 0.2881 - val_accuracy: 0.8848\n",
      "Epoch 71/100\n",
      "123/123 [==============================] - 74s 601ms/step - loss: 0.2995 - accuracy: 0.8717 - val_loss: 0.3465 - val_accuracy: 0.8341\n",
      "Epoch 72/100\n",
      "123/123 [==============================] - 78s 630ms/step - loss: 0.2975 - accuracy: 0.8730 - val_loss: 0.2950 - val_accuracy: 0.8687\n",
      "Epoch 73/100\n",
      "123/123 [==============================] - 74s 599ms/step - loss: 0.2977 - accuracy: 0.8691 - val_loss: 0.2848 - val_accuracy: 0.8687\n",
      "Epoch 74/100\n",
      "123/123 [==============================] - 78s 634ms/step - loss: 0.2975 - accuracy: 0.8740 - val_loss: 0.3319 - val_accuracy: 0.8479\n",
      "Epoch 75/100\n",
      "123/123 [==============================] - 75s 608ms/step - loss: 0.2976 - accuracy: 0.8717 - val_loss: 0.2888 - val_accuracy: 0.8756\n",
      "Epoch 76/100\n",
      "123/123 [==============================] - 77s 623ms/step - loss: 0.2974 - accuracy: 0.8725 - val_loss: 0.5936 - val_accuracy: 0.7212\n",
      "Epoch 77/100\n",
      "123/123 [==============================] - 72s 587ms/step - loss: 0.3037 - accuracy: 0.8689 - val_loss: 0.2844 - val_accuracy: 0.8687\n",
      "Epoch 78/100\n",
      "123/123 [==============================] - 76s 620ms/step - loss: 0.2936 - accuracy: 0.8720 - val_loss: 0.2861 - val_accuracy: 0.8710\n",
      "Epoch 79/100\n",
      "123/123 [==============================] - 75s 606ms/step - loss: 0.2941 - accuracy: 0.8725 - val_loss: 0.2831 - val_accuracy: 0.8733\n",
      "Epoch 80/100\n",
      "123/123 [==============================] - 75s 611ms/step - loss: 0.2906 - accuracy: 0.8738 - val_loss: 0.2867 - val_accuracy: 0.8756\n",
      "Epoch 81/100\n",
      "123/123 [==============================] - 75s 613ms/step - loss: 0.2896 - accuracy: 0.8758 - val_loss: 0.2916 - val_accuracy: 0.8641\n",
      "Epoch 82/100\n",
      "123/123 [==============================] - 75s 612ms/step - loss: 0.2931 - accuracy: 0.8771 - val_loss: 0.2914 - val_accuracy: 0.8779\n",
      "Epoch 83/100\n",
      "123/123 [==============================] - 74s 604ms/step - loss: 0.2929 - accuracy: 0.8702 - val_loss: 0.2943 - val_accuracy: 0.8687\n",
      "Epoch 84/100\n",
      "123/123 [==============================] - 77s 623ms/step - loss: 0.2869 - accuracy: 0.8809 - val_loss: 0.2956 - val_accuracy: 0.8618\n",
      "Epoch 85/100\n",
      "123/123 [==============================] - 75s 608ms/step - loss: 0.2903 - accuracy: 0.8755 - val_loss: 0.2794 - val_accuracy: 0.8687\n",
      "Epoch 86/100\n",
      "123/123 [==============================] - 73s 597ms/step - loss: 0.2826 - accuracy: 0.8784 - val_loss: 0.2794 - val_accuracy: 0.8710\n",
      "Epoch 87/100\n",
      "123/123 [==============================] - 77s 623ms/step - loss: 0.2881 - accuracy: 0.8755 - val_loss: 0.2783 - val_accuracy: 0.8756\n",
      "Epoch 88/100\n",
      "123/123 [==============================] - 74s 600ms/step - loss: 0.2921 - accuracy: 0.8709 - val_loss: 0.3057 - val_accuracy: 0.8618\n",
      "Epoch 89/100\n",
      "123/123 [==============================] - 75s 610ms/step - loss: 0.2912 - accuracy: 0.8773 - val_loss: 0.2847 - val_accuracy: 0.8756\n",
      "Epoch 90/100\n",
      "123/123 [==============================] - 75s 610ms/step - loss: 0.2824 - accuracy: 0.8814 - val_loss: 0.2826 - val_accuracy: 0.8756\n",
      "Epoch 91/100\n",
      "123/123 [==============================] - 83s 677ms/step - loss: 0.2822 - accuracy: 0.8791 - val_loss: 0.2836 - val_accuracy: 0.8733\n",
      "Epoch 92/100\n",
      "123/123 [==============================] - 106s 866ms/step - loss: 0.2815 - accuracy: 0.8807 - val_loss: 0.2834 - val_accuracy: 0.8710\n",
      "Epoch 93/100\n",
      "123/123 [==============================] - 105s 857ms/step - loss: 0.2858 - accuracy: 0.8789 - val_loss: 0.2835 - val_accuracy: 0.8710\n",
      "Epoch 94/100\n",
      "123/123 [==============================] - 105s 854ms/step - loss: 0.2835 - accuracy: 0.8784 - val_loss: 0.2833 - val_accuracy: 0.8687\n",
      "Epoch 95/100\n",
      "123/123 [==============================] - 104s 843ms/step - loss: 0.2831 - accuracy: 0.8771 - val_loss: 0.2963 - val_accuracy: 0.8641\n",
      "Epoch 96/100\n",
      "123/123 [==============================] - 106s 861ms/step - loss: 0.2801 - accuracy: 0.8807 - val_loss: 0.2837 - val_accuracy: 0.8779\n",
      "Epoch 97/100\n",
      "123/123 [==============================] - 107s 866ms/step - loss: 0.2813 - accuracy: 0.8784 - val_loss: 0.2798 - val_accuracy: 0.8756\n",
      "Epoch 98/100\n",
      "123/123 [==============================] - 105s 858ms/step - loss: 0.2812 - accuracy: 0.8822 - val_loss: 0.2783 - val_accuracy: 0.8802\n",
      "Epoch 99/100\n",
      "123/123 [==============================] - 104s 845ms/step - loss: 0.2810 - accuracy: 0.8789 - val_loss: 0.2789 - val_accuracy: 0.8756\n",
      "Epoch 100/100\n",
      "123/123 [==============================] - 107s 872ms/step - loss: 0.2791 - accuracy: 0.8817 - val_loss: 0.2789 - val_accuracy: 0.8756\n",
      "WARNING:tensorflow:Layer lstm_284 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Epoch 1/100\n",
      "123/123 [==============================] - 110s 882ms/step - loss: 0.6215 - accuracy: 0.6561 - val_loss: 0.5794 - val_accuracy: 0.7834\n",
      "Epoch 2/100\n",
      "123/123 [==============================] - 107s 869ms/step - loss: 0.5296 - accuracy: 0.7915 - val_loss: 0.5033 - val_accuracy: 0.7972\n",
      "Epoch 3/100\n",
      "123/123 [==============================] - 107s 869ms/step - loss: 0.4595 - accuracy: 0.8218 - val_loss: 0.4600 - val_accuracy: 0.7972\n",
      "Epoch 4/100\n",
      "123/123 [==============================] - 107s 869ms/step - loss: 0.4158 - accuracy: 0.8261 - val_loss: 0.4318 - val_accuracy: 0.8111\n",
      "Epoch 5/100\n",
      "123/123 [==============================] - 109s 888ms/step - loss: 0.3939 - accuracy: 0.8259 - val_loss: 0.4136 - val_accuracy: 0.8157\n",
      "Epoch 6/100\n",
      "123/123 [==============================] - 108s 879ms/step - loss: 0.3773 - accuracy: 0.8318 - val_loss: 0.4053 - val_accuracy: 0.8134\n",
      "Epoch 7/100\n",
      "123/123 [==============================] - 107s 871ms/step - loss: 0.3682 - accuracy: 0.8364 - val_loss: 0.4084 - val_accuracy: 0.8065\n",
      "Epoch 8/100\n",
      "123/123 [==============================] - 107s 870ms/step - loss: 0.3621 - accuracy: 0.8389 - val_loss: 0.3998 - val_accuracy: 0.8088\n",
      "Epoch 9/100\n",
      "123/123 [==============================] - 108s 875ms/step - loss: 0.3560 - accuracy: 0.8392 - val_loss: 0.3908 - val_accuracy: 0.8410\n",
      "Epoch 10/100\n",
      "123/123 [==============================] - 107s 872ms/step - loss: 0.3526 - accuracy: 0.8389 - val_loss: 0.3946 - val_accuracy: 0.8088\n",
      "Epoch 11/100\n",
      "123/123 [==============================] - 108s 875ms/step - loss: 0.3481 - accuracy: 0.8423 - val_loss: 0.4146 - val_accuracy: 0.8018\n",
      "Epoch 12/100\n",
      "123/123 [==============================] - 106s 859ms/step - loss: 0.3462 - accuracy: 0.8425 - val_loss: 0.3928 - val_accuracy: 0.8111\n",
      "Epoch 13/100\n",
      "123/123 [==============================] - 107s 871ms/step - loss: 0.3434 - accuracy: 0.8456 - val_loss: 0.3854 - val_accuracy: 0.8433\n",
      "Epoch 14/100\n",
      "123/123 [==============================] - 91s 736ms/step - loss: 0.3392 - accuracy: 0.8479 - val_loss: 0.3854 - val_accuracy: 0.8456\n",
      "Epoch 15/100\n",
      "123/123 [==============================] - 77s 630ms/step - loss: 0.3389 - accuracy: 0.8471 - val_loss: 0.3840 - val_accuracy: 0.8295\n",
      "Epoch 16/100\n",
      "123/123 [==============================] - 74s 606ms/step - loss: 0.3358 - accuracy: 0.8504 - val_loss: 0.3896 - val_accuracy: 0.8203\n",
      "Epoch 17/100\n",
      "123/123 [==============================] - 78s 632ms/step - loss: 0.3328 - accuracy: 0.8520 - val_loss: 0.3927 - val_accuracy: 0.8203\n",
      "Epoch 18/100\n",
      "123/123 [==============================] - 74s 600ms/step - loss: 0.3328 - accuracy: 0.8535 - val_loss: 0.3856 - val_accuracy: 0.8226\n",
      "Epoch 19/100\n",
      "123/123 [==============================] - 78s 630ms/step - loss: 0.3299 - accuracy: 0.8548 - val_loss: 0.3810 - val_accuracy: 0.8272\n",
      "Epoch 20/100\n",
      "123/123 [==============================] - 75s 611ms/step - loss: 0.3268 - accuracy: 0.8548 - val_loss: 0.3822 - val_accuracy: 0.8249\n",
      "Epoch 21/100\n",
      "123/123 [==============================] - 77s 628ms/step - loss: 0.3248 - accuracy: 0.8607 - val_loss: 0.3873 - val_accuracy: 0.8295\n",
      "Epoch 22/100\n",
      "123/123 [==============================] - 76s 619ms/step - loss: 0.3281 - accuracy: 0.8576 - val_loss: 0.3816 - val_accuracy: 0.8295\n",
      "Epoch 23/100\n",
      "123/123 [==============================] - 77s 627ms/step - loss: 0.3200 - accuracy: 0.8556 - val_loss: 0.3762 - val_accuracy: 0.8479\n",
      "Epoch 24/100\n",
      "123/123 [==============================] - 77s 625ms/step - loss: 0.3216 - accuracy: 0.8627 - val_loss: 0.3760 - val_accuracy: 0.8525\n",
      "Epoch 25/100\n",
      "123/123 [==============================] - 78s 631ms/step - loss: 0.3242 - accuracy: 0.8581 - val_loss: 0.4040 - val_accuracy: 0.8134\n",
      "Epoch 26/100\n",
      "123/123 [==============================] - 76s 620ms/step - loss: 0.3184 - accuracy: 0.8645 - val_loss: 0.3929 - val_accuracy: 0.8249\n",
      "Epoch 27/100\n",
      "123/123 [==============================] - 76s 617ms/step - loss: 0.3223 - accuracy: 0.8584 - val_loss: 0.3764 - val_accuracy: 0.8387\n",
      "Epoch 28/100\n",
      "123/123 [==============================] - 76s 620ms/step - loss: 0.3153 - accuracy: 0.8656 - val_loss: 0.3745 - val_accuracy: 0.8387\n",
      "Epoch 29/100\n",
      "123/123 [==============================] - 76s 618ms/step - loss: 0.3178 - accuracy: 0.8643 - val_loss: 0.3724 - val_accuracy: 0.8479\n",
      "Epoch 30/100\n",
      "123/123 [==============================] - 77s 623ms/step - loss: 0.3143 - accuracy: 0.8622 - val_loss: 0.3823 - val_accuracy: 0.8341\n",
      "Epoch 31/100\n",
      "123/123 [==============================] - 78s 631ms/step - loss: 0.3159 - accuracy: 0.8643 - val_loss: 0.3723 - val_accuracy: 0.8456\n",
      "Epoch 32/100\n",
      "123/123 [==============================] - 75s 613ms/step - loss: 0.3124 - accuracy: 0.8666 - val_loss: 0.3738 - val_accuracy: 0.8502\n",
      "Epoch 33/100\n",
      "123/123 [==============================] - 77s 624ms/step - loss: 0.3142 - accuracy: 0.8635 - val_loss: 0.3724 - val_accuracy: 0.8479\n",
      "Epoch 34/100\n",
      "123/123 [==============================] - 78s 635ms/step - loss: 0.3107 - accuracy: 0.8686 - val_loss: 0.3779 - val_accuracy: 0.8410\n",
      "Epoch 35/100\n",
      "123/123 [==============================] - 77s 623ms/step - loss: 0.3110 - accuracy: 0.8658 - val_loss: 0.3740 - val_accuracy: 0.8410\n",
      "Epoch 36/100\n",
      "123/123 [==============================] - 75s 610ms/step - loss: 0.3096 - accuracy: 0.8717 - val_loss: 0.3727 - val_accuracy: 0.8502\n",
      "Epoch 37/100\n",
      "123/123 [==============================] - 78s 632ms/step - loss: 0.3096 - accuracy: 0.8673 - val_loss: 0.3731 - val_accuracy: 0.8456\n",
      "Epoch 38/100\n",
      "123/123 [==============================] - 75s 609ms/step - loss: 0.3067 - accuracy: 0.8686 - val_loss: 0.4096 - val_accuracy: 0.8157\n",
      "Epoch 39/100\n",
      "123/123 [==============================] - 78s 634ms/step - loss: 0.3065 - accuracy: 0.8707 - val_loss: 0.4395 - val_accuracy: 0.8065\n",
      "Epoch 40/100\n",
      "123/123 [==============================] - 76s 616ms/step - loss: 0.3081 - accuracy: 0.8684 - val_loss: 0.4211 - val_accuracy: 0.7995\n",
      "Epoch 41/100\n",
      "123/123 [==============================] - 77s 626ms/step - loss: 0.3119 - accuracy: 0.8668 - val_loss: 0.3717 - val_accuracy: 0.8479\n",
      "Epoch 42/100\n",
      "123/123 [==============================] - 75s 612ms/step - loss: 0.3038 - accuracy: 0.8735 - val_loss: 0.3729 - val_accuracy: 0.8456\n",
      "Epoch 43/100\n",
      "123/123 [==============================] - 76s 618ms/step - loss: 0.3014 - accuracy: 0.8725 - val_loss: 0.3884 - val_accuracy: 0.8318\n",
      "Epoch 44/100\n",
      "123/123 [==============================] - 76s 622ms/step - loss: 0.3035 - accuracy: 0.8714 - val_loss: 0.3725 - val_accuracy: 0.8456\n",
      "Epoch 45/100\n",
      "123/123 [==============================] - 78s 636ms/step - loss: 0.3017 - accuracy: 0.8671 - val_loss: 0.3790 - val_accuracy: 0.8433\n",
      "Epoch 46/100\n",
      "123/123 [==============================] - 77s 627ms/step - loss: 0.3006 - accuracy: 0.8722 - val_loss: 0.3725 - val_accuracy: 0.8479\n",
      "Epoch 47/100\n",
      "123/123 [==============================] - 75s 610ms/step - loss: 0.3027 - accuracy: 0.8727 - val_loss: 0.3703 - val_accuracy: 0.8341\n",
      "Epoch 48/100\n",
      "123/123 [==============================] - 77s 630ms/step - loss: 0.3009 - accuracy: 0.8727 - val_loss: 0.3731 - val_accuracy: 0.8272\n",
      "Epoch 49/100\n",
      "123/123 [==============================] - 76s 621ms/step - loss: 0.2923 - accuracy: 0.8771 - val_loss: 0.3735 - val_accuracy: 0.8502\n",
      "Epoch 50/100\n",
      "123/123 [==============================] - 77s 628ms/step - loss: 0.2979 - accuracy: 0.8794 - val_loss: 0.3761 - val_accuracy: 0.8456\n",
      "Epoch 51/100\n",
      "123/123 [==============================] - 76s 620ms/step - loss: 0.2984 - accuracy: 0.8745 - val_loss: 0.3750 - val_accuracy: 0.8502\n",
      "Epoch 52/100\n",
      "123/123 [==============================] - 76s 620ms/step - loss: 0.2994 - accuracy: 0.8784 - val_loss: 0.3721 - val_accuracy: 0.8410\n",
      "Epoch 53/100\n",
      "123/123 [==============================] - 75s 611ms/step - loss: 0.2948 - accuracy: 0.8748 - val_loss: 0.3726 - val_accuracy: 0.8410\n",
      "Epoch 54/100\n",
      "123/123 [==============================] - 77s 627ms/step - loss: 0.2962 - accuracy: 0.8732 - val_loss: 0.3732 - val_accuracy: 0.8502\n",
      "Epoch 55/100\n",
      "123/123 [==============================] - 76s 617ms/step - loss: 0.2950 - accuracy: 0.8761 - val_loss: 0.3787 - val_accuracy: 0.8456\n",
      "Epoch 56/100\n",
      "123/123 [==============================] - 78s 636ms/step - loss: 0.2956 - accuracy: 0.8722 - val_loss: 0.3879 - val_accuracy: 0.8456\n",
      "Epoch 57/100\n",
      "123/123 [==============================] - 78s 636ms/step - loss: 0.2935 - accuracy: 0.8804 - val_loss: 0.3802 - val_accuracy: 0.8479\n",
      "Epoch 58/100\n",
      "123/123 [==============================] - 77s 628ms/step - loss: 0.2894 - accuracy: 0.8807 - val_loss: 0.3802 - val_accuracy: 0.8456\n",
      "Epoch 59/100\n",
      "123/123 [==============================] - 75s 611ms/step - loss: 0.2888 - accuracy: 0.8812 - val_loss: 0.3752 - val_accuracy: 0.8364\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60/100\n",
      "123/123 [==============================] - 76s 619ms/step - loss: 0.2920 - accuracy: 0.8748 - val_loss: 0.3727 - val_accuracy: 0.8410\n",
      "Epoch 61/100\n",
      "123/123 [==============================] - 76s 620ms/step - loss: 0.2918 - accuracy: 0.8771 - val_loss: 0.3772 - val_accuracy: 0.8502\n",
      "Epoch 62/100\n",
      "123/123 [==============================] - 77s 624ms/step - loss: 0.2958 - accuracy: 0.8773 - val_loss: 0.3829 - val_accuracy: 0.8433\n",
      "Epoch 63/100\n",
      "123/123 [==============================] - 77s 627ms/step - loss: 0.2862 - accuracy: 0.8825 - val_loss: 0.3794 - val_accuracy: 0.8502\n",
      "Epoch 64/100\n",
      "123/123 [==============================] - 78s 631ms/step - loss: 0.2922 - accuracy: 0.8763 - val_loss: 0.3787 - val_accuracy: 0.8502\n",
      "Epoch 65/100\n",
      "123/123 [==============================] - 74s 605ms/step - loss: 0.2917 - accuracy: 0.8776 - val_loss: 0.3758 - val_accuracy: 0.8502\n",
      "Epoch 66/100\n",
      "123/123 [==============================] - 78s 637ms/step - loss: 0.2899 - accuracy: 0.8814 - val_loss: 0.3711 - val_accuracy: 0.8364\n",
      "Epoch 67/100\n",
      "123/123 [==============================] - 75s 609ms/step - loss: 0.2906 - accuracy: 0.8732 - val_loss: 0.4103 - val_accuracy: 0.8295\n",
      "WARNING:tensorflow:Layer lstm_285 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Epoch 1/100\n",
      "122/122 [==============================] - 41s 324ms/step - loss: 0.3680 - accuracy: 0.8348 - val_loss: 0.3189 - val_accuracy: 0.8571\n",
      "Epoch 2/100\n",
      "122/122 [==============================] - 40s 324ms/step - loss: 0.3296 - accuracy: 0.8568 - val_loss: 0.3156 - val_accuracy: 0.8479\n",
      "Epoch 3/100\n",
      "122/122 [==============================] - 39s 320ms/step - loss: 0.3133 - accuracy: 0.8617 - val_loss: 0.3168 - val_accuracy: 0.8594\n",
      "Epoch 4/100\n",
      "122/122 [==============================] - 39s 318ms/step - loss: 0.2964 - accuracy: 0.8706 - val_loss: 0.3005 - val_accuracy: 0.8641\n",
      "Epoch 5/100\n",
      "122/122 [==============================] - 39s 317ms/step - loss: 0.2832 - accuracy: 0.8814 - val_loss: 0.3036 - val_accuracy: 0.8664\n",
      "Epoch 6/100\n",
      "122/122 [==============================] - 39s 317ms/step - loss: 0.2619 - accuracy: 0.8850 - val_loss: 0.2870 - val_accuracy: 0.8687\n",
      "Epoch 7/100\n",
      "122/122 [==============================] - 40s 325ms/step - loss: 0.2482 - accuracy: 0.8940 - val_loss: 0.3110 - val_accuracy: 0.8548\n",
      "Epoch 8/100\n",
      "122/122 [==============================] - 39s 321ms/step - loss: 0.2343 - accuracy: 0.9016 - val_loss: 0.2988 - val_accuracy: 0.8641\n",
      "Epoch 9/100\n",
      "122/122 [==============================] - 39s 321ms/step - loss: 0.2143 - accuracy: 0.9070 - val_loss: 0.2967 - val_accuracy: 0.8641\n",
      "Epoch 10/100\n",
      "122/122 [==============================] - 38s 314ms/step - loss: 0.1941 - accuracy: 0.9183 - val_loss: 0.3173 - val_accuracy: 0.8594\n",
      "Epoch 11/100\n",
      "122/122 [==============================] - 41s 337ms/step - loss: 0.1794 - accuracy: 0.9265 - val_loss: 0.3464 - val_accuracy: 0.8594\n",
      "Epoch 12/100\n",
      "122/122 [==============================] - 39s 318ms/step - loss: 0.1639 - accuracy: 0.9293 - val_loss: 0.3793 - val_accuracy: 0.8479\n",
      "Epoch 13/100\n",
      "122/122 [==============================] - 39s 319ms/step - loss: 0.1475 - accuracy: 0.9367 - val_loss: 0.3154 - val_accuracy: 0.8802\n",
      "Epoch 14/100\n",
      "122/122 [==============================] - 37s 306ms/step - loss: 0.1391 - accuracy: 0.9403 - val_loss: 0.3483 - val_accuracy: 0.8618\n",
      "Epoch 15/100\n",
      "122/122 [==============================] - 39s 317ms/step - loss: 0.1230 - accuracy: 0.9488 - val_loss: 0.4013 - val_accuracy: 0.8548\n",
      "Epoch 16/100\n",
      "122/122 [==============================] - 38s 310ms/step - loss: 0.1133 - accuracy: 0.9539 - val_loss: 0.3682 - val_accuracy: 0.8618\n",
      "Epoch 17/100\n",
      "122/122 [==============================] - 38s 311ms/step - loss: 0.1021 - accuracy: 0.9598 - val_loss: 0.3611 - val_accuracy: 0.8525\n",
      "Epoch 18/100\n",
      "122/122 [==============================] - 38s 310ms/step - loss: 0.0901 - accuracy: 0.9629 - val_loss: 0.4290 - val_accuracy: 0.8387\n",
      "Epoch 19/100\n",
      "122/122 [==============================] - 38s 309ms/step - loss: 0.0937 - accuracy: 0.9639 - val_loss: 0.4178 - val_accuracy: 0.8479\n",
      "Epoch 20/100\n",
      "122/122 [==============================] - 37s 300ms/step - loss: 0.0837 - accuracy: 0.9639 - val_loss: 0.4085 - val_accuracy: 0.8548\n",
      "Epoch 21/100\n",
      "122/122 [==============================] - 37s 306ms/step - loss: 0.0752 - accuracy: 0.9708 - val_loss: 0.4855 - val_accuracy: 0.8433\n",
      "Epoch 22/100\n",
      "122/122 [==============================] - 37s 306ms/step - loss: 0.0747 - accuracy: 0.9703 - val_loss: 0.4804 - val_accuracy: 0.8479\n",
      "Epoch 23/100\n",
      "122/122 [==============================] - 37s 303ms/step - loss: 0.0639 - accuracy: 0.9731 - val_loss: 0.4665 - val_accuracy: 0.8433\n",
      "Epoch 24/100\n",
      "122/122 [==============================] - 38s 308ms/step - loss: 0.0629 - accuracy: 0.9739 - val_loss: 0.5184 - val_accuracy: 0.8433\n",
      "Epoch 25/100\n",
      "122/122 [==============================] - 37s 307ms/step - loss: 0.0524 - accuracy: 0.9775 - val_loss: 0.4555 - val_accuracy: 0.8664\n",
      "Epoch 26/100\n",
      "122/122 [==============================] - 39s 317ms/step - loss: 0.0513 - accuracy: 0.9803 - val_loss: 0.4805 - val_accuracy: 0.8525\n",
      "WARNING:tensorflow:Layer lstm_286 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Epoch 1/100\n",
      "123/123 [==============================] - 80s 626ms/step - loss: 0.3783 - accuracy: 0.8241 - val_loss: 0.3080 - val_accuracy: 0.8502\n",
      "Epoch 2/100\n",
      "123/123 [==============================] - 74s 606ms/step - loss: 0.3386 - accuracy: 0.8497 - val_loss: 0.2842 - val_accuracy: 0.8687\n",
      "Epoch 3/100\n",
      "123/123 [==============================] - 75s 610ms/step - loss: 0.3126 - accuracy: 0.8594 - val_loss: 0.3058 - val_accuracy: 0.8525\n",
      "Epoch 4/100\n",
      "123/123 [==============================] - 75s 612ms/step - loss: 0.2948 - accuracy: 0.8697 - val_loss: 0.3270 - val_accuracy: 0.8502\n",
      "Epoch 5/100\n",
      "123/123 [==============================] - 76s 621ms/step - loss: 0.2787 - accuracy: 0.8804 - val_loss: 0.2910 - val_accuracy: 0.8733\n",
      "Epoch 6/100\n",
      "123/123 [==============================] - 72s 588ms/step - loss: 0.2737 - accuracy: 0.8843 - val_loss: 0.2802 - val_accuracy: 0.8733\n",
      "Epoch 7/100\n",
      "123/123 [==============================] - 78s 635ms/step - loss: 0.2442 - accuracy: 0.8953 - val_loss: 0.2732 - val_accuracy: 0.8848\n",
      "Epoch 8/100\n",
      "123/123 [==============================] - 100s 815ms/step - loss: 0.2385 - accuracy: 0.8965 - val_loss: 0.3160 - val_accuracy: 0.8571\n",
      "Epoch 9/100\n",
      "123/123 [==============================] - 106s 859ms/step - loss: 0.2269 - accuracy: 0.8999 - val_loss: 0.2964 - val_accuracy: 0.8710\n",
      "Epoch 10/100\n",
      "123/123 [==============================] - 107s 875ms/step - loss: 0.1997 - accuracy: 0.9173 - val_loss: 0.2793 - val_accuracy: 0.8940\n",
      "Epoch 11/100\n",
      "123/123 [==============================] - 108s 876ms/step - loss: 0.1756 - accuracy: 0.9283 - val_loss: 0.3274 - val_accuracy: 0.8779\n",
      "Epoch 12/100\n",
      "123/123 [==============================] - 106s 864ms/step - loss: 0.1771 - accuracy: 0.9252 - val_loss: 0.3409 - val_accuracy: 0.8618\n",
      "Epoch 13/100\n",
      "123/123 [==============================] - 106s 861ms/step - loss: 0.1548 - accuracy: 0.9342 - val_loss: 0.3865 - val_accuracy: 0.8571\n",
      "Epoch 14/100\n",
      "123/123 [==============================] - 109s 890ms/step - loss: 0.1432 - accuracy: 0.9365 - val_loss: 0.3681 - val_accuracy: 0.8618\n",
      "Epoch 15/100\n",
      "123/123 [==============================] - 116s 942ms/step - loss: 0.1196 - accuracy: 0.9496 - val_loss: 0.3462 - val_accuracy: 0.8848\n",
      "Epoch 16/100\n",
      "123/123 [==============================] - 107s 868ms/step - loss: 0.1162 - accuracy: 0.9526 - val_loss: 0.3294 - val_accuracy: 0.8802\n",
      "Epoch 17/100\n",
      "123/123 [==============================] - 106s 862ms/step - loss: 0.1180 - accuracy: 0.9524 - val_loss: 0.3590 - val_accuracy: 0.8848\n",
      "Epoch 18/100\n",
      "123/123 [==============================] - 106s 859ms/step - loss: 0.1052 - accuracy: 0.9557 - val_loss: 0.3542 - val_accuracy: 0.8687\n",
      "Epoch 19/100\n",
      "123/123 [==============================] - 107s 868ms/step - loss: 0.1008 - accuracy: 0.9552 - val_loss: 0.3784 - val_accuracy: 0.8664\n",
      "Epoch 20/100\n",
      "123/123 [==============================] - 106s 864ms/step - loss: 0.0961 - accuracy: 0.9588 - val_loss: 0.5121 - val_accuracy: 0.8433\n",
      "Epoch 21/100\n",
      "123/123 [==============================] - 105s 851ms/step - loss: 0.0869 - accuracy: 0.9624 - val_loss: 0.4213 - val_accuracy: 0.8641\n",
      "Epoch 22/100\n",
      "123/123 [==============================] - 105s 856ms/step - loss: 0.0721 - accuracy: 0.9693 - val_loss: 0.3684 - val_accuracy: 0.8917\n",
      "Epoch 23/100\n",
      "123/123 [==============================] - 107s 870ms/step - loss: 0.0651 - accuracy: 0.9754 - val_loss: 0.4146 - val_accuracy: 0.8756\n",
      "Epoch 24/100\n",
      "123/123 [==============================] - 102s 826ms/step - loss: 0.0622 - accuracy: 0.9736 - val_loss: 0.4820 - val_accuracy: 0.8641\n",
      "Epoch 25/100\n",
      "123/123 [==============================] - 74s 601ms/step - loss: 0.0607 - accuracy: 0.9716 - val_loss: 0.4305 - val_accuracy: 0.8779\n",
      "Epoch 26/100\n",
      "123/123 [==============================] - 75s 608ms/step - loss: 0.0605 - accuracy: 0.9729 - val_loss: 0.4983 - val_accuracy: 0.8479\n",
      "Epoch 27/100\n",
      "123/123 [==============================] - 72s 588ms/step - loss: 0.0624 - accuracy: 0.9729 - val_loss: 0.4763 - val_accuracy: 0.8664\n",
      "WARNING:tensorflow:Layer lstm_287 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Epoch 1/100\n",
      "123/123 [==============================] - 77s 610ms/step - loss: 0.3697 - accuracy: 0.8330 - val_loss: 0.3626 - val_accuracy: 0.8502\n",
      "Epoch 2/100\n",
      "123/123 [==============================] - 75s 610ms/step - loss: 0.3139 - accuracy: 0.8681 - val_loss: 0.3585 - val_accuracy: 0.8641\n",
      "Epoch 3/100\n",
      "123/123 [==============================] - 73s 595ms/step - loss: 0.2991 - accuracy: 0.8776 - val_loss: 0.3528 - val_accuracy: 0.8571\n",
      "Epoch 4/100\n",
      "123/123 [==============================] - 75s 609ms/step - loss: 0.2753 - accuracy: 0.8858 - val_loss: 0.4049 - val_accuracy: 0.8433\n",
      "Epoch 5/100\n",
      "123/123 [==============================] - 74s 598ms/step - loss: 0.2715 - accuracy: 0.8848 - val_loss: 0.3603 - val_accuracy: 0.8525\n",
      "Epoch 6/100\n",
      "123/123 [==============================] - 75s 609ms/step - loss: 0.2581 - accuracy: 0.8891 - val_loss: 0.3512 - val_accuracy: 0.8525\n",
      "Epoch 7/100\n",
      "123/123 [==============================] - 75s 608ms/step - loss: 0.2322 - accuracy: 0.9032 - val_loss: 0.3690 - val_accuracy: 0.8387\n",
      "Epoch 8/100\n",
      "123/123 [==============================] - 75s 607ms/step - loss: 0.2312 - accuracy: 0.9017 - val_loss: 0.3820 - val_accuracy: 0.8502\n",
      "Epoch 9/100\n",
      "123/123 [==============================] - 74s 602ms/step - loss: 0.2081 - accuracy: 0.9142 - val_loss: 0.3898 - val_accuracy: 0.8456\n",
      "Epoch 10/100\n",
      "123/123 [==============================] - 76s 614ms/step - loss: 0.1865 - accuracy: 0.9222 - val_loss: 0.4021 - val_accuracy: 0.8364\n",
      "Epoch 11/100\n",
      "123/123 [==============================] - 73s 596ms/step - loss: 0.1781 - accuracy: 0.9270 - val_loss: 0.4052 - val_accuracy: 0.8594\n",
      "Epoch 12/100\n",
      "123/123 [==============================] - 75s 614ms/step - loss: 0.1662 - accuracy: 0.9286 - val_loss: 0.4091 - val_accuracy: 0.8502\n",
      "Epoch 13/100\n",
      "123/123 [==============================] - 73s 597ms/step - loss: 0.1481 - accuracy: 0.9385 - val_loss: 0.4887 - val_accuracy: 0.8272\n",
      "Epoch 14/100\n",
      "123/123 [==============================] - 74s 600ms/step - loss: 0.1330 - accuracy: 0.9467 - val_loss: 0.4779 - val_accuracy: 0.8548\n",
      "Epoch 15/100\n",
      "123/123 [==============================] - 72s 586ms/step - loss: 0.1167 - accuracy: 0.9511 - val_loss: 0.5021 - val_accuracy: 0.8318\n",
      "Epoch 16/100\n",
      "123/123 [==============================] - 76s 615ms/step - loss: 0.1093 - accuracy: 0.9513 - val_loss: 0.5289 - val_accuracy: 0.8479\n",
      "Epoch 17/100\n",
      "123/123 [==============================] - 72s 589ms/step - loss: 0.0976 - accuracy: 0.9601 - val_loss: 0.5253 - val_accuracy: 0.8525\n",
      "Epoch 18/100\n",
      "123/123 [==============================] - 74s 599ms/step - loss: 0.0882 - accuracy: 0.9621 - val_loss: 0.5721 - val_accuracy: 0.8433\n",
      "Epoch 19/100\n",
      "123/123 [==============================] - 74s 604ms/step - loss: 0.0853 - accuracy: 0.9647 - val_loss: 0.5411 - val_accuracy: 0.8618\n",
      "Epoch 20/100\n",
      "123/123 [==============================] - 76s 617ms/step - loss: 0.0802 - accuracy: 0.9629 - val_loss: 0.5891 - val_accuracy: 0.8341\n",
      "Epoch 21/100\n",
      "123/123 [==============================] - 75s 609ms/step - loss: 0.0693 - accuracy: 0.9703 - val_loss: 0.5982 - val_accuracy: 0.8410\n",
      "Epoch 22/100\n",
      "123/123 [==============================] - 74s 600ms/step - loss: 0.0718 - accuracy: 0.9695 - val_loss: 0.5886 - val_accuracy: 0.8733\n",
      "Epoch 23/100\n",
      "123/123 [==============================] - 76s 620ms/step - loss: 0.0682 - accuracy: 0.9703 - val_loss: 0.5974 - val_accuracy: 0.8479\n",
      "Epoch 24/100\n",
      "123/123 [==============================] - 76s 617ms/step - loss: 0.0610 - accuracy: 0.9754 - val_loss: 0.6586 - val_accuracy: 0.8479\n",
      "Epoch 25/100\n",
      "123/123 [==============================] - 75s 611ms/step - loss: 0.0575 - accuracy: 0.9757 - val_loss: 0.6247 - val_accuracy: 0.8387\n",
      "Epoch 26/100\n",
      "123/123 [==============================] - 75s 613ms/step - loss: 0.0557 - accuracy: 0.9772 - val_loss: 0.6863 - val_accuracy: 0.8641\n",
      "WARNING:tensorflow:Layer lstm_288 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Epoch 1/100\n",
      "122/122 [==============================] - 41s 325ms/step - loss: 0.6223 - accuracy: 0.6539 - val_loss: 0.5679 - val_accuracy: 0.7811\n",
      "Epoch 2/100\n",
      "122/122 [==============================] - 40s 324ms/step - loss: 0.5291 - accuracy: 0.7871 - val_loss: 0.4964 - val_accuracy: 0.7949\n",
      "Epoch 3/100\n",
      "122/122 [==============================] - 39s 316ms/step - loss: 0.4659 - accuracy: 0.8133 - val_loss: 0.4498 - val_accuracy: 0.8088\n",
      "Epoch 4/100\n",
      "122/122 [==============================] - 39s 316ms/step - loss: 0.4259 - accuracy: 0.8266 - val_loss: 0.4225 - val_accuracy: 0.8180\n",
      "Epoch 5/100\n",
      "122/122 [==============================] - 39s 319ms/step - loss: 0.4058 - accuracy: 0.8294 - val_loss: 0.4123 - val_accuracy: 0.8065\n",
      "Epoch 6/100\n",
      "122/122 [==============================] - 39s 316ms/step - loss: 0.3872 - accuracy: 0.8330 - val_loss: 0.4068 - val_accuracy: 0.8065\n",
      "Epoch 7/100\n",
      "122/122 [==============================] - 39s 321ms/step - loss: 0.3812 - accuracy: 0.8350 - val_loss: 0.3953 - val_accuracy: 0.8111\n",
      "Epoch 8/100\n",
      "122/122 [==============================] - 39s 318ms/step - loss: 0.3755 - accuracy: 0.8322 - val_loss: 0.3876 - val_accuracy: 0.8111\n",
      "Epoch 9/100\n",
      "122/122 [==============================] - 40s 325ms/step - loss: 0.3718 - accuracy: 0.8327 - val_loss: 0.3958 - val_accuracy: 0.8134\n",
      "Epoch 10/100\n",
      "122/122 [==============================] - 39s 316ms/step - loss: 0.3708 - accuracy: 0.8350 - val_loss: 0.3831 - val_accuracy: 0.8157\n",
      "Epoch 11/100\n",
      "122/122 [==============================] - 39s 321ms/step - loss: 0.3650 - accuracy: 0.8391 - val_loss: 0.3688 - val_accuracy: 0.8203\n",
      "Epoch 12/100\n",
      "122/122 [==============================] - 39s 317ms/step - loss: 0.3608 - accuracy: 0.8389 - val_loss: 0.3747 - val_accuracy: 0.8203\n",
      "Epoch 13/100\n",
      "122/122 [==============================] - 39s 320ms/step - loss: 0.3568 - accuracy: 0.8407 - val_loss: 0.3684 - val_accuracy: 0.8203\n",
      "Epoch 14/100\n",
      "122/122 [==============================] - 38s 314ms/step - loss: 0.3545 - accuracy: 0.8414 - val_loss: 0.3803 - val_accuracy: 0.8180\n",
      "Epoch 15/100\n",
      "122/122 [==============================] - 37s 306ms/step - loss: 0.3554 - accuracy: 0.8443 - val_loss: 0.3564 - val_accuracy: 0.8341\n",
      "Epoch 16/100\n",
      "122/122 [==============================] - 40s 331ms/step - loss: 0.3515 - accuracy: 0.8399 - val_loss: 0.3629 - val_accuracy: 0.8295\n",
      "Epoch 17/100\n",
      "122/122 [==============================] - 40s 330ms/step - loss: 0.3517 - accuracy: 0.8468 - val_loss: 0.3631 - val_accuracy: 0.8295\n",
      "Epoch 18/100\n",
      "122/122 [==============================] - 40s 326ms/step - loss: 0.3454 - accuracy: 0.8496 - val_loss: 0.3565 - val_accuracy: 0.8341\n",
      "Epoch 19/100\n",
      "122/122 [==============================] - 40s 325ms/step - loss: 0.3435 - accuracy: 0.8494 - val_loss: 0.3510 - val_accuracy: 0.8387\n",
      "Epoch 20/100\n",
      "122/122 [==============================] - 40s 328ms/step - loss: 0.3438 - accuracy: 0.8502 - val_loss: 0.3555 - val_accuracy: 0.8295\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/100\n",
      "122/122 [==============================] - 40s 324ms/step - loss: 0.3404 - accuracy: 0.8507 - val_loss: 0.3500 - val_accuracy: 0.8364\n",
      "Epoch 22/100\n",
      "122/122 [==============================] - 39s 320ms/step - loss: 0.3400 - accuracy: 0.8507 - val_loss: 0.3471 - val_accuracy: 0.8387\n",
      "Epoch 23/100\n",
      "122/122 [==============================] - 40s 325ms/step - loss: 0.3375 - accuracy: 0.8522 - val_loss: 0.3506 - val_accuracy: 0.8295\n",
      "Epoch 24/100\n",
      "122/122 [==============================] - 41s 336ms/step - loss: 0.3369 - accuracy: 0.8530 - val_loss: 0.3481 - val_accuracy: 0.8341\n",
      "Epoch 25/100\n",
      "122/122 [==============================] - 58s 472ms/step - loss: 0.3353 - accuracy: 0.8535 - val_loss: 0.3293 - val_accuracy: 0.8548\n",
      "Epoch 26/100\n",
      "122/122 [==============================] - 56s 458ms/step - loss: 0.3334 - accuracy: 0.8555 - val_loss: 0.3415 - val_accuracy: 0.8387\n",
      "Epoch 27/100\n",
      "122/122 [==============================] - 56s 455ms/step - loss: 0.3306 - accuracy: 0.8596 - val_loss: 0.3252 - val_accuracy: 0.8594\n",
      "Epoch 28/100\n",
      "122/122 [==============================] - 56s 457ms/step - loss: 0.3341 - accuracy: 0.8522 - val_loss: 0.3333 - val_accuracy: 0.8502\n",
      "Epoch 29/100\n",
      "122/122 [==============================] - 56s 459ms/step - loss: 0.3300 - accuracy: 0.8571 - val_loss: 0.3386 - val_accuracy: 0.8456\n",
      "Epoch 30/100\n",
      "122/122 [==============================] - 58s 475ms/step - loss: 0.3299 - accuracy: 0.8543 - val_loss: 0.3239 - val_accuracy: 0.8594\n",
      "Epoch 31/100\n",
      "122/122 [==============================] - 56s 460ms/step - loss: 0.3306 - accuracy: 0.8581 - val_loss: 0.3297 - val_accuracy: 0.8525\n",
      "Epoch 32/100\n",
      "122/122 [==============================] - 56s 459ms/step - loss: 0.3267 - accuracy: 0.8591 - val_loss: 0.3218 - val_accuracy: 0.8618\n",
      "Epoch 33/100\n",
      "122/122 [==============================] - 58s 476ms/step - loss: 0.3272 - accuracy: 0.8578 - val_loss: 0.3334 - val_accuracy: 0.8479\n",
      "Epoch 34/100\n",
      "122/122 [==============================] - 42s 341ms/step - loss: 0.3229 - accuracy: 0.8553 - val_loss: 0.3167 - val_accuracy: 0.8687\n",
      "Epoch 35/100\n",
      "122/122 [==============================] - 38s 314ms/step - loss: 0.3226 - accuracy: 0.8622 - val_loss: 0.3256 - val_accuracy: 0.8525\n",
      "Epoch 36/100\n",
      "122/122 [==============================] - 39s 322ms/step - loss: 0.3226 - accuracy: 0.8612 - val_loss: 0.3228 - val_accuracy: 0.8548\n",
      "Epoch 37/100\n",
      "122/122 [==============================] - 39s 317ms/step - loss: 0.3155 - accuracy: 0.8619 - val_loss: 0.3133 - val_accuracy: 0.8664\n",
      "Epoch 38/100\n",
      "122/122 [==============================] - 38s 314ms/step - loss: 0.3203 - accuracy: 0.8594 - val_loss: 0.3153 - val_accuracy: 0.8664\n",
      "Epoch 39/100\n",
      "122/122 [==============================] - 38s 314ms/step - loss: 0.3254 - accuracy: 0.8599 - val_loss: 0.3199 - val_accuracy: 0.8594\n",
      "Epoch 40/100\n",
      "122/122 [==============================] - 38s 314ms/step - loss: 0.3208 - accuracy: 0.8637 - val_loss: 0.3119 - val_accuracy: 0.8687\n",
      "Epoch 41/100\n",
      "122/122 [==============================] - 39s 316ms/step - loss: 0.3143 - accuracy: 0.8665 - val_loss: 0.3146 - val_accuracy: 0.8664\n",
      "Epoch 42/100\n",
      "122/122 [==============================] - 39s 316ms/step - loss: 0.3186 - accuracy: 0.8614 - val_loss: 0.3248 - val_accuracy: 0.8525\n",
      "Epoch 43/100\n",
      "122/122 [==============================] - 38s 316ms/step - loss: 0.3156 - accuracy: 0.8630 - val_loss: 0.3136 - val_accuracy: 0.8664\n",
      "Epoch 44/100\n",
      "122/122 [==============================] - 38s 314ms/step - loss: 0.3150 - accuracy: 0.8630 - val_loss: 0.3187 - val_accuracy: 0.8594\n",
      "Epoch 45/100\n",
      "122/122 [==============================] - 38s 316ms/step - loss: 0.3156 - accuracy: 0.8627 - val_loss: 0.3106 - val_accuracy: 0.8664\n",
      "Epoch 46/100\n",
      "122/122 [==============================] - 39s 319ms/step - loss: 0.3157 - accuracy: 0.8668 - val_loss: 0.3153 - val_accuracy: 0.8594\n",
      "Epoch 47/100\n",
      "122/122 [==============================] - 38s 312ms/step - loss: 0.3124 - accuracy: 0.8663 - val_loss: 0.3191 - val_accuracy: 0.8525\n",
      "Epoch 48/100\n",
      "122/122 [==============================] - 38s 309ms/step - loss: 0.3125 - accuracy: 0.8694 - val_loss: 0.3039 - val_accuracy: 0.8618\n",
      "Epoch 49/100\n",
      "122/122 [==============================] - 39s 316ms/step - loss: 0.3133 - accuracy: 0.8609 - val_loss: 0.3210 - val_accuracy: 0.8502\n",
      "Epoch 50/100\n",
      "122/122 [==============================] - 40s 327ms/step - loss: 0.3129 - accuracy: 0.8645 - val_loss: 0.3075 - val_accuracy: 0.8618\n",
      "Epoch 51/100\n",
      "122/122 [==============================] - 39s 321ms/step - loss: 0.3150 - accuracy: 0.8607 - val_loss: 0.3040 - val_accuracy: 0.8618\n",
      "Epoch 52/100\n",
      "122/122 [==============================] - 40s 327ms/step - loss: 0.3101 - accuracy: 0.8699 - val_loss: 0.3027 - val_accuracy: 0.8618\n",
      "Epoch 53/100\n",
      "122/122 [==============================] - 39s 321ms/step - loss: 0.3131 - accuracy: 0.8655 - val_loss: 0.3108 - val_accuracy: 0.8641\n",
      "Epoch 54/100\n",
      "122/122 [==============================] - 39s 321ms/step - loss: 0.3082 - accuracy: 0.8658 - val_loss: 0.3121 - val_accuracy: 0.8571\n",
      "Epoch 55/100\n",
      "122/122 [==============================] - 39s 322ms/step - loss: 0.3081 - accuracy: 0.8691 - val_loss: 0.3051 - val_accuracy: 0.8641\n",
      "Epoch 56/100\n",
      "122/122 [==============================] - 39s 321ms/step - loss: 0.3059 - accuracy: 0.8704 - val_loss: 0.3072 - val_accuracy: 0.8664\n",
      "Epoch 57/100\n",
      "122/122 [==============================] - 38s 315ms/step - loss: 0.3060 - accuracy: 0.8673 - val_loss: 0.3041 - val_accuracy: 0.8641\n",
      "Epoch 58/100\n",
      "122/122 [==============================] - 39s 316ms/step - loss: 0.3055 - accuracy: 0.8717 - val_loss: 0.3002 - val_accuracy: 0.8641\n",
      "Epoch 59/100\n",
      "122/122 [==============================] - 39s 318ms/step - loss: 0.3055 - accuracy: 0.8663 - val_loss: 0.3019 - val_accuracy: 0.8618\n",
      "Epoch 60/100\n",
      "122/122 [==============================] - 38s 311ms/step - loss: 0.3054 - accuracy: 0.8704 - val_loss: 0.3089 - val_accuracy: 0.8594\n",
      "Epoch 61/100\n",
      "122/122 [==============================] - 38s 310ms/step - loss: 0.3043 - accuracy: 0.8673 - val_loss: 0.3000 - val_accuracy: 0.8641\n",
      "Epoch 62/100\n",
      "122/122 [==============================] - 40s 328ms/step - loss: 0.3051 - accuracy: 0.8704 - val_loss: 0.3159 - val_accuracy: 0.8479\n",
      "Epoch 63/100\n",
      "122/122 [==============================] - 39s 322ms/step - loss: 0.3094 - accuracy: 0.8668 - val_loss: 0.3030 - val_accuracy: 0.8641\n",
      "Epoch 64/100\n",
      "122/122 [==============================] - 39s 320ms/step - loss: 0.3021 - accuracy: 0.8699 - val_loss: 0.3005 - val_accuracy: 0.8664\n",
      "Epoch 65/100\n",
      "122/122 [==============================] - 39s 318ms/step - loss: 0.3039 - accuracy: 0.8689 - val_loss: 0.3053 - val_accuracy: 0.8618\n",
      "Epoch 66/100\n",
      "122/122 [==============================] - 39s 317ms/step - loss: 0.2999 - accuracy: 0.8714 - val_loss: 0.2999 - val_accuracy: 0.8664\n",
      "Epoch 67/100\n",
      "122/122 [==============================] - 38s 312ms/step - loss: 0.2944 - accuracy: 0.8755 - val_loss: 0.3045 - val_accuracy: 0.8618\n",
      "Epoch 68/100\n",
      "122/122 [==============================] - 38s 313ms/step - loss: 0.2994 - accuracy: 0.8689 - val_loss: 0.3202 - val_accuracy: 0.8433\n",
      "Epoch 69/100\n",
      "122/122 [==============================] - 38s 314ms/step - loss: 0.2975 - accuracy: 0.8745 - val_loss: 0.2976 - val_accuracy: 0.8664\n",
      "Epoch 70/100\n",
      "122/122 [==============================] - 39s 320ms/step - loss: 0.2971 - accuracy: 0.8760 - val_loss: 0.2932 - val_accuracy: 0.8733\n",
      "Epoch 71/100\n",
      "122/122 [==============================] - 39s 322ms/step - loss: 0.2968 - accuracy: 0.8763 - val_loss: 0.2975 - val_accuracy: 0.8664\n",
      "Epoch 72/100\n",
      "122/122 [==============================] - 39s 321ms/step - loss: 0.2950 - accuracy: 0.8765 - val_loss: 0.2980 - val_accuracy: 0.8664\n",
      "Epoch 73/100\n",
      "122/122 [==============================] - 38s 314ms/step - loss: 0.2988 - accuracy: 0.8727 - val_loss: 0.3096 - val_accuracy: 0.8548\n",
      "Epoch 74/100\n",
      "122/122 [==============================] - 38s 312ms/step - loss: 0.2945 - accuracy: 0.8760 - val_loss: 0.2999 - val_accuracy: 0.8641\n",
      "Epoch 75/100\n",
      "122/122 [==============================] - 40s 325ms/step - loss: 0.2964 - accuracy: 0.8691 - val_loss: 0.2989 - val_accuracy: 0.8594\n",
      "Epoch 76/100\n",
      "122/122 [==============================] - 40s 327ms/step - loss: 0.2943 - accuracy: 0.8747 - val_loss: 0.2990 - val_accuracy: 0.8641\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 77/100\n",
      "122/122 [==============================] - 39s 318ms/step - loss: 0.2910 - accuracy: 0.8722 - val_loss: 0.2991 - val_accuracy: 0.8618\n",
      "Epoch 78/100\n",
      "122/122 [==============================] - 39s 321ms/step - loss: 0.2965 - accuracy: 0.8745 - val_loss: 0.3023 - val_accuracy: 0.8618\n",
      "Epoch 79/100\n",
      "122/122 [==============================] - 39s 320ms/step - loss: 0.2954 - accuracy: 0.8709 - val_loss: 0.3019 - val_accuracy: 0.8641\n",
      "Epoch 80/100\n",
      "122/122 [==============================] - 39s 318ms/step - loss: 0.2947 - accuracy: 0.8740 - val_loss: 0.3023 - val_accuracy: 0.8618\n",
      "Epoch 81/100\n",
      "122/122 [==============================] - 39s 317ms/step - loss: 0.2891 - accuracy: 0.8781 - val_loss: 0.3057 - val_accuracy: 0.8571\n",
      "Epoch 82/100\n",
      "122/122 [==============================] - 38s 314ms/step - loss: 0.2934 - accuracy: 0.8709 - val_loss: 0.2957 - val_accuracy: 0.8664\n",
      "Epoch 83/100\n",
      "122/122 [==============================] - 39s 319ms/step - loss: 0.2875 - accuracy: 0.8747 - val_loss: 0.2979 - val_accuracy: 0.8687\n",
      "Epoch 84/100\n",
      "122/122 [==============================] - 38s 315ms/step - loss: 0.2932 - accuracy: 0.8763 - val_loss: 0.2979 - val_accuracy: 0.8641\n",
      "Epoch 85/100\n",
      "122/122 [==============================] - 38s 313ms/step - loss: 0.2889 - accuracy: 0.8765 - val_loss: 0.3017 - val_accuracy: 0.8618\n",
      "Epoch 86/100\n",
      "122/122 [==============================] - 38s 310ms/step - loss: 0.2885 - accuracy: 0.8755 - val_loss: 0.2959 - val_accuracy: 0.8641\n",
      "Epoch 87/100\n",
      "122/122 [==============================] - 38s 313ms/step - loss: 0.2889 - accuracy: 0.8809 - val_loss: 0.2888 - val_accuracy: 0.8710\n",
      "Epoch 88/100\n",
      "122/122 [==============================] - 38s 313ms/step - loss: 0.2866 - accuracy: 0.8770 - val_loss: 0.2991 - val_accuracy: 0.8618\n",
      "Epoch 89/100\n",
      "122/122 [==============================] - 39s 322ms/step - loss: 0.2850 - accuracy: 0.8763 - val_loss: 0.2950 - val_accuracy: 0.8687\n",
      "Epoch 90/100\n",
      "122/122 [==============================] - 39s 321ms/step - loss: 0.2822 - accuracy: 0.8858 - val_loss: 0.3030 - val_accuracy: 0.8525\n",
      "Epoch 91/100\n",
      "122/122 [==============================] - 39s 321ms/step - loss: 0.2910 - accuracy: 0.8760 - val_loss: 0.3006 - val_accuracy: 0.8525\n",
      "Epoch 92/100\n",
      "122/122 [==============================] - 38s 315ms/step - loss: 0.2793 - accuracy: 0.8852 - val_loss: 0.2977 - val_accuracy: 0.8571\n",
      "Epoch 93/100\n",
      "122/122 [==============================] - 39s 317ms/step - loss: 0.2804 - accuracy: 0.8822 - val_loss: 0.2918 - val_accuracy: 0.8733\n",
      "Epoch 94/100\n",
      "122/122 [==============================] - 39s 319ms/step - loss: 0.2843 - accuracy: 0.8819 - val_loss: 0.3001 - val_accuracy: 0.8548\n",
      "Epoch 95/100\n",
      "122/122 [==============================] - 39s 319ms/step - loss: 0.2851 - accuracy: 0.8788 - val_loss: 0.2912 - val_accuracy: 0.8710\n",
      "Epoch 96/100\n",
      "122/122 [==============================] - 39s 317ms/step - loss: 0.2828 - accuracy: 0.8740 - val_loss: 0.2911 - val_accuracy: 0.8710\n",
      "Epoch 97/100\n",
      "122/122 [==============================] - 38s 315ms/step - loss: 0.2863 - accuracy: 0.8783 - val_loss: 0.2990 - val_accuracy: 0.8618\n",
      "Epoch 98/100\n",
      "122/122 [==============================] - 38s 311ms/step - loss: 0.2781 - accuracy: 0.8799 - val_loss: 0.3007 - val_accuracy: 0.8618\n",
      "Epoch 99/100\n",
      "122/122 [==============================] - 39s 316ms/step - loss: 0.2773 - accuracy: 0.8868 - val_loss: 0.2949 - val_accuracy: 0.8618\n",
      "Epoch 100/100\n",
      "122/122 [==============================] - 38s 313ms/step - loss: 0.2776 - accuracy: 0.8822 - val_loss: 0.2958 - val_accuracy: 0.8618\n",
      "WARNING:tensorflow:Layer lstm_289 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Epoch 1/100\n",
      "123/123 [==============================] - 76s 604ms/step - loss: 0.6136 - accuracy: 0.7032 - val_loss: 0.5667 - val_accuracy: 0.7972\n",
      "Epoch 2/100\n",
      "123/123 [==============================] - 76s 615ms/step - loss: 0.5235 - accuracy: 0.8015 - val_loss: 0.4896 - val_accuracy: 0.7972\n",
      "Epoch 3/100\n",
      "123/123 [==============================] - 75s 607ms/step - loss: 0.4674 - accuracy: 0.8085 - val_loss: 0.4516 - val_accuracy: 0.8088\n",
      "Epoch 4/100\n",
      "123/123 [==============================] - 74s 599ms/step - loss: 0.4300 - accuracy: 0.8159 - val_loss: 0.4322 - val_accuracy: 0.8065\n",
      "Epoch 5/100\n",
      "123/123 [==============================] - 76s 619ms/step - loss: 0.4114 - accuracy: 0.8187 - val_loss: 0.4158 - val_accuracy: 0.8134\n",
      "Epoch 6/100\n",
      "123/123 [==============================] - 74s 600ms/step - loss: 0.3993 - accuracy: 0.8205 - val_loss: 0.4205 - val_accuracy: 0.8041\n",
      "Epoch 7/100\n",
      "123/123 [==============================] - 73s 597ms/step - loss: 0.3910 - accuracy: 0.8190 - val_loss: 0.4034 - val_accuracy: 0.8134\n",
      "Epoch 8/100\n",
      "123/123 [==============================] - 76s 621ms/step - loss: 0.3866 - accuracy: 0.8200 - val_loss: 0.4183 - val_accuracy: 0.8041\n",
      "Epoch 9/100\n",
      "123/123 [==============================] - 74s 602ms/step - loss: 0.3814 - accuracy: 0.8254 - val_loss: 0.4019 - val_accuracy: 0.8088\n",
      "Epoch 10/100\n",
      "123/123 [==============================] - 74s 605ms/step - loss: 0.3718 - accuracy: 0.8271 - val_loss: 0.4205 - val_accuracy: 0.8065\n",
      "Epoch 11/100\n",
      "123/123 [==============================] - 75s 607ms/step - loss: 0.3727 - accuracy: 0.8294 - val_loss: 0.3812 - val_accuracy: 0.8203\n",
      "Epoch 12/100\n",
      "123/123 [==============================] - 75s 613ms/step - loss: 0.3690 - accuracy: 0.8328 - val_loss: 0.3855 - val_accuracy: 0.8111\n",
      "Epoch 13/100\n",
      "123/123 [==============================] - 73s 595ms/step - loss: 0.3689 - accuracy: 0.8341 - val_loss: 0.3921 - val_accuracy: 0.8111\n",
      "Epoch 14/100\n",
      "123/123 [==============================] - 76s 620ms/step - loss: 0.3648 - accuracy: 0.8343 - val_loss: 0.3783 - val_accuracy: 0.8111\n",
      "Epoch 15/100\n",
      "123/123 [==============================] - 76s 617ms/step - loss: 0.3597 - accuracy: 0.8371 - val_loss: 0.3442 - val_accuracy: 0.8502\n",
      "Epoch 16/100\n",
      "123/123 [==============================] - 74s 600ms/step - loss: 0.3616 - accuracy: 0.8371 - val_loss: 0.3633 - val_accuracy: 0.8226\n",
      "Epoch 17/100\n",
      "123/123 [==============================] - 74s 601ms/step - loss: 0.3553 - accuracy: 0.8394 - val_loss: 0.3481 - val_accuracy: 0.8364\n",
      "Epoch 18/100\n",
      "123/123 [==============================] - 76s 619ms/step - loss: 0.3510 - accuracy: 0.8387 - val_loss: 0.3635 - val_accuracy: 0.8249\n",
      "Epoch 19/100\n",
      "123/123 [==============================] - 75s 607ms/step - loss: 0.3540 - accuracy: 0.8448 - val_loss: 0.3569 - val_accuracy: 0.8318\n",
      "Epoch 20/100\n",
      "123/123 [==============================] - 75s 610ms/step - loss: 0.3530 - accuracy: 0.8423 - val_loss: 0.3396 - val_accuracy: 0.8410\n",
      "Epoch 21/100\n",
      "123/123 [==============================] - 75s 608ms/step - loss: 0.3503 - accuracy: 0.8440 - val_loss: 0.3472 - val_accuracy: 0.8341\n",
      "Epoch 22/100\n",
      "123/123 [==============================] - 74s 599ms/step - loss: 0.3510 - accuracy: 0.8428 - val_loss: 0.3429 - val_accuracy: 0.8364\n",
      "Epoch 23/100\n",
      "123/123 [==============================] - 73s 598ms/step - loss: 0.3461 - accuracy: 0.8451 - val_loss: 0.3557 - val_accuracy: 0.8295\n",
      "Epoch 24/100\n",
      "123/123 [==============================] - 76s 622ms/step - loss: 0.3480 - accuracy: 0.8492 - val_loss: 0.3472 - val_accuracy: 0.8341\n",
      "Epoch 25/100\n",
      "123/123 [==============================] - 73s 592ms/step - loss: 0.3411 - accuracy: 0.8540 - val_loss: 0.3233 - val_accuracy: 0.8664\n",
      "Epoch 26/100\n",
      "123/123 [==============================] - 76s 616ms/step - loss: 0.3407 - accuracy: 0.8479 - val_loss: 0.3355 - val_accuracy: 0.8479\n",
      "Epoch 27/100\n",
      "123/123 [==============================] - 75s 609ms/step - loss: 0.3402 - accuracy: 0.8492 - val_loss: 0.3368 - val_accuracy: 0.8433\n",
      "Epoch 28/100\n",
      "123/123 [==============================] - 75s 614ms/step - loss: 0.3396 - accuracy: 0.8502 - val_loss: 0.3439 - val_accuracy: 0.8502\n",
      "Epoch 29/100\n",
      "123/123 [==============================] - 73s 597ms/step - loss: 0.3422 - accuracy: 0.8489 - val_loss: 0.3187 - val_accuracy: 0.8687\n",
      "Epoch 30/100\n",
      "123/123 [==============================] - 75s 612ms/step - loss: 0.3388 - accuracy: 0.8499 - val_loss: 0.3172 - val_accuracy: 0.8733\n",
      "Epoch 31/100\n",
      "123/123 [==============================] - 75s 607ms/step - loss: 0.3364 - accuracy: 0.8504 - val_loss: 0.3465 - val_accuracy: 0.8272\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32/100\n",
      "123/123 [==============================] - 76s 615ms/step - loss: 0.3308 - accuracy: 0.8528 - val_loss: 0.3321 - val_accuracy: 0.8410\n",
      "Epoch 33/100\n",
      "123/123 [==============================] - 76s 619ms/step - loss: 0.3334 - accuracy: 0.8538 - val_loss: 0.3753 - val_accuracy: 0.8018\n",
      "Epoch 34/100\n",
      "123/123 [==============================] - 74s 604ms/step - loss: 0.3328 - accuracy: 0.8533 - val_loss: 0.3155 - val_accuracy: 0.8756\n",
      "Epoch 35/100\n",
      "123/123 [==============================] - 75s 610ms/step - loss: 0.3281 - accuracy: 0.8561 - val_loss: 0.3134 - val_accuracy: 0.8756\n",
      "Epoch 36/100\n",
      "123/123 [==============================] - 75s 608ms/step - loss: 0.3300 - accuracy: 0.8553 - val_loss: 0.3170 - val_accuracy: 0.8687\n",
      "Epoch 37/100\n",
      "123/123 [==============================] - 75s 610ms/step - loss: 0.3296 - accuracy: 0.8540 - val_loss: 0.3038 - val_accuracy: 0.8779\n",
      "Epoch 38/100\n",
      "123/123 [==============================] - 75s 609ms/step - loss: 0.3266 - accuracy: 0.8558 - val_loss: 0.3063 - val_accuracy: 0.8733\n",
      "Epoch 39/100\n",
      "123/123 [==============================] - 76s 615ms/step - loss: 0.3225 - accuracy: 0.8569 - val_loss: 0.3149 - val_accuracy: 0.8687\n",
      "Epoch 40/100\n",
      "123/123 [==============================] - 77s 624ms/step - loss: 0.3224 - accuracy: 0.8551 - val_loss: 0.3039 - val_accuracy: 0.8710\n",
      "Epoch 41/100\n",
      "123/123 [==============================] - 96s 784ms/step - loss: 0.3258 - accuracy: 0.8551 - val_loss: 0.3013 - val_accuracy: 0.8710\n",
      "Epoch 42/100\n",
      "123/123 [==============================] - 110s 893ms/step - loss: 0.3268 - accuracy: 0.8540 - val_loss: 0.2995 - val_accuracy: 0.8756\n",
      "Epoch 43/100\n",
      "123/123 [==============================] - 108s 878ms/step - loss: 0.3227 - accuracy: 0.8581 - val_loss: 0.3112 - val_accuracy: 0.8687\n",
      "Epoch 44/100\n",
      "123/123 [==============================] - 108s 877ms/step - loss: 0.3222 - accuracy: 0.8563 - val_loss: 0.3115 - val_accuracy: 0.8664\n",
      "Epoch 45/100\n",
      "123/123 [==============================] - 108s 877ms/step - loss: 0.3200 - accuracy: 0.8650 - val_loss: 0.2980 - val_accuracy: 0.8687\n",
      "Epoch 46/100\n",
      "123/123 [==============================] - 111s 905ms/step - loss: 0.3180 - accuracy: 0.8604 - val_loss: 0.2930 - val_accuracy: 0.8733\n",
      "Epoch 47/100\n",
      "123/123 [==============================] - 109s 884ms/step - loss: 0.3151 - accuracy: 0.8648 - val_loss: 0.3037 - val_accuracy: 0.8618\n",
      "Epoch 48/100\n",
      "123/123 [==============================] - 108s 879ms/step - loss: 0.3198 - accuracy: 0.8643 - val_loss: 0.2960 - val_accuracy: 0.8664\n",
      "Epoch 49/100\n",
      "123/123 [==============================] - 107s 874ms/step - loss: 0.3188 - accuracy: 0.8615 - val_loss: 0.3183 - val_accuracy: 0.8479\n",
      "Epoch 50/100\n",
      "123/123 [==============================] - 108s 881ms/step - loss: 0.3170 - accuracy: 0.8633 - val_loss: 0.2941 - val_accuracy: 0.8687\n",
      "Epoch 51/100\n",
      "123/123 [==============================] - 108s 882ms/step - loss: 0.3120 - accuracy: 0.8602 - val_loss: 0.2950 - val_accuracy: 0.8710\n",
      "Epoch 52/100\n",
      "123/123 [==============================] - 108s 880ms/step - loss: 0.3157 - accuracy: 0.8638 - val_loss: 0.2970 - val_accuracy: 0.8641\n",
      "Epoch 53/100\n",
      "123/123 [==============================] - 108s 878ms/step - loss: 0.3183 - accuracy: 0.8638 - val_loss: 0.3132 - val_accuracy: 0.8548\n",
      "Epoch 54/100\n",
      "123/123 [==============================] - 109s 888ms/step - loss: 0.3166 - accuracy: 0.8622 - val_loss: 0.3620 - val_accuracy: 0.8157\n",
      "Epoch 55/100\n",
      "123/123 [==============================] - 110s 893ms/step - loss: 0.3132 - accuracy: 0.8615 - val_loss: 0.3209 - val_accuracy: 0.8479\n",
      "Epoch 56/100\n",
      "123/123 [==============================] - 109s 890ms/step - loss: 0.3130 - accuracy: 0.8620 - val_loss: 0.3203 - val_accuracy: 0.8502\n",
      "Epoch 57/100\n",
      "123/123 [==============================] - 108s 876ms/step - loss: 0.3111 - accuracy: 0.8666 - val_loss: 0.2870 - val_accuracy: 0.8802\n",
      "Epoch 58/100\n",
      "123/123 [==============================] - 106s 866ms/step - loss: 0.3089 - accuracy: 0.8681 - val_loss: 0.4217 - val_accuracy: 0.7903\n",
      "Epoch 59/100\n",
      "123/123 [==============================] - 108s 875ms/step - loss: 0.3126 - accuracy: 0.8643 - val_loss: 0.3010 - val_accuracy: 0.8618\n",
      "Epoch 60/100\n",
      "123/123 [==============================] - 107s 871ms/step - loss: 0.3086 - accuracy: 0.8661 - val_loss: 0.2909 - val_accuracy: 0.8664\n",
      "Epoch 61/100\n",
      "123/123 [==============================] - 110s 894ms/step - loss: 0.3071 - accuracy: 0.8707 - val_loss: 0.3376 - val_accuracy: 0.8341\n",
      "Epoch 62/100\n",
      "123/123 [==============================] - 107s 870ms/step - loss: 0.3077 - accuracy: 0.8707 - val_loss: 0.3134 - val_accuracy: 0.8548\n",
      "Epoch 63/100\n",
      "123/123 [==============================] - 109s 888ms/step - loss: 0.3041 - accuracy: 0.8740 - val_loss: 0.2950 - val_accuracy: 0.8687\n",
      "Epoch 64/100\n",
      "123/123 [==============================] - 108s 879ms/step - loss: 0.3077 - accuracy: 0.8648 - val_loss: 0.2919 - val_accuracy: 0.8641\n",
      "Epoch 65/100\n",
      "123/123 [==============================] - 106s 865ms/step - loss: 0.3035 - accuracy: 0.8671 - val_loss: 0.2850 - val_accuracy: 0.8756\n",
      "Epoch 66/100\n",
      "123/123 [==============================] - 108s 876ms/step - loss: 0.3054 - accuracy: 0.8694 - val_loss: 0.3068 - val_accuracy: 0.8571\n",
      "Epoch 67/100\n",
      "123/123 [==============================] - 1184s 10s/step - loss: 0.3039 - accuracy: 0.8673 - val_loss: 0.2829 - val_accuracy: 0.8825\n",
      "Epoch 68/100\n",
      "123/123 [==============================] - 76s 616ms/step - loss: 0.3019 - accuracy: 0.8704 - val_loss: 0.4589 - val_accuracy: 0.7765\n",
      "Epoch 69/100\n",
      "123/123 [==============================] - 77s 630ms/step - loss: 0.3110 - accuracy: 0.8673 - val_loss: 0.2868 - val_accuracy: 0.8687\n",
      "Epoch 70/100\n",
      "123/123 [==============================] - 77s 627ms/step - loss: 0.2984 - accuracy: 0.8743 - val_loss: 0.2982 - val_accuracy: 0.8618\n",
      "Epoch 71/100\n",
      "123/123 [==============================] - 77s 627ms/step - loss: 0.2979 - accuracy: 0.8732 - val_loss: 0.2889 - val_accuracy: 0.8733\n",
      "Epoch 72/100\n",
      "123/123 [==============================] - 78s 633ms/step - loss: 0.2989 - accuracy: 0.8681 - val_loss: 0.3141 - val_accuracy: 0.8548\n",
      "Epoch 73/100\n",
      "123/123 [==============================] - 79s 641ms/step - loss: 0.2957 - accuracy: 0.8686 - val_loss: 0.2847 - val_accuracy: 0.8710\n",
      "Epoch 74/100\n",
      "123/123 [==============================] - 80s 649ms/step - loss: 0.2965 - accuracy: 0.8722 - val_loss: 0.2889 - val_accuracy: 0.8733\n",
      "Epoch 75/100\n",
      "123/123 [==============================] - 78s 630ms/step - loss: 0.2959 - accuracy: 0.8735 - val_loss: 0.2968 - val_accuracy: 0.8687\n",
      "Epoch 76/100\n",
      "123/123 [==============================] - 79s 646ms/step - loss: 0.2989 - accuracy: 0.8720 - val_loss: 0.2913 - val_accuracy: 0.8733\n",
      "Epoch 77/100\n",
      "123/123 [==============================] - 78s 635ms/step - loss: 0.2921 - accuracy: 0.8727 - val_loss: 0.2991 - val_accuracy: 0.8710\n",
      "Epoch 78/100\n",
      "123/123 [==============================] - 77s 625ms/step - loss: 0.2944 - accuracy: 0.8689 - val_loss: 0.2902 - val_accuracy: 0.8733\n",
      "Epoch 79/100\n",
      "123/123 [==============================] - 79s 639ms/step - loss: 0.2938 - accuracy: 0.8738 - val_loss: 0.2953 - val_accuracy: 0.8710\n",
      "Epoch 80/100\n",
      "123/123 [==============================] - 76s 622ms/step - loss: 0.2896 - accuracy: 0.8799 - val_loss: 0.3554 - val_accuracy: 0.8203\n",
      "Epoch 81/100\n",
      "123/123 [==============================] - 77s 630ms/step - loss: 0.2897 - accuracy: 0.8755 - val_loss: 0.2811 - val_accuracy: 0.8756\n",
      "Epoch 82/100\n",
      "123/123 [==============================] - 76s 615ms/step - loss: 0.2911 - accuracy: 0.8753 - val_loss: 0.2978 - val_accuracy: 0.8687\n",
      "Epoch 83/100\n",
      "123/123 [==============================] - 78s 638ms/step - loss: 0.2869 - accuracy: 0.8786 - val_loss: 0.3475 - val_accuracy: 0.8272\n",
      "Epoch 84/100\n",
      "123/123 [==============================] - 78s 633ms/step - loss: 0.2927 - accuracy: 0.8745 - val_loss: 0.2969 - val_accuracy: 0.8710\n",
      "Epoch 85/100\n",
      "123/123 [==============================] - 78s 632ms/step - loss: 0.2900 - accuracy: 0.8796 - val_loss: 0.3396 - val_accuracy: 0.8318\n",
      "Epoch 86/100\n",
      "123/123 [==============================] - 77s 630ms/step - loss: 0.2913 - accuracy: 0.8748 - val_loss: 0.5421 - val_accuracy: 0.7442\n",
      "Epoch 87/100\n",
      "123/123 [==============================] - 77s 623ms/step - loss: 0.2922 - accuracy: 0.8722 - val_loss: 0.2936 - val_accuracy: 0.8710\n",
      "Epoch 88/100\n",
      "123/123 [==============================] - 77s 626ms/step - loss: 0.2894 - accuracy: 0.8766 - val_loss: 0.2873 - val_accuracy: 0.8802\n",
      "Epoch 89/100\n",
      "123/123 [==============================] - 78s 633ms/step - loss: 0.2875 - accuracy: 0.8784 - val_loss: 0.2811 - val_accuracy: 0.8825\n",
      "Epoch 90/100\n",
      "123/123 [==============================] - 78s 635ms/step - loss: 0.2881 - accuracy: 0.8771 - val_loss: 0.2976 - val_accuracy: 0.8641\n",
      "Epoch 91/100\n",
      "123/123 [==============================] - 77s 626ms/step - loss: 0.2855 - accuracy: 0.8766 - val_loss: 0.2878 - val_accuracy: 0.8756\n",
      "Epoch 92/100\n",
      "123/123 [==============================] - 79s 645ms/step - loss: 0.2869 - accuracy: 0.8773 - val_loss: 0.2926 - val_accuracy: 0.8687\n",
      "Epoch 93/100\n",
      "123/123 [==============================] - 77s 625ms/step - loss: 0.2853 - accuracy: 0.8781 - val_loss: 0.2967 - val_accuracy: 0.8710\n",
      "Epoch 94/100\n",
      "123/123 [==============================] - 31334s 257s/step - loss: 0.2860 - accuracy: 0.8766 - val_loss: 0.2955 - val_accuracy: 0.8664\n",
      "Epoch 95/100\n",
      "123/123 [==============================] - 83s 676ms/step - loss: 0.2815 - accuracy: 0.8835 - val_loss: 0.2963 - val_accuracy: 0.8664\n",
      "Epoch 96/100\n",
      "123/123 [==============================] - 79s 646ms/step - loss: 0.2804 - accuracy: 0.8789 - val_loss: 0.2754 - val_accuracy: 0.8687\n",
      "Epoch 97/100\n",
      "123/123 [==============================] - 79s 642ms/step - loss: 0.2816 - accuracy: 0.8794 - val_loss: 0.2828 - val_accuracy: 0.8733\n",
      "Epoch 98/100\n",
      "123/123 [==============================] - 80s 651ms/step - loss: 0.2819 - accuracy: 0.8807 - val_loss: 0.2833 - val_accuracy: 0.8710\n",
      "Epoch 99/100\n",
      "123/123 [==============================] - 82s 671ms/step - loss: 0.2834 - accuracy: 0.8778 - val_loss: 0.4330 - val_accuracy: 0.7903\n",
      "Epoch 100/100\n",
      "123/123 [==============================] - 80s 652ms/step - loss: 0.2845 - accuracy: 0.8804 - val_loss: 0.2766 - val_accuracy: 0.8779\n",
      "WARNING:tensorflow:Layer lstm_290 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Epoch 1/100\n",
      "123/123 [==============================] - 86s 660ms/step - loss: 0.6197 - accuracy: 0.6576 - val_loss: 0.5727 - val_accuracy: 0.7650\n",
      "Epoch 2/100\n",
      "123/123 [==============================] - 80s 651ms/step - loss: 0.5168 - accuracy: 0.7933 - val_loss: 0.4889 - val_accuracy: 0.8041\n",
      "Epoch 3/100\n",
      "123/123 [==============================] - 80s 650ms/step - loss: 0.4464 - accuracy: 0.8251 - val_loss: 0.4441 - val_accuracy: 0.8088\n",
      "Epoch 4/100\n",
      "123/123 [==============================] - 79s 639ms/step - loss: 0.4054 - accuracy: 0.8289 - val_loss: 0.4273 - val_accuracy: 0.8088\n",
      "Epoch 5/100\n",
      "123/123 [==============================] - 78s 637ms/step - loss: 0.3833 - accuracy: 0.8356 - val_loss: 0.4055 - val_accuracy: 0.8249\n",
      "Epoch 6/100\n",
      "123/123 [==============================] - 79s 644ms/step - loss: 0.3713 - accuracy: 0.8351 - val_loss: 0.4195 - val_accuracy: 0.7926\n",
      "Epoch 7/100\n",
      "123/123 [==============================] - 78s 636ms/step - loss: 0.3621 - accuracy: 0.8356 - val_loss: 0.4061 - val_accuracy: 0.7949\n",
      "Epoch 8/100\n",
      "123/123 [==============================] - 76s 617ms/step - loss: 0.3556 - accuracy: 0.8412 - val_loss: 0.3967 - val_accuracy: 0.8041\n",
      "Epoch 9/100\n",
      "123/123 [==============================] - 79s 644ms/step - loss: 0.3521 - accuracy: 0.8407 - val_loss: 0.4005 - val_accuracy: 0.7972\n",
      "Epoch 10/100\n",
      "123/123 [==============================] - 78s 634ms/step - loss: 0.3475 - accuracy: 0.8461 - val_loss: 0.3922 - val_accuracy: 0.8180\n",
      "Epoch 11/100\n",
      "123/123 [==============================] - 82s 669ms/step - loss: 0.3472 - accuracy: 0.8417 - val_loss: 0.3913 - val_accuracy: 0.8180\n",
      "Epoch 12/100\n",
      "123/123 [==============================] - 78s 632ms/step - loss: 0.3424 - accuracy: 0.8474 - val_loss: 0.4020 - val_accuracy: 0.8088\n",
      "Epoch 13/100\n",
      "123/123 [==============================] - 77s 625ms/step - loss: 0.3421 - accuracy: 0.8446 - val_loss: 0.3895 - val_accuracy: 0.8157\n",
      "Epoch 14/100\n",
      "123/123 [==============================] - 78s 635ms/step - loss: 0.3368 - accuracy: 0.8502 - val_loss: 0.3814 - val_accuracy: 0.8318\n",
      "Epoch 15/100\n",
      "123/123 [==============================] - 78s 631ms/step - loss: 0.3354 - accuracy: 0.8484 - val_loss: 0.4007 - val_accuracy: 0.8157\n",
      "Epoch 16/100\n",
      "123/123 [==============================] - 79s 645ms/step - loss: 0.3369 - accuracy: 0.8481 - val_loss: 0.3897 - val_accuracy: 0.8249\n",
      "Epoch 17/100\n",
      "123/123 [==============================] - 79s 639ms/step - loss: 0.3324 - accuracy: 0.8502 - val_loss: 0.3836 - val_accuracy: 0.8295\n",
      "Epoch 18/100\n",
      "123/123 [==============================] - 78s 632ms/step - loss: 0.3290 - accuracy: 0.8561 - val_loss: 0.4039 - val_accuracy: 0.8203\n",
      "Epoch 19/100\n",
      "123/123 [==============================] - 77s 625ms/step - loss: 0.3299 - accuracy: 0.8561 - val_loss: 0.3867 - val_accuracy: 0.8295\n",
      "Epoch 20/100\n",
      "123/123 [==============================] - 78s 634ms/step - loss: 0.3280 - accuracy: 0.8538 - val_loss: 0.3747 - val_accuracy: 0.8410\n",
      "Epoch 21/100\n",
      "123/123 [==============================] - 78s 631ms/step - loss: 0.3257 - accuracy: 0.8566 - val_loss: 0.3864 - val_accuracy: 0.8318\n",
      "Epoch 22/100\n",
      "123/123 [==============================] - 78s 633ms/step - loss: 0.3251 - accuracy: 0.8592 - val_loss: 0.3895 - val_accuracy: 0.8387\n",
      "Epoch 23/100\n",
      "123/123 [==============================] - 78s 635ms/step - loss: 0.3224 - accuracy: 0.8617 - val_loss: 0.3769 - val_accuracy: 0.8341\n",
      "Epoch 24/100\n",
      "123/123 [==============================] - 78s 633ms/step - loss: 0.3189 - accuracy: 0.8615 - val_loss: 0.3739 - val_accuracy: 0.8364\n",
      "Epoch 25/100\n",
      "123/123 [==============================] - 79s 643ms/step - loss: 0.3193 - accuracy: 0.8604 - val_loss: 0.3842 - val_accuracy: 0.8387\n",
      "Epoch 26/100\n",
      "123/123 [==============================] - 77s 625ms/step - loss: 0.3189 - accuracy: 0.8653 - val_loss: 0.3871 - val_accuracy: 0.8387\n",
      "Epoch 27/100\n",
      "123/123 [==============================] - 79s 641ms/step - loss: 0.3191 - accuracy: 0.8625 - val_loss: 0.4019 - val_accuracy: 0.8249\n",
      "Epoch 28/100\n",
      "123/123 [==============================] - 78s 634ms/step - loss: 0.3158 - accuracy: 0.8650 - val_loss: 0.3749 - val_accuracy: 0.8341\n",
      "Epoch 29/100\n",
      "123/123 [==============================] - 78s 637ms/step - loss: 0.3171 - accuracy: 0.8620 - val_loss: 0.3792 - val_accuracy: 0.8410\n",
      "Epoch 30/100\n",
      "123/123 [==============================] - 77s 629ms/step - loss: 0.3130 - accuracy: 0.8676 - val_loss: 0.3804 - val_accuracy: 0.8433\n",
      "Epoch 31/100\n",
      "123/123 [==============================] - 77s 626ms/step - loss: 0.3134 - accuracy: 0.8648 - val_loss: 0.3723 - val_accuracy: 0.8433\n",
      "Epoch 32/100\n",
      "123/123 [==============================] - 78s 636ms/step - loss: 0.3152 - accuracy: 0.8592 - val_loss: 0.3773 - val_accuracy: 0.8433\n",
      "Epoch 33/100\n",
      "123/123 [==============================] - 77s 630ms/step - loss: 0.3100 - accuracy: 0.8671 - val_loss: 0.3770 - val_accuracy: 0.8410\n",
      "Epoch 34/100\n",
      "123/123 [==============================] - 78s 634ms/step - loss: 0.3136 - accuracy: 0.8656 - val_loss: 0.3809 - val_accuracy: 0.8456\n",
      "Epoch 35/100\n",
      "123/123 [==============================] - 78s 631ms/step - loss: 0.3120 - accuracy: 0.8676 - val_loss: 0.3846 - val_accuracy: 0.8456\n",
      "Epoch 36/100\n",
      "123/123 [==============================] - 78s 631ms/step - loss: 0.3084 - accuracy: 0.8658 - val_loss: 0.3724 - val_accuracy: 0.8410\n",
      "Epoch 37/100\n",
      "123/123 [==============================] - 77s 627ms/step - loss: 0.3123 - accuracy: 0.8666 - val_loss: 0.3758 - val_accuracy: 0.8410\n",
      "Epoch 38/100\n",
      "123/123 [==============================] - 78s 633ms/step - loss: 0.3053 - accuracy: 0.8679 - val_loss: 0.3904 - val_accuracy: 0.8410\n",
      "Epoch 39/100\n",
      "123/123 [==============================] - 77s 624ms/step - loss: 0.3051 - accuracy: 0.8712 - val_loss: 0.3784 - val_accuracy: 0.8433\n",
      "Epoch 40/100\n",
      "123/123 [==============================] - 79s 641ms/step - loss: 0.3056 - accuracy: 0.8714 - val_loss: 0.3769 - val_accuracy: 0.8433\n",
      "Epoch 41/100\n",
      "123/123 [==============================] - 78s 634ms/step - loss: 0.3041 - accuracy: 0.8689 - val_loss: 0.3805 - val_accuracy: 0.8502\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42/100\n",
      "123/123 [==============================] - 79s 643ms/step - loss: 0.3017 - accuracy: 0.8712 - val_loss: 0.3711 - val_accuracy: 0.8433\n",
      "Epoch 43/100\n",
      "123/123 [==============================] - 80s 649ms/step - loss: 0.3025 - accuracy: 0.8755 - val_loss: 0.3718 - val_accuracy: 0.8433\n",
      "Epoch 44/100\n",
      "123/123 [==============================] - 78s 637ms/step - loss: 0.3040 - accuracy: 0.8712 - val_loss: 0.3745 - val_accuracy: 0.8479\n",
      "Epoch 45/100\n",
      "123/123 [==============================] - 96s 785ms/step - loss: 0.3027 - accuracy: 0.8730 - val_loss: 0.3729 - val_accuracy: 0.8479\n",
      "Epoch 46/100\n",
      "123/123 [==============================] - 112s 915ms/step - loss: 0.3033 - accuracy: 0.8755 - val_loss: 0.3769 - val_accuracy: 0.8502\n",
      "Epoch 47/100\n",
      "123/123 [==============================] - 114s 926ms/step - loss: 0.3021 - accuracy: 0.8735 - val_loss: 0.3730 - val_accuracy: 0.8479\n",
      "Epoch 48/100\n",
      "123/123 [==============================] - 114s 925ms/step - loss: 0.2956 - accuracy: 0.8786 - val_loss: 0.3817 - val_accuracy: 0.8479\n",
      "Epoch 49/100\n",
      "123/123 [==============================] - 116s 943ms/step - loss: 0.2975 - accuracy: 0.8709 - val_loss: 0.3740 - val_accuracy: 0.8456\n",
      "Epoch 50/100\n",
      "123/123 [==============================] - 113s 923ms/step - loss: 0.2953 - accuracy: 0.8738 - val_loss: 0.3852 - val_accuracy: 0.8157\n",
      "Epoch 51/100\n",
      "123/123 [==============================] - 115s 936ms/step - loss: 0.2978 - accuracy: 0.8694 - val_loss: 0.3710 - val_accuracy: 0.8410\n",
      "Epoch 52/100\n",
      "123/123 [==============================] - 114s 926ms/step - loss: 0.2973 - accuracy: 0.8776 - val_loss: 0.3725 - val_accuracy: 0.8410\n",
      "Epoch 53/100\n",
      "123/123 [==============================] - 114s 926ms/step - loss: 0.2942 - accuracy: 0.8735 - val_loss: 0.3729 - val_accuracy: 0.8410\n",
      "Epoch 54/100\n",
      "123/123 [==============================] - 115s 939ms/step - loss: 0.2934 - accuracy: 0.8748 - val_loss: 0.4339 - val_accuracy: 0.8226\n",
      "Epoch 55/100\n",
      "123/123 [==============================] - 114s 927ms/step - loss: 0.2948 - accuracy: 0.8766 - val_loss: 0.3783 - val_accuracy: 0.8548\n",
      "Epoch 56/100\n",
      "123/123 [==============================] - 113s 919ms/step - loss: 0.2960 - accuracy: 0.8725 - val_loss: 0.3807 - val_accuracy: 0.8525\n",
      "Epoch 57/100\n",
      "123/123 [==============================] - 117s 955ms/step - loss: 0.2944 - accuracy: 0.8738 - val_loss: 0.3763 - val_accuracy: 0.8525\n",
      "Epoch 58/100\n",
      "123/123 [==============================] - 80s 651ms/step - loss: 0.2946 - accuracy: 0.8763 - val_loss: 0.3734 - val_accuracy: 0.8456\n",
      "Epoch 59/100\n",
      "123/123 [==============================] - 82s 665ms/step - loss: 0.2908 - accuracy: 0.8763 - val_loss: 0.3795 - val_accuracy: 0.8548\n",
      "Epoch 60/100\n",
      "123/123 [==============================] - 77s 631ms/step - loss: 0.2942 - accuracy: 0.8730 - val_loss: 0.3715 - val_accuracy: 0.8410\n",
      "Epoch 61/100\n",
      "123/123 [==============================] - 78s 635ms/step - loss: 0.2904 - accuracy: 0.8758 - val_loss: 0.3754 - val_accuracy: 0.8479\n",
      "Epoch 62/100\n",
      "123/123 [==============================] - 76s 622ms/step - loss: 0.2895 - accuracy: 0.8807 - val_loss: 0.4106 - val_accuracy: 0.8272\n",
      "Epoch 63/100\n",
      "123/123 [==============================] - 79s 642ms/step - loss: 0.2842 - accuracy: 0.8855 - val_loss: 0.3783 - val_accuracy: 0.8456\n",
      "Epoch 64/100\n",
      "123/123 [==============================] - 78s 634ms/step - loss: 0.2877 - accuracy: 0.8712 - val_loss: 0.3728 - val_accuracy: 0.8433\n",
      "Epoch 65/100\n",
      "123/123 [==============================] - 78s 632ms/step - loss: 0.2835 - accuracy: 0.8789 - val_loss: 0.5310 - val_accuracy: 0.7926\n",
      "Epoch 66/100\n",
      "123/123 [==============================] - 77s 629ms/step - loss: 0.2954 - accuracy: 0.8730 - val_loss: 0.3732 - val_accuracy: 0.8364\n",
      "Epoch 67/100\n",
      "123/123 [==============================] - 78s 632ms/step - loss: 0.2883 - accuracy: 0.8784 - val_loss: 0.3773 - val_accuracy: 0.8525\n",
      "Epoch 68/100\n",
      "123/123 [==============================] - 78s 633ms/step - loss: 0.2875 - accuracy: 0.8763 - val_loss: 0.3764 - val_accuracy: 0.8479\n",
      "Epoch 69/100\n",
      "123/123 [==============================] - 78s 630ms/step - loss: 0.2856 - accuracy: 0.8773 - val_loss: 0.4481 - val_accuracy: 0.8180\n",
      "Epoch 70/100\n",
      "123/123 [==============================] - 79s 640ms/step - loss: 0.2880 - accuracy: 0.8781 - val_loss: 0.3763 - val_accuracy: 0.8410\n",
      "Epoch 71/100\n",
      "123/123 [==============================] - 77s 628ms/step - loss: 0.2788 - accuracy: 0.8825 - val_loss: 0.3849 - val_accuracy: 0.8502\n",
      "WARNING:tensorflow:Layer lstm_291 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Epoch 1/100\n",
      "122/122 [==============================] - 40s 319ms/step - loss: 0.6153 - accuracy: 0.6739 - val_loss: 0.5486 - val_accuracy: 0.7834\n",
      "Epoch 2/100\n",
      "122/122 [==============================] - 39s 323ms/step - loss: 0.5049 - accuracy: 0.8040 - val_loss: 0.4752 - val_accuracy: 0.7972\n",
      "Epoch 3/100\n",
      "122/122 [==============================] - 40s 324ms/step - loss: 0.4449 - accuracy: 0.8163 - val_loss: 0.4405 - val_accuracy: 0.8088\n",
      "Epoch 4/100\n",
      "122/122 [==============================] - 40s 324ms/step - loss: 0.4166 - accuracy: 0.8225 - val_loss: 0.4175 - val_accuracy: 0.8134\n",
      "Epoch 5/100\n",
      "122/122 [==============================] - 39s 322ms/step - loss: 0.3963 - accuracy: 0.8350 - val_loss: 0.4035 - val_accuracy: 0.8203\n",
      "Epoch 6/100\n",
      "122/122 [==============================] - 40s 325ms/step - loss: 0.3853 - accuracy: 0.8299 - val_loss: 0.4010 - val_accuracy: 0.8134\n",
      "Epoch 7/100\n",
      "122/122 [==============================] - 39s 321ms/step - loss: 0.3776 - accuracy: 0.8356 - val_loss: 0.3987 - val_accuracy: 0.8157\n",
      "Epoch 8/100\n",
      "122/122 [==============================] - 39s 323ms/step - loss: 0.3762 - accuracy: 0.8338 - val_loss: 0.3863 - val_accuracy: 0.8157\n",
      "Epoch 9/100\n",
      "122/122 [==============================] - 39s 322ms/step - loss: 0.3688 - accuracy: 0.8389 - val_loss: 0.3855 - val_accuracy: 0.8180\n",
      "Epoch 10/100\n",
      "122/122 [==============================] - 40s 326ms/step - loss: 0.3664 - accuracy: 0.8404 - val_loss: 0.3869 - val_accuracy: 0.8226\n",
      "Epoch 11/100\n",
      "122/122 [==============================] - 39s 324ms/step - loss: 0.3629 - accuracy: 0.8366 - val_loss: 0.3839 - val_accuracy: 0.8203\n",
      "Epoch 12/100\n",
      "122/122 [==============================] - 39s 320ms/step - loss: 0.3602 - accuracy: 0.8409 - val_loss: 0.3707 - val_accuracy: 0.8249\n",
      "Epoch 13/100\n",
      "122/122 [==============================] - 39s 322ms/step - loss: 0.3575 - accuracy: 0.8384 - val_loss: 0.3745 - val_accuracy: 0.8226\n",
      "Epoch 14/100\n",
      "122/122 [==============================] - 40s 324ms/step - loss: 0.3536 - accuracy: 0.8414 - val_loss: 0.3668 - val_accuracy: 0.8226\n",
      "Epoch 15/100\n",
      "122/122 [==============================] - 39s 323ms/step - loss: 0.3528 - accuracy: 0.8481 - val_loss: 0.3636 - val_accuracy: 0.8249\n",
      "Epoch 16/100\n",
      "122/122 [==============================] - 40s 327ms/step - loss: 0.3509 - accuracy: 0.8468 - val_loss: 0.3584 - val_accuracy: 0.8226\n",
      "Epoch 17/100\n",
      "122/122 [==============================] - 40s 324ms/step - loss: 0.3485 - accuracy: 0.8445 - val_loss: 0.3663 - val_accuracy: 0.8295\n",
      "Epoch 18/100\n",
      "122/122 [==============================] - 40s 331ms/step - loss: 0.3443 - accuracy: 0.8481 - val_loss: 0.3534 - val_accuracy: 0.8272\n",
      "Epoch 19/100\n",
      "122/122 [==============================] - 39s 322ms/step - loss: 0.3437 - accuracy: 0.8481 - val_loss: 0.3505 - val_accuracy: 0.8341\n",
      "Epoch 20/100\n",
      "122/122 [==============================] - 40s 327ms/step - loss: 0.3438 - accuracy: 0.8489 - val_loss: 0.3530 - val_accuracy: 0.8318\n",
      "Epoch 21/100\n",
      "122/122 [==============================] - 39s 323ms/step - loss: 0.3360 - accuracy: 0.8512 - val_loss: 0.3633 - val_accuracy: 0.8226\n",
      "Epoch 22/100\n",
      "122/122 [==============================] - 40s 324ms/step - loss: 0.3387 - accuracy: 0.8525 - val_loss: 0.3482 - val_accuracy: 0.8387\n",
      "Epoch 23/100\n",
      "122/122 [==============================] - 40s 325ms/step - loss: 0.3346 - accuracy: 0.8532 - val_loss: 0.3397 - val_accuracy: 0.8433\n",
      "Epoch 24/100\n",
      "122/122 [==============================] - 39s 323ms/step - loss: 0.3353 - accuracy: 0.8504 - val_loss: 0.3411 - val_accuracy: 0.8456\n",
      "Epoch 25/100\n",
      "122/122 [==============================] - 39s 319ms/step - loss: 0.3361 - accuracy: 0.8517 - val_loss: 0.3374 - val_accuracy: 0.8479\n",
      "Epoch 26/100\n",
      "122/122 [==============================] - 39s 321ms/step - loss: 0.3337 - accuracy: 0.8550 - val_loss: 0.3306 - val_accuracy: 0.8525\n",
      "Epoch 27/100\n",
      "122/122 [==============================] - 39s 320ms/step - loss: 0.3327 - accuracy: 0.8535 - val_loss: 0.3305 - val_accuracy: 0.8548\n",
      "Epoch 28/100\n",
      "122/122 [==============================] - 39s 323ms/step - loss: 0.3325 - accuracy: 0.8553 - val_loss: 0.3296 - val_accuracy: 0.8594\n",
      "Epoch 29/100\n",
      "122/122 [==============================] - 39s 321ms/step - loss: 0.3275 - accuracy: 0.8540 - val_loss: 0.3260 - val_accuracy: 0.8571\n",
      "Epoch 30/100\n",
      "122/122 [==============================] - 40s 326ms/step - loss: 0.3281 - accuracy: 0.8558 - val_loss: 0.3293 - val_accuracy: 0.8548\n",
      "Epoch 31/100\n",
      "122/122 [==============================] - 39s 322ms/step - loss: 0.3273 - accuracy: 0.8573 - val_loss: 0.3193 - val_accuracy: 0.8594\n",
      "Epoch 32/100\n",
      "122/122 [==============================] - 39s 320ms/step - loss: 0.3232 - accuracy: 0.8614 - val_loss: 0.3334 - val_accuracy: 0.8525\n",
      "Epoch 33/100\n",
      "122/122 [==============================] - 39s 322ms/step - loss: 0.3253 - accuracy: 0.8591 - val_loss: 0.3284 - val_accuracy: 0.8548\n",
      "Epoch 34/100\n",
      "122/122 [==============================] - 39s 320ms/step - loss: 0.3260 - accuracy: 0.8571 - val_loss: 0.3176 - val_accuracy: 0.8571\n",
      "Epoch 35/100\n",
      "122/122 [==============================] - 39s 318ms/step - loss: 0.3228 - accuracy: 0.8642 - val_loss: 0.3313 - val_accuracy: 0.8548\n",
      "Epoch 36/100\n",
      "122/122 [==============================] - 39s 319ms/step - loss: 0.3247 - accuracy: 0.8548 - val_loss: 0.3343 - val_accuracy: 0.8548\n",
      "Epoch 37/100\n",
      "122/122 [==============================] - 40s 327ms/step - loss: 0.3233 - accuracy: 0.8596 - val_loss: 0.3211 - val_accuracy: 0.8594\n",
      "Epoch 38/100\n",
      "122/122 [==============================] - 42s 342ms/step - loss: 0.3171 - accuracy: 0.8619 - val_loss: 0.3107 - val_accuracy: 0.8641\n",
      "Epoch 39/100\n",
      "122/122 [==============================] - 40s 329ms/step - loss: 0.3213 - accuracy: 0.8591 - val_loss: 0.3263 - val_accuracy: 0.8571\n",
      "Epoch 40/100\n",
      "122/122 [==============================] - 40s 325ms/step - loss: 0.3194 - accuracy: 0.8614 - val_loss: 0.3275 - val_accuracy: 0.8502\n",
      "Epoch 41/100\n",
      "122/122 [==============================] - 40s 325ms/step - loss: 0.3186 - accuracy: 0.8609 - val_loss: 0.3086 - val_accuracy: 0.8618\n",
      "Epoch 42/100\n",
      "122/122 [==============================] - 39s 322ms/step - loss: 0.3156 - accuracy: 0.8660 - val_loss: 0.3242 - val_accuracy: 0.8548\n",
      "Epoch 43/100\n",
      "122/122 [==============================] - 40s 325ms/step - loss: 0.3164 - accuracy: 0.8663 - val_loss: 0.3301 - val_accuracy: 0.8502\n",
      "Epoch 44/100\n",
      "122/122 [==============================] - 39s 321ms/step - loss: 0.3163 - accuracy: 0.8658 - val_loss: 0.3298 - val_accuracy: 0.8502\n",
      "Epoch 45/100\n",
      "122/122 [==============================] - 39s 317ms/step - loss: 0.3173 - accuracy: 0.8630 - val_loss: 0.3162 - val_accuracy: 0.8594\n",
      "Epoch 46/100\n",
      "122/122 [==============================] - 39s 321ms/step - loss: 0.3114 - accuracy: 0.8648 - val_loss: 0.3279 - val_accuracy: 0.8502\n",
      "Epoch 47/100\n",
      "122/122 [==============================] - 39s 323ms/step - loss: 0.3158 - accuracy: 0.8645 - val_loss: 0.3183 - val_accuracy: 0.8502\n",
      "Epoch 48/100\n",
      "122/122 [==============================] - 40s 324ms/step - loss: 0.3097 - accuracy: 0.8696 - val_loss: 0.3088 - val_accuracy: 0.8548\n",
      "Epoch 49/100\n",
      "122/122 [==============================] - 39s 319ms/step - loss: 0.3117 - accuracy: 0.8676 - val_loss: 0.3077 - val_accuracy: 0.8571\n",
      "Epoch 50/100\n",
      "122/122 [==============================] - 39s 323ms/step - loss: 0.3121 - accuracy: 0.8622 - val_loss: 0.3127 - val_accuracy: 0.8594\n",
      "Epoch 51/100\n",
      "122/122 [==============================] - 39s 321ms/step - loss: 0.3095 - accuracy: 0.8630 - val_loss: 0.3160 - val_accuracy: 0.8548\n",
      "Epoch 52/100\n",
      "122/122 [==============================] - 39s 321ms/step - loss: 0.3136 - accuracy: 0.8642 - val_loss: 0.3109 - val_accuracy: 0.8594\n",
      "Epoch 53/100\n",
      "122/122 [==============================] - 39s 322ms/step - loss: 0.3088 - accuracy: 0.8673 - val_loss: 0.3229 - val_accuracy: 0.8456\n",
      "Epoch 54/100\n",
      "122/122 [==============================] - 39s 319ms/step - loss: 0.3108 - accuracy: 0.8678 - val_loss: 0.3101 - val_accuracy: 0.8525\n",
      "Epoch 55/100\n",
      "122/122 [==============================] - 40s 325ms/step - loss: 0.3103 - accuracy: 0.8678 - val_loss: 0.3118 - val_accuracy: 0.8548\n",
      "Epoch 56/100\n",
      "122/122 [==============================] - 40s 325ms/step - loss: 0.3062 - accuracy: 0.8706 - val_loss: 0.3248 - val_accuracy: 0.8456\n",
      "Epoch 57/100\n",
      "122/122 [==============================] - 39s 323ms/step - loss: 0.3081 - accuracy: 0.8673 - val_loss: 0.3116 - val_accuracy: 0.8571\n",
      "Epoch 58/100\n",
      "122/122 [==============================] - 39s 319ms/step - loss: 0.3047 - accuracy: 0.8694 - val_loss: 0.3132 - val_accuracy: 0.8571\n",
      "Epoch 59/100\n",
      "122/122 [==============================] - 39s 322ms/step - loss: 0.3061 - accuracy: 0.8665 - val_loss: 0.3164 - val_accuracy: 0.8479\n",
      "Epoch 60/100\n",
      "122/122 [==============================] - 39s 321ms/step - loss: 0.3038 - accuracy: 0.8706 - val_loss: 0.3010 - val_accuracy: 0.8664\n",
      "Epoch 61/100\n",
      "122/122 [==============================] - 39s 322ms/step - loss: 0.3008 - accuracy: 0.8712 - val_loss: 0.2989 - val_accuracy: 0.8710\n",
      "Epoch 62/100\n",
      "122/122 [==============================] - 39s 322ms/step - loss: 0.3045 - accuracy: 0.8714 - val_loss: 0.3044 - val_accuracy: 0.8571\n",
      "Epoch 63/100\n",
      "122/122 [==============================] - 40s 326ms/step - loss: 0.3041 - accuracy: 0.8727 - val_loss: 0.3077 - val_accuracy: 0.8571\n",
      "Epoch 64/100\n",
      "122/122 [==============================] - 39s 321ms/step - loss: 0.3003 - accuracy: 0.8706 - val_loss: 0.3036 - val_accuracy: 0.8571\n",
      "Epoch 65/100\n",
      "122/122 [==============================] - 39s 321ms/step - loss: 0.3017 - accuracy: 0.8704 - val_loss: 0.2997 - val_accuracy: 0.8618\n",
      "Epoch 66/100\n",
      "122/122 [==============================] - 40s 328ms/step - loss: 0.3047 - accuracy: 0.8663 - val_loss: 0.3065 - val_accuracy: 0.8548\n",
      "Epoch 67/100\n",
      "122/122 [==============================] - 39s 319ms/step - loss: 0.2991 - accuracy: 0.8724 - val_loss: 0.2956 - val_accuracy: 0.8710\n",
      "Epoch 68/100\n",
      "122/122 [==============================] - 39s 322ms/step - loss: 0.2970 - accuracy: 0.8763 - val_loss: 0.3076 - val_accuracy: 0.8571\n",
      "Epoch 69/100\n",
      "122/122 [==============================] - 39s 322ms/step - loss: 0.3011 - accuracy: 0.8704 - val_loss: 0.2985 - val_accuracy: 0.8641\n",
      "Epoch 70/100\n",
      "122/122 [==============================] - 39s 323ms/step - loss: 0.2976 - accuracy: 0.8701 - val_loss: 0.2929 - val_accuracy: 0.8733\n",
      "Epoch 71/100\n",
      "122/122 [==============================] - 39s 321ms/step - loss: 0.2961 - accuracy: 0.8730 - val_loss: 0.3069 - val_accuracy: 0.8594\n",
      "Epoch 72/100\n",
      "122/122 [==============================] - 40s 325ms/step - loss: 0.2972 - accuracy: 0.8712 - val_loss: 0.3046 - val_accuracy: 0.8594\n",
      "Epoch 73/100\n",
      "122/122 [==============================] - 40s 325ms/step - loss: 0.2931 - accuracy: 0.8750 - val_loss: 0.3039 - val_accuracy: 0.8618\n",
      "Epoch 74/100\n",
      "122/122 [==============================] - 61s 504ms/step - loss: 0.2991 - accuracy: 0.8709 - val_loss: 0.2974 - val_accuracy: 0.8664\n",
      "Epoch 75/100\n",
      "122/122 [==============================] - 58s 479ms/step - loss: 0.2907 - accuracy: 0.8770 - val_loss: 0.2926 - val_accuracy: 0.8710\n",
      "Epoch 76/100\n",
      "122/122 [==============================] - 58s 478ms/step - loss: 0.2951 - accuracy: 0.8742 - val_loss: 0.2981 - val_accuracy: 0.8641\n",
      "Epoch 77/100\n",
      "122/122 [==============================] - 59s 480ms/step - loss: 0.2860 - accuracy: 0.8773 - val_loss: 0.3186 - val_accuracy: 0.8502\n",
      "Epoch 78/100\n",
      "122/122 [==============================] - 59s 484ms/step - loss: 0.2926 - accuracy: 0.8773 - val_loss: 0.3038 - val_accuracy: 0.8594\n",
      "Epoch 79/100\n",
      "122/122 [==============================] - 59s 487ms/step - loss: 0.2914 - accuracy: 0.8758 - val_loss: 0.2971 - val_accuracy: 0.8664\n",
      "Epoch 80/100\n",
      "122/122 [==============================] - 59s 483ms/step - loss: 0.2918 - accuracy: 0.8758 - val_loss: 0.3016 - val_accuracy: 0.8618\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 81/100\n",
      "122/122 [==============================] - 59s 483ms/step - loss: 0.2914 - accuracy: 0.8722 - val_loss: 0.2996 - val_accuracy: 0.8594\n",
      "Epoch 82/100\n",
      "122/122 [==============================] - 58s 477ms/step - loss: 0.2918 - accuracy: 0.8773 - val_loss: 0.3260 - val_accuracy: 0.8456\n",
      "Epoch 83/100\n",
      "122/122 [==============================] - 59s 480ms/step - loss: 0.2909 - accuracy: 0.8765 - val_loss: 0.3046 - val_accuracy: 0.8571\n",
      "Epoch 84/100\n",
      "122/122 [==============================] - 60s 490ms/step - loss: 0.2924 - accuracy: 0.8709 - val_loss: 0.3074 - val_accuracy: 0.8548\n",
      "Epoch 85/100\n",
      "122/122 [==============================] - 58s 477ms/step - loss: 0.2920 - accuracy: 0.8737 - val_loss: 0.3011 - val_accuracy: 0.8594\n",
      "Epoch 86/100\n",
      "122/122 [==============================] - 58s 477ms/step - loss: 0.2910 - accuracy: 0.8750 - val_loss: 0.2911 - val_accuracy: 0.8664\n",
      "Epoch 87/100\n",
      "122/122 [==============================] - 60s 488ms/step - loss: 0.2864 - accuracy: 0.8709 - val_loss: 0.2978 - val_accuracy: 0.8641\n",
      "Epoch 88/100\n",
      "122/122 [==============================] - 59s 483ms/step - loss: 0.2882 - accuracy: 0.8763 - val_loss: 0.3087 - val_accuracy: 0.8571\n",
      "Epoch 89/100\n",
      "122/122 [==============================] - 58s 475ms/step - loss: 0.2838 - accuracy: 0.8806 - val_loss: 0.2934 - val_accuracy: 0.8618\n",
      "Epoch 90/100\n",
      "122/122 [==============================] - 59s 480ms/step - loss: 0.2887 - accuracy: 0.8719 - val_loss: 0.2930 - val_accuracy: 0.8687\n",
      "Epoch 91/100\n",
      "122/122 [==============================] - 59s 480ms/step - loss: 0.2872 - accuracy: 0.8740 - val_loss: 0.2894 - val_accuracy: 0.8687\n",
      "Epoch 92/100\n",
      "122/122 [==============================] - 58s 479ms/step - loss: 0.2842 - accuracy: 0.8832 - val_loss: 0.2894 - val_accuracy: 0.8664\n",
      "Epoch 93/100\n",
      "122/122 [==============================] - 58s 473ms/step - loss: 0.2833 - accuracy: 0.8817 - val_loss: 0.3020 - val_accuracy: 0.8618\n",
      "Epoch 94/100\n",
      "122/122 [==============================] - 59s 482ms/step - loss: 0.2851 - accuracy: 0.8791 - val_loss: 0.3003 - val_accuracy: 0.8641\n",
      "Epoch 95/100\n",
      "122/122 [==============================] - 59s 481ms/step - loss: 0.2861 - accuracy: 0.8788 - val_loss: 0.2853 - val_accuracy: 0.8756\n",
      "Epoch 96/100\n",
      "122/122 [==============================] - 58s 476ms/step - loss: 0.2816 - accuracy: 0.8809 - val_loss: 0.2945 - val_accuracy: 0.8710\n",
      "Epoch 97/100\n",
      "122/122 [==============================] - 59s 484ms/step - loss: 0.2844 - accuracy: 0.8765 - val_loss: 0.2973 - val_accuracy: 0.8687\n",
      "Epoch 98/100\n",
      "122/122 [==============================] - 58s 479ms/step - loss: 0.2826 - accuracy: 0.8806 - val_loss: 0.2863 - val_accuracy: 0.8687\n",
      "Epoch 99/100\n",
      "122/122 [==============================] - 59s 487ms/step - loss: 0.2816 - accuracy: 0.8811 - val_loss: 0.2917 - val_accuracy: 0.8687\n",
      "Epoch 100/100\n",
      "122/122 [==============================] - 59s 481ms/step - loss: 0.2794 - accuracy: 0.8822 - val_loss: 0.2899 - val_accuracy: 0.8664\n",
      "WARNING:tensorflow:Layer lstm_292 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Epoch 1/100\n",
      "123/123 [==============================] - 115s 920ms/step - loss: 0.6186 - accuracy: 0.6725 - val_loss: 0.5754 - val_accuracy: 0.7995\n",
      "Epoch 2/100\n",
      "123/123 [==============================] - 82s 664ms/step - loss: 0.5434 - accuracy: 0.7939 - val_loss: 0.5122 - val_accuracy: 0.7995\n",
      "Epoch 3/100\n",
      "123/123 [==============================] - 77s 626ms/step - loss: 0.4792 - accuracy: 0.8123 - val_loss: 0.4561 - val_accuracy: 0.8018\n",
      "Epoch 4/100\n",
      "123/123 [==============================] - 77s 628ms/step - loss: 0.4395 - accuracy: 0.8131 - val_loss: 0.4291 - val_accuracy: 0.8065\n",
      "Epoch 5/100\n",
      "123/123 [==============================] - 78s 632ms/step - loss: 0.4167 - accuracy: 0.8120 - val_loss: 0.4208 - val_accuracy: 0.8134\n",
      "Epoch 6/100\n",
      "123/123 [==============================] - 76s 619ms/step - loss: 0.3999 - accuracy: 0.8197 - val_loss: 0.4266 - val_accuracy: 0.8041\n",
      "Epoch 7/100\n",
      "123/123 [==============================] - 77s 622ms/step - loss: 0.3914 - accuracy: 0.8225 - val_loss: 0.3895 - val_accuracy: 0.8134\n",
      "Epoch 8/100\n",
      "123/123 [==============================] - 77s 628ms/step - loss: 0.3845 - accuracy: 0.8261 - val_loss: 0.3905 - val_accuracy: 0.8157\n",
      "Epoch 9/100\n",
      "123/123 [==============================] - 77s 629ms/step - loss: 0.3811 - accuracy: 0.8302 - val_loss: 0.4016 - val_accuracy: 0.8041\n",
      "Epoch 10/100\n",
      "123/123 [==============================] - 77s 624ms/step - loss: 0.3747 - accuracy: 0.8256 - val_loss: 0.3899 - val_accuracy: 0.8180\n",
      "Epoch 11/100\n",
      "123/123 [==============================] - 139188s 1141s/step - loss: 0.3721 - accuracy: 0.8254 - val_loss: 0.3826 - val_accuracy: 0.8180\n",
      "Epoch 12/100\n",
      "123/123 [==============================] - 93s 756ms/step - loss: 0.3708 - accuracy: 0.8353 - val_loss: 0.3767 - val_accuracy: 0.8226\n",
      "Epoch 13/100\n",
      "123/123 [==============================] - 81s 655ms/step - loss: 0.3675 - accuracy: 0.8294 - val_loss: 0.3630 - val_accuracy: 0.8203\n",
      "Epoch 14/100\n",
      "123/123 [==============================] - 78s 636ms/step - loss: 0.3630 - accuracy: 0.8369 - val_loss: 0.3806 - val_accuracy: 0.8180\n",
      "Epoch 15/100\n",
      "123/123 [==============================] - 79s 640ms/step - loss: 0.3642 - accuracy: 0.8320 - val_loss: 0.3430 - val_accuracy: 0.8502\n",
      "Epoch 16/100\n",
      "123/123 [==============================] - 89s 723ms/step - loss: 0.3609 - accuracy: 0.8371 - val_loss: 0.3678 - val_accuracy: 0.8226\n",
      "Epoch 17/100\n",
      "123/123 [==============================] - 82s 671ms/step - loss: 0.3567 - accuracy: 0.8423 - val_loss: 0.3569 - val_accuracy: 0.8272\n",
      "Epoch 18/100\n",
      "123/123 [==============================] - 79s 645ms/step - loss: 0.3572 - accuracy: 0.8366 - val_loss: 0.3560 - val_accuracy: 0.8272\n",
      "Epoch 19/100\n",
      "123/123 [==============================] - 78s 638ms/step - loss: 0.3535 - accuracy: 0.8348 - val_loss: 0.3500 - val_accuracy: 0.8295\n",
      "Epoch 20/100\n",
      "123/123 [==============================] - 80s 652ms/step - loss: 0.3486 - accuracy: 0.8443 - val_loss: 0.4164 - val_accuracy: 0.7903\n",
      "Epoch 21/100\n",
      "123/123 [==============================] - 79s 640ms/step - loss: 0.3536 - accuracy: 0.8405 - val_loss: 0.3551 - val_accuracy: 0.8249\n",
      "Epoch 22/100\n",
      "123/123 [==============================] - 79s 641ms/step - loss: 0.3465 - accuracy: 0.8438 - val_loss: 0.3314 - val_accuracy: 0.8479\n",
      "Epoch 23/100\n",
      "123/123 [==============================] - 80s 647ms/step - loss: 0.3431 - accuracy: 0.8474 - val_loss: 0.3758 - val_accuracy: 0.8111\n",
      "Epoch 24/100\n",
      "123/123 [==============================] - 79s 639ms/step - loss: 0.3457 - accuracy: 0.8433 - val_loss: 0.3246 - val_accuracy: 0.8571\n",
      "Epoch 25/100\n",
      "123/123 [==============================] - 78s 630ms/step - loss: 0.3424 - accuracy: 0.8464 - val_loss: 0.3290 - val_accuracy: 0.8410\n",
      "Epoch 26/100\n",
      "123/123 [==============================] - 76s 619ms/step - loss: 0.3425 - accuracy: 0.8453 - val_loss: 0.3263 - val_accuracy: 0.8479\n",
      "Epoch 27/100\n",
      "123/123 [==============================] - 78s 635ms/step - loss: 0.3393 - accuracy: 0.8487 - val_loss: 0.3206 - val_accuracy: 0.8571\n",
      "Epoch 28/100\n",
      "123/123 [==============================] - 75s 613ms/step - loss: 0.3388 - accuracy: 0.8512 - val_loss: 0.3307 - val_accuracy: 0.8502\n",
      "Epoch 29/100\n",
      "123/123 [==============================] - 76s 621ms/step - loss: 0.3367 - accuracy: 0.8512 - val_loss: 0.3498 - val_accuracy: 0.8479\n",
      "Epoch 30/100\n",
      "123/123 [==============================] - 77s 627ms/step - loss: 0.3374 - accuracy: 0.8530 - val_loss: 0.3491 - val_accuracy: 0.8272\n",
      "Epoch 31/100\n",
      "123/123 [==============================] - 75s 608ms/step - loss: 0.3348 - accuracy: 0.8492 - val_loss: 0.3209 - val_accuracy: 0.8571\n",
      "Epoch 32/100\n",
      "123/123 [==============================] - 76s 620ms/step - loss: 0.3363 - accuracy: 0.8530 - val_loss: 0.3883 - val_accuracy: 0.8018\n",
      "Epoch 33/100\n",
      "123/123 [==============================] - 76s 621ms/step - loss: 0.3391 - accuracy: 0.8515 - val_loss: 0.3082 - val_accuracy: 0.8710\n",
      "Epoch 34/100\n",
      "123/123 [==============================] - 76s 619ms/step - loss: 0.3331 - accuracy: 0.8502 - val_loss: 0.3156 - val_accuracy: 0.8618\n",
      "Epoch 35/100\n",
      "123/123 [==============================] - 77s 627ms/step - loss: 0.3280 - accuracy: 0.8569 - val_loss: 0.3225 - val_accuracy: 0.8548\n",
      "Epoch 36/100\n",
      "123/123 [==============================] - 76s 622ms/step - loss: 0.3301 - accuracy: 0.8522 - val_loss: 0.3120 - val_accuracy: 0.8664\n",
      "Epoch 37/100\n",
      "123/123 [==============================] - 74s 602ms/step - loss: 0.3254 - accuracy: 0.8533 - val_loss: 0.3135 - val_accuracy: 0.8641\n",
      "Epoch 38/100\n",
      "123/123 [==============================] - 78s 634ms/step - loss: 0.3311 - accuracy: 0.8545 - val_loss: 0.3188 - val_accuracy: 0.8571\n",
      "Epoch 39/100\n",
      "123/123 [==============================] - 76s 616ms/step - loss: 0.3270 - accuracy: 0.8597 - val_loss: 0.3109 - val_accuracy: 0.8664\n",
      "Epoch 40/100\n",
      "123/123 [==============================] - 75s 610ms/step - loss: 0.3283 - accuracy: 0.8594 - val_loss: 0.2977 - val_accuracy: 0.8710\n",
      "Epoch 41/100\n",
      "123/123 [==============================] - 77s 628ms/step - loss: 0.3235 - accuracy: 0.8574 - val_loss: 0.3039 - val_accuracy: 0.8687\n",
      "Epoch 42/100\n",
      "123/123 [==============================] - 75s 613ms/step - loss: 0.3225 - accuracy: 0.8563 - val_loss: 0.2992 - val_accuracy: 0.8710\n",
      "Epoch 43/100\n",
      "123/123 [==============================] - 77s 624ms/step - loss: 0.3223 - accuracy: 0.8597 - val_loss: 0.3076 - val_accuracy: 0.8710\n",
      "Epoch 44/100\n",
      "123/123 [==============================] - 76s 618ms/step - loss: 0.3213 - accuracy: 0.8571 - val_loss: 0.3024 - val_accuracy: 0.8687\n",
      "Epoch 45/100\n",
      "123/123 [==============================] - 74s 606ms/step - loss: 0.3212 - accuracy: 0.8607 - val_loss: 0.3083 - val_accuracy: 0.8664\n",
      "Epoch 46/100\n",
      "123/123 [==============================] - 78s 635ms/step - loss: 0.3211 - accuracy: 0.8643 - val_loss: 0.2921 - val_accuracy: 0.8687\n",
      "Epoch 47/100\n",
      "123/123 [==============================] - 76s 619ms/step - loss: 0.3214 - accuracy: 0.8599 - val_loss: 0.2934 - val_accuracy: 0.8664\n",
      "Epoch 48/100\n",
      "123/123 [==============================] - 31426s 258s/step - loss: 0.3171 - accuracy: 0.8656 - val_loss: 0.4205 - val_accuracy: 0.7857\n",
      "Epoch 49/100\n",
      "123/123 [==============================] - 78s 634ms/step - loss: 0.3237 - accuracy: 0.8535 - val_loss: 0.3026 - val_accuracy: 0.8664\n",
      "Epoch 50/100\n",
      "123/123 [==============================] - 78s 638ms/step - loss: 0.3228 - accuracy: 0.8579 - val_loss: 0.3059 - val_accuracy: 0.8594\n",
      "Epoch 51/100\n",
      "123/123 [==============================] - 81s 658ms/step - loss: 0.3126 - accuracy: 0.8635 - val_loss: 0.2899 - val_accuracy: 0.8825\n",
      "Epoch 52/100\n",
      "123/123 [==============================] - 81s 655ms/step - loss: 0.3141 - accuracy: 0.8656 - val_loss: 0.3201 - val_accuracy: 0.8410\n",
      "Epoch 53/100\n",
      "123/123 [==============================] - 82s 668ms/step - loss: 0.3141 - accuracy: 0.8663 - val_loss: 0.3012 - val_accuracy: 0.8641\n",
      "Epoch 54/100\n",
      "123/123 [==============================] - 78s 632ms/step - loss: 0.3108 - accuracy: 0.8666 - val_loss: 0.2994 - val_accuracy: 0.8641\n",
      "Epoch 55/100\n",
      "123/123 [==============================] - 78s 632ms/step - loss: 0.3118 - accuracy: 0.8645 - val_loss: 0.2926 - val_accuracy: 0.8664\n",
      "Epoch 56/100\n",
      "123/123 [==============================] - 77s 625ms/step - loss: 0.3122 - accuracy: 0.8640 - val_loss: 0.3218 - val_accuracy: 0.8456\n",
      "Epoch 57/100\n",
      "123/123 [==============================] - 80s 649ms/step - loss: 0.3153 - accuracy: 0.8635 - val_loss: 0.2924 - val_accuracy: 0.8664\n",
      "Epoch 58/100\n",
      "123/123 [==============================] - 77s 630ms/step - loss: 0.3136 - accuracy: 0.8684 - val_loss: 0.2845 - val_accuracy: 0.8733\n",
      "Epoch 59/100\n",
      "123/123 [==============================] - 75s 613ms/step - loss: 0.3079 - accuracy: 0.8645 - val_loss: 0.2895 - val_accuracy: 0.8687\n",
      "Epoch 60/100\n",
      "123/123 [==============================] - 78s 633ms/step - loss: 0.3081 - accuracy: 0.8702 - val_loss: 0.2946 - val_accuracy: 0.8710\n",
      "Epoch 61/100\n",
      "123/123 [==============================] - 78s 632ms/step - loss: 0.3057 - accuracy: 0.8671 - val_loss: 0.2900 - val_accuracy: 0.8733\n",
      "Epoch 62/100\n",
      "123/123 [==============================] - 77s 628ms/step - loss: 0.3098 - accuracy: 0.8648 - val_loss: 0.2852 - val_accuracy: 0.8710\n",
      "Epoch 63/100\n",
      "123/123 [==============================] - 77s 628ms/step - loss: 0.3061 - accuracy: 0.8699 - val_loss: 0.2910 - val_accuracy: 0.8687\n",
      "Epoch 64/100\n",
      "123/123 [==============================] - 77s 628ms/step - loss: 0.3082 - accuracy: 0.8681 - val_loss: 0.2869 - val_accuracy: 0.8687\n",
      "Epoch 65/100\n",
      "123/123 [==============================] - 76s 623ms/step - loss: 0.3039 - accuracy: 0.8717 - val_loss: 0.2873 - val_accuracy: 0.8710\n",
      "Epoch 66/100\n",
      "123/123 [==============================] - 78s 637ms/step - loss: 0.3089 - accuracy: 0.8699 - val_loss: 0.2850 - val_accuracy: 0.8733\n",
      "Epoch 67/100\n",
      "123/123 [==============================] - 77s 626ms/step - loss: 0.3086 - accuracy: 0.8679 - val_loss: 0.3162 - val_accuracy: 0.8502\n",
      "Epoch 68/100\n",
      "123/123 [==============================] - 92s 753ms/step - loss: 0.3069 - accuracy: 0.8666 - val_loss: 0.2842 - val_accuracy: 0.8733\n",
      "Epoch 69/100\n",
      "123/123 [==============================] - 112s 910ms/step - loss: 0.3031 - accuracy: 0.8714 - val_loss: 0.2792 - val_accuracy: 0.8710\n",
      "Epoch 70/100\n",
      "123/123 [==============================] - 112s 910ms/step - loss: 0.3039 - accuracy: 0.8709 - val_loss: 0.2807 - val_accuracy: 0.8756\n",
      "Epoch 71/100\n",
      "123/123 [==============================] - 109s 889ms/step - loss: 0.3025 - accuracy: 0.8689 - val_loss: 0.4300 - val_accuracy: 0.7834\n",
      "Epoch 72/100\n",
      "123/123 [==============================] - 111s 899ms/step - loss: 0.3074 - accuracy: 0.8686 - val_loss: 0.2826 - val_accuracy: 0.8756\n",
      "Epoch 73/100\n",
      "123/123 [==============================] - 110s 890ms/step - loss: 0.2996 - accuracy: 0.8702 - val_loss: 0.2933 - val_accuracy: 0.8641\n",
      "Epoch 74/100\n",
      "123/123 [==============================] - 110s 894ms/step - loss: 0.3024 - accuracy: 0.8704 - val_loss: 0.3204 - val_accuracy: 0.8710\n",
      "Epoch 75/100\n",
      "123/123 [==============================] - 113s 917ms/step - loss: 0.2989 - accuracy: 0.8725 - val_loss: 0.2787 - val_accuracy: 0.8802\n",
      "Epoch 76/100\n",
      "123/123 [==============================] - 110s 892ms/step - loss: 0.2984 - accuracy: 0.8717 - val_loss: 0.2749 - val_accuracy: 0.8733\n",
      "Epoch 77/100\n",
      "123/123 [==============================] - 14254s 117s/step - loss: 0.2949 - accuracy: 0.8750 - val_loss: 0.2738 - val_accuracy: 0.8779\n",
      "Epoch 78/100\n",
      "123/123 [==============================] - 78s 631ms/step - loss: 0.3000 - accuracy: 0.8689 - val_loss: 0.2845 - val_accuracy: 0.8687\n",
      "Epoch 79/100\n",
      "123/123 [==============================] - 79s 641ms/step - loss: 0.2989 - accuracy: 0.8712 - val_loss: 0.2988 - val_accuracy: 0.8756\n",
      "Epoch 80/100\n",
      "123/123 [==============================] - 79s 640ms/step - loss: 0.2969 - accuracy: 0.8730 - val_loss: 0.2847 - val_accuracy: 0.8710\n",
      "Epoch 81/100\n",
      "123/123 [==============================] - 79s 645ms/step - loss: 0.2919 - accuracy: 0.8735 - val_loss: 0.3731 - val_accuracy: 0.8134\n",
      "Epoch 82/100\n",
      "123/123 [==============================] - 78s 632ms/step - loss: 0.2961 - accuracy: 0.8738 - val_loss: 0.2821 - val_accuracy: 0.8779\n",
      "Epoch 83/100\n",
      "123/123 [==============================] - 79s 646ms/step - loss: 0.2917 - accuracy: 0.8743 - val_loss: 0.2741 - val_accuracy: 0.8779\n",
      "Epoch 84/100\n",
      "123/123 [==============================] - 76s 620ms/step - loss: 0.2912 - accuracy: 0.8735 - val_loss: 0.2806 - val_accuracy: 0.8779\n",
      "Epoch 85/100\n",
      "123/123 [==============================] - 78s 637ms/step - loss: 0.2949 - accuracy: 0.8735 - val_loss: 0.2720 - val_accuracy: 0.8733\n",
      "Epoch 86/100\n",
      "123/123 [==============================] - 78s 633ms/step - loss: 0.2939 - accuracy: 0.8781 - val_loss: 0.2980 - val_accuracy: 0.8687\n",
      "Epoch 87/100\n",
      "123/123 [==============================] - 78s 636ms/step - loss: 0.2906 - accuracy: 0.8763 - val_loss: 0.3096 - val_accuracy: 0.8548\n",
      "Epoch 88/100\n",
      "123/123 [==============================] - 79s 644ms/step - loss: 0.2940 - accuracy: 0.8735 - val_loss: 0.2754 - val_accuracy: 0.8802\n",
      "Epoch 89/100\n",
      "123/123 [==============================] - 76s 615ms/step - loss: 0.2870 - accuracy: 0.8768 - val_loss: 0.2780 - val_accuracy: 0.8733\n",
      "Epoch 90/100\n",
      "123/123 [==============================] - 77s 624ms/step - loss: 0.2965 - accuracy: 0.8704 - val_loss: 0.2793 - val_accuracy: 0.8733\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 91/100\n",
      "123/123 [==============================] - 77s 630ms/step - loss: 0.2900 - accuracy: 0.8725 - val_loss: 0.2781 - val_accuracy: 0.8802\n",
      "Epoch 92/100\n",
      "123/123 [==============================] - 78s 638ms/step - loss: 0.2888 - accuracy: 0.8768 - val_loss: 0.2691 - val_accuracy: 0.8733\n",
      "Epoch 93/100\n",
      "123/123 [==============================] - 79s 639ms/step - loss: 0.2908 - accuracy: 0.8709 - val_loss: 0.2723 - val_accuracy: 0.8756\n",
      "Epoch 94/100\n",
      "123/123 [==============================] - 80s 655ms/step - loss: 0.2911 - accuracy: 0.8753 - val_loss: 0.2702 - val_accuracy: 0.8664\n",
      "Epoch 95/100\n",
      "123/123 [==============================] - 76s 616ms/step - loss: 0.2857 - accuracy: 0.8796 - val_loss: 0.2735 - val_accuracy: 0.8802\n",
      "Epoch 96/100\n",
      "123/123 [==============================] - 76s 621ms/step - loss: 0.2871 - accuracy: 0.8781 - val_loss: 0.2698 - val_accuracy: 0.8756\n",
      "Epoch 97/100\n",
      "123/123 [==============================] - 77s 628ms/step - loss: 0.2872 - accuracy: 0.8778 - val_loss: 0.2692 - val_accuracy: 0.8733\n",
      "Epoch 98/100\n",
      "123/123 [==============================] - 76s 615ms/step - loss: 0.2816 - accuracy: 0.8786 - val_loss: 0.2986 - val_accuracy: 0.8571\n",
      "Epoch 99/100\n",
      "123/123 [==============================] - 75s 610ms/step - loss: 0.2809 - accuracy: 0.8799 - val_loss: 0.2831 - val_accuracy: 0.8710\n",
      "Epoch 100/100\n",
      "123/123 [==============================] - 79s 641ms/step - loss: 0.2884 - accuracy: 0.8766 - val_loss: 0.2717 - val_accuracy: 0.8825\n",
      "WARNING:tensorflow:Layer lstm_293 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Epoch 1/100\n",
      "123/123 [==============================] - 80s 638ms/step - loss: 0.6346 - accuracy: 0.6218 - val_loss: 0.5915 - val_accuracy: 0.7097\n",
      "Epoch 2/100\n",
      "123/123 [==============================] - 77s 625ms/step - loss: 0.5332 - accuracy: 0.7787 - val_loss: 0.5059 - val_accuracy: 0.7995\n",
      "Epoch 3/100\n",
      "123/123 [==============================] - 76s 616ms/step - loss: 0.4588 - accuracy: 0.8200 - val_loss: 0.4557 - val_accuracy: 0.8157\n",
      "Epoch 4/100\n",
      "123/123 [==============================] - 76s 615ms/step - loss: 0.4119 - accuracy: 0.8289 - val_loss: 0.4283 - val_accuracy: 0.8088\n",
      "Epoch 5/100\n",
      "123/123 [==============================] - 77s 623ms/step - loss: 0.3883 - accuracy: 0.8330 - val_loss: 0.4153 - val_accuracy: 0.7995\n",
      "Epoch 6/100\n",
      "123/123 [==============================] - 75s 609ms/step - loss: 0.3738 - accuracy: 0.8366 - val_loss: 0.4048 - val_accuracy: 0.8018\n",
      "Epoch 7/100\n",
      "123/123 [==============================] - 74s 605ms/step - loss: 0.3650 - accuracy: 0.8384 - val_loss: 0.3956 - val_accuracy: 0.8249\n",
      "Epoch 8/100\n",
      "123/123 [==============================] - 77s 623ms/step - loss: 0.3580 - accuracy: 0.8438 - val_loss: 0.3939 - val_accuracy: 0.8180\n",
      "Epoch 9/100\n",
      "123/123 [==============================] - 76s 618ms/step - loss: 0.3531 - accuracy: 0.8387 - val_loss: 0.3984 - val_accuracy: 0.7995\n",
      "Epoch 10/100\n",
      "123/123 [==============================] - 75s 607ms/step - loss: 0.3469 - accuracy: 0.8461 - val_loss: 0.3937 - val_accuracy: 0.8134\n",
      "Epoch 11/100\n",
      "123/123 [==============================] - 77s 629ms/step - loss: 0.3469 - accuracy: 0.8435 - val_loss: 0.3896 - val_accuracy: 0.8180\n",
      "Epoch 12/100\n",
      "123/123 [==============================] - 76s 618ms/step - loss: 0.3450 - accuracy: 0.8471 - val_loss: 0.3859 - val_accuracy: 0.8203\n",
      "Epoch 13/100\n",
      "123/123 [==============================] - 77s 629ms/step - loss: 0.3431 - accuracy: 0.8458 - val_loss: 0.3898 - val_accuracy: 0.8134\n",
      "Epoch 14/100\n",
      "123/123 [==============================] - 76s 615ms/step - loss: 0.3418 - accuracy: 0.8499 - val_loss: 0.3826 - val_accuracy: 0.8318\n",
      "Epoch 15/100\n",
      "123/123 [==============================] - 75s 612ms/step - loss: 0.3368 - accuracy: 0.8504 - val_loss: 0.4223 - val_accuracy: 0.7995\n",
      "Epoch 16/100\n",
      "123/123 [==============================] - 76s 615ms/step - loss: 0.3405 - accuracy: 0.8512 - val_loss: 0.3911 - val_accuracy: 0.8180\n",
      "Epoch 17/100\n",
      "123/123 [==============================] - 77s 625ms/step - loss: 0.3338 - accuracy: 0.8522 - val_loss: 0.3944 - val_accuracy: 0.8111\n",
      "Epoch 18/100\n",
      "123/123 [==============================] - 75s 613ms/step - loss: 0.3321 - accuracy: 0.8558 - val_loss: 0.3751 - val_accuracy: 0.8433\n",
      "Epoch 19/100\n",
      "123/123 [==============================] - 186s 2s/step - loss: 0.3310 - accuracy: 0.8566 - val_loss: 0.3772 - val_accuracy: 0.8479\n",
      "Epoch 20/100\n",
      "123/123 [==============================] - 114s 927ms/step - loss: 0.3300 - accuracy: 0.8530 - val_loss: 0.3909 - val_accuracy: 0.8180\n",
      "Epoch 21/100\n",
      "123/123 [==============================] - 116s 947ms/step - loss: 0.3264 - accuracy: 0.8597 - val_loss: 0.3773 - val_accuracy: 0.8341\n",
      "Epoch 22/100\n",
      "123/123 [==============================] - 113s 921ms/step - loss: 0.3242 - accuracy: 0.8579 - val_loss: 0.3780 - val_accuracy: 0.8341\n",
      "Epoch 23/100\n",
      "123/123 [==============================] - 103s 838ms/step - loss: 0.3180 - accuracy: 0.8597 - val_loss: 0.3821 - val_accuracy: 0.8364\n",
      "Epoch 24/100\n",
      "123/123 [==============================] - 104s 843ms/step - loss: 0.3210 - accuracy: 0.8579 - val_loss: 0.3769 - val_accuracy: 0.8364\n",
      "Epoch 25/100\n",
      "123/123 [==============================] - 104s 846ms/step - loss: 0.3200 - accuracy: 0.8615 - val_loss: 0.4243 - val_accuracy: 0.7972\n",
      "Epoch 26/100\n",
      "123/123 [==============================] - 104s 844ms/step - loss: 0.3241 - accuracy: 0.8607 - val_loss: 0.3739 - val_accuracy: 0.8387\n",
      "Epoch 27/100\n",
      "123/123 [==============================] - 104s 847ms/step - loss: 0.3199 - accuracy: 0.8597 - val_loss: 0.3738 - val_accuracy: 0.8433\n",
      "Epoch 28/100\n",
      "123/123 [==============================] - 105s 853ms/step - loss: 0.3170 - accuracy: 0.8622 - val_loss: 0.3705 - val_accuracy: 0.8433\n",
      "Epoch 29/100\n",
      "123/123 [==============================] - 104s 848ms/step - loss: 0.3144 - accuracy: 0.8630 - val_loss: 0.3984 - val_accuracy: 0.8180\n",
      "Epoch 30/100\n",
      "123/123 [==============================] - 104s 846ms/step - loss: 0.3158 - accuracy: 0.8635 - val_loss: 0.4016 - val_accuracy: 0.8180\n",
      "Epoch 31/100\n",
      "123/123 [==============================] - 104s 846ms/step - loss: 0.3179 - accuracy: 0.8658 - val_loss: 0.3739 - val_accuracy: 0.8410\n",
      "Epoch 32/100\n",
      "123/123 [==============================] - 104s 843ms/step - loss: 0.3122 - accuracy: 0.8640 - val_loss: 0.4029 - val_accuracy: 0.8088\n",
      "Epoch 33/100\n",
      "123/123 [==============================] - 106s 859ms/step - loss: 0.3108 - accuracy: 0.8694 - val_loss: 0.3707 - val_accuracy: 0.8433\n",
      "Epoch 34/100\n",
      "123/123 [==============================] - 108s 880ms/step - loss: 0.3121 - accuracy: 0.8627 - val_loss: 0.4173 - val_accuracy: 0.8111\n",
      "Epoch 35/100\n",
      "123/123 [==============================] - 112s 910ms/step - loss: 0.3092 - accuracy: 0.8663 - val_loss: 0.3683 - val_accuracy: 0.8479\n",
      "Epoch 36/100\n",
      "123/123 [==============================] - 113s 920ms/step - loss: 0.3111 - accuracy: 0.8691 - val_loss: 0.3899 - val_accuracy: 0.8203\n",
      "Epoch 37/100\n",
      "123/123 [==============================] - 113s 921ms/step - loss: 0.3074 - accuracy: 0.8673 - val_loss: 0.3694 - val_accuracy: 0.8387\n",
      "Epoch 38/100\n",
      "123/123 [==============================] - 112s 907ms/step - loss: 0.3023 - accuracy: 0.8676 - val_loss: 0.3688 - val_accuracy: 0.8364\n",
      "Epoch 39/100\n",
      "123/123 [==============================] - 113s 920ms/step - loss: 0.3067 - accuracy: 0.8694 - val_loss: 0.3698 - val_accuracy: 0.8410\n",
      "Epoch 40/100\n",
      "123/123 [==============================] - 112s 913ms/step - loss: 0.3018 - accuracy: 0.8725 - val_loss: 0.3743 - val_accuracy: 0.8479\n",
      "Epoch 41/100\n",
      "123/123 [==============================] - 112s 914ms/step - loss: 0.3021 - accuracy: 0.8722 - val_loss: 0.4013 - val_accuracy: 0.8249\n",
      "Epoch 42/100\n",
      "123/123 [==============================] - 113s 916ms/step - loss: 0.3037 - accuracy: 0.8707 - val_loss: 0.3804 - val_accuracy: 0.8479\n",
      "Epoch 43/100\n",
      "123/123 [==============================] - 110s 891ms/step - loss: 0.3005 - accuracy: 0.8768 - val_loss: 0.3775 - val_accuracy: 0.8479\n",
      "Epoch 44/100\n",
      "123/123 [==============================] - 108s 875ms/step - loss: 0.2975 - accuracy: 0.8745 - val_loss: 0.3732 - val_accuracy: 0.8226\n",
      "Epoch 45/100\n",
      "123/123 [==============================] - 107s 873ms/step - loss: 0.3006 - accuracy: 0.8717 - val_loss: 0.3897 - val_accuracy: 0.8456\n",
      "Epoch 46/100\n",
      "123/123 [==============================] - 108s 879ms/step - loss: 0.3006 - accuracy: 0.8732 - val_loss: 0.3728 - val_accuracy: 0.8479\n",
      "Epoch 47/100\n",
      "123/123 [==============================] - 1859s 15s/step - loss: 0.3021 - accuracy: 0.8740 - val_loss: 0.4479 - val_accuracy: 0.8088\n",
      "Epoch 48/100\n",
      "123/123 [==============================] - 79s 645ms/step - loss: 0.3060 - accuracy: 0.8681 - val_loss: 0.3712 - val_accuracy: 0.8456\n",
      "Epoch 49/100\n",
      "123/123 [==============================] - 80s 649ms/step - loss: 0.3018 - accuracy: 0.8686 - val_loss: 0.4155 - val_accuracy: 0.7949\n",
      "Epoch 50/100\n",
      " 59/123 [=============>................] - ETA: 39s - loss: 0.3078 - accuracy: 0.8665"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [36]\u001b[0m, in \u001b[0;36m<cell line: 19>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     10\u001b[0m params \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124moptimizer\u001b[39m\u001b[38;5;124m'\u001b[39m : [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msgd\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdropout_rate\u001b[39m\u001b[38;5;124m'\u001b[39m : [\u001b[38;5;241m0.2\u001b[39m, \u001b[38;5;241m0.3\u001b[39m, \u001b[38;5;241m0.1\u001b[39m],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdense_activation\u001b[39m\u001b[38;5;124m'\u001b[39m : [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124melu\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msigmoid\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     16\u001b[0m }\n\u001b[0;32m     18\u001b[0m rand_search \u001b[38;5;241m=\u001b[39m RandomizedSearchCV(classifier, params, n_iter\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, scoring\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m, return_train_score\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m---> 19\u001b[0m \u001b[43mrand_search\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_padded\u001b[49m\u001b[43m,\u001b[49m\u001b[43mY_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     20\u001b[0m \u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mes_cb\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\gpu\\lib\\site-packages\\sklearn\\model_selection\\_search.py:891\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    885\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[0;32m    886\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m    887\u001b[0m     )\n\u001b[0;32m    889\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[1;32m--> 891\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    893\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m    894\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m    895\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\gpu\\lib\\site-packages\\sklearn\\model_selection\\_search.py:1766\u001b[0m, in \u001b[0;36mRandomizedSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1764\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1765\u001b[0m     \u001b[38;5;124;03m\"\"\"Search n_iter candidates from param_distributions\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1766\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1767\u001b[0m \u001b[43m        \u001b[49m\u001b[43mParameterSampler\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1768\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_distributions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_iter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom_state\u001b[49m\n\u001b[0;32m   1769\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1770\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\gpu\\lib\\site-packages\\sklearn\\model_selection\\_search.py:838\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    830\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    831\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[0;32m    832\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    833\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    834\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[0;32m    835\u001b[0m         )\n\u001b[0;32m    836\u001b[0m     )\n\u001b[1;32m--> 838\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    839\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    840\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    841\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    842\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    843\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    844\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    845\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    846\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    847\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    848\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    849\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    850\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    851\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    852\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    853\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    855\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    856\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    857\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    858\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    859\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    860\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\gpu\\lib\\site-packages\\joblib\\parallel.py:1046\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1043\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[0;32m   1044\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_original_iterator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1046\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdispatch_one_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m   1047\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m   1049\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pre_dispatch \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   1050\u001b[0m     \u001b[38;5;66;03m# The iterable was consumed all at once by the above for loop.\u001b[39;00m\n\u001b[0;32m   1051\u001b[0m     \u001b[38;5;66;03m# No need to wait for async callbacks to trigger to\u001b[39;00m\n\u001b[0;32m   1052\u001b[0m     \u001b[38;5;66;03m# consumption.\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\gpu\\lib\\site-packages\\joblib\\parallel.py:861\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    859\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    860\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 861\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    862\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\gpu\\lib\\site-packages\\joblib\\parallel.py:779\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    777\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m    778\u001b[0m     job_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs)\n\u001b[1;32m--> 779\u001b[0m     job \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_backend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_async\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    780\u001b[0m     \u001b[38;5;66;03m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[0;32m    781\u001b[0m     \u001b[38;5;66;03m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[0;32m    782\u001b[0m     \u001b[38;5;66;03m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[0;32m    783\u001b[0m     \u001b[38;5;66;03m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[0;32m    784\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs\u001b[38;5;241m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\gpu\\lib\\site-packages\\joblib\\_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_async\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, callback\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    207\u001b[0m     \u001b[38;5;124;03m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[1;32m--> 208\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mImmediateResult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m callback:\n\u001b[0;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\gpu\\lib\\site-packages\\joblib\\_parallel_backends.py:572\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    569\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch):\n\u001b[0;32m    570\u001b[0m     \u001b[38;5;66;03m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[0;32m    571\u001b[0m     \u001b[38;5;66;03m# arguments in memory\u001b[39;00m\n\u001b[1;32m--> 572\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults \u001b[38;5;241m=\u001b[39m \u001b[43mbatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\gpu\\lib\\site-packages\\joblib\\parallel.py:262\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    258\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    259\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    260\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    261\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 262\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    263\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\gpu\\lib\\site-packages\\joblib\\parallel.py:262\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    258\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    259\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    260\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    261\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 262\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    263\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\gpu\\lib\\site-packages\\sklearn\\utils\\fixes.py:216\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig):\n\u001b[1;32m--> 216\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:680\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[0;32m    678\u001b[0m         estimator\u001b[38;5;241m.\u001b[39mfit(X_train, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[0;32m    679\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 680\u001b[0m         estimator\u001b[38;5;241m.\u001b[39mfit(X_train, y_train, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[0;32m    682\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m    683\u001b[0m     \u001b[38;5;66;03m# Note fit time as time until error\u001b[39;00m\n\u001b[0;32m    684\u001b[0m     fit_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\gpu\\lib\\site-packages\\keras\\wrappers\\scikit_learn.py:236\u001b[0m, in \u001b[0;36mKerasClassifier.fit\u001b[1;34m(self, x, y, **kwargs)\u001b[0m\n\u001b[0;32m    234\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInvalid shape for y: \u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(y\u001b[38;5;241m.\u001b[39mshape))\n\u001b[0;32m    235\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_)\n\u001b[1;32m--> 236\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m(KerasClassifier, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mfit(x, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\gpu\\lib\\site-packages\\keras\\wrappers\\scikit_learn.py:164\u001b[0m, in \u001b[0;36mBaseWrapper.fit\u001b[1;34m(self, x, y, **kwargs)\u001b[0m\n\u001b[0;32m    161\u001b[0m fit_args \u001b[38;5;241m=\u001b[39m copy\u001b[38;5;241m.\u001b[39mdeepcopy(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfilter_sk_params(Sequential\u001b[38;5;241m.\u001b[39mfit))\n\u001b[0;32m    162\u001b[0m fit_args\u001b[38;5;241m.\u001b[39mupdate(kwargs)\n\u001b[1;32m--> 164\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mfit(x, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_args)\n\u001b[0;32m    166\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m history\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\gpu\\lib\\site-packages\\keras\\utils\\traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 64\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\gpu\\lib\\site-packages\\keras\\engine\\training.py:1384\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1377\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1378\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   1379\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   1380\u001b[0m     step_num\u001b[38;5;241m=\u001b[39mstep,\n\u001b[0;32m   1381\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[0;32m   1382\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m   1383\u001b[0m   callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1384\u001b[0m   tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1385\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1386\u001b[0m     context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    912\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    914\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 915\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    917\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    918\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    944\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    945\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    946\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 947\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateless_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    948\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    949\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    950\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[0;32m    951\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\function.py:2956\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2953\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m   2954\u001b[0m   (graph_function,\n\u001b[0;32m   2955\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2956\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2957\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\function.py:1853\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1849\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1850\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1851\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1852\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1853\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1854\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1855\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1856\u001b[0m     args,\n\u001b[0;32m   1857\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1858\u001b[0m     executing_eagerly)\n\u001b[0;32m   1859\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    497\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    498\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 499\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    504\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    505\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    506\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    507\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[0;32m    508\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    511\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[0;32m    512\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "es_cb = EarlyStopping(monitor='val_loss', patience=20, mode='min', restore_best_weights=True)\n",
    "classifier = KerasClassifier(build_lstm_model)\n",
    "\n",
    "classifier.get_params().keys()\n",
    "\n",
    "params = {\n",
    "    'optimizer' : ['sgd', 'adam'],\n",
    "    'dropout_rate' : [0.2, 0.3, 0.1],\n",
    "    'n_neurons' : [300, 128, 64],\n",
    "    'cnn_activation' : ['relu', 'elu'],\n",
    "    'dense_activation' : ['relu', 'elu','sigmoid']\n",
    "}\n",
    "\n",
    "rand_search = RandomizedSearchCV(classifier, params, n_iter=10, cv=3, verbose=1, scoring='accuracy', return_train_score=True)\n",
    "rand_search.fit(X_train_padded,Y_train,validation_split=0.1, epochs=100,\n",
    "callbacks=es_cb)\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
